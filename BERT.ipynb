{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pv6KDdCLqngu"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 512\n",
        "BERT_MODEL = \"bert-base-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ODpHxEA0vkd7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "G2QXzlNkvkd9"
      },
      "outputs": [],
      "source": [
        "class BERTModel(nn.Module):\n",
        "    \"\"\"\n",
        "        BERT model with a dropout and linear layer with 2 outputs\n",
        "    \"\"\"\n",
        "    def __init__(self, bert_model, num_classes=2, dropout_rate=0.3):\n",
        "        super(BERTModel, self).__init__()\n",
        "        self.bert = transformers.BertModel.from_pretrained(bert_model)\n",
        "        self.drop = nn.Dropout(dropout_rate)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4ykvSgarp9A4"
      },
      "outputs": [],
      "source": [
        "def remove_tags(text):\n",
        "    if isinstance(text, list):\n",
        "        return [remove_tags(t) for t in text]\n",
        "    else:\n",
        "        text = text.lower()\n",
        "        # Remove hashtags\n",
        "        text = re.sub(r'#\\w+', '', text)\n",
        "        # Remove '<user>'\n",
        "        text = re.sub(r'<user>', '', text)\n",
        "        # Remove '<url>'\n",
        "        text = re.sub(r'<url>', '', text)\n",
        "        # remove number\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "f3qCUn8gvkd9"
      },
      "outputs": [],
      "source": [
        "def train(data, model, optimizer, device):\n",
        "    \"\"\"\n",
        "        Train the model for one epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_idx, d in enumerate(data):\n",
        "        mask = d['mask'].to(device, dtype=torch.long)\n",
        "        ids = d['ids'].to(device, dtype=torch.long)\n",
        "        token_type_ids = d['token_type_ids'].to(device, dtype=torch.long)\n",
        "        targets = d['targets'].to(device, dtype=torch.long)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        loss = torch.nn.CrossEntropyLoss(outputs, targets) # Calculate loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0 and batch_idx !=0:\n",
        "            temp = f'Batch index = {batch_idx}\\tRunning Loss = {running_loss/10}'\n",
        "            print(temp)\n",
        "            running_loss = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "39defc5139e24431ac20c3f1bc7faa7f",
            "aedb6b756d5949b897c8efcd38622855",
            "55adf2e4079240c28006e6b2f5247c2d",
            "909aa314910d429b9a24e6b33ba41dc8",
            "bacc9e20d09d4064b8d9824d37a43d44",
            "3bd9188ae6414fe3b28f52d88aa6012c",
            "bd417b8d4a8745b293956f05ba48f7b2",
            "0f38fc12874446abbf2767a04e1e05ef",
            "8dd318a1fa2843cbab7047bc3741296e",
            "b679171ab707492ab9d0aebc07232d92",
            "125fc3defb934484b47c9d86cd632bbc",
            "2cb7f33f73a44212903dacb9fc13a5c8",
            "408fe317813f421bb77c97ec30e41125",
            "5f56a9f04032416995d83ebc7e8067b7",
            "399404ae78514d87af805eeae52ac6da",
            "dc8be3d30f5b47ffae3e394102a7392c",
            "9278eac27dc740cfafd944b71bc44eeb",
            "c4c6b654729b4221962a4fdc30bbcb9e",
            "9aeee5e49361449b8a269519a4f176d0",
            "175368bb903c41b6b9dc09574b2f27d6",
            "73f44759a18d43229dcadc240334944f",
            "36bf77fe27ab483997e073c49096464a",
            "726d5e2f329b4d12a8088b6667ea42c0",
            "ab80dce52b374653b0d363e821b28468",
            "79e3872c7ffd4fc19602cd0917243da3",
            "b347db1d29654fd9b096b789d8b6080a",
            "8a296714b44044689d1881fd9ec84160",
            "eed58ea3c0e942d4a93f98080f1ea808",
            "bd099c2b893244eb8c07824b3350a48f",
            "72353c6129d44c2ab0654b922fd9a0bb",
            "f86cfe1ddaa240ce8eaac38a82c20abd",
            "9156a6bc795f42beb5a5991b23591033",
            "443e61c993dd42eb9c9ad782b11eca93",
            "f2b5b740966544598f468398a42121c6",
            "89e4a680539f47a3ab8a6ff018898df4",
            "9d6c22f05b2f4501bea23c38edcbbb6b",
            "0fa78a342be94571a268ee61f4e3c01d",
            "2fa8386c7a7b47f4a5417002e5fec63a",
            "0b5d6a1e607144878554a64ebab0533f",
            "ae76992fb23943f7ac30b058a4c8e16a",
            "636e173a4d8a4d5db8b34b8935db62e0",
            "26d819d3a7234c05978fa8b38a3d3c61",
            "9094bfe693954583927f67e355770eaf",
            "4d26a53fe26549349e45e227c1bfd585"
          ]
        },
        "id": "6quHUiImvkd9",
        "outputId": "a1796ed9-7386-487c-fddb-9975d58bbd79"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'lower'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     neg_tweets \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# TODO: preprocess data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pos_tweets \u001b[39m=\u001b[39m remove_tags(pos_tweets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m neg_tweets \u001b[39m=\u001b[39m remove_tags(neg_tweets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m pos_labels \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(pos_tweets))]\n",
            "\u001b[1;32m/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mremove_tags\u001b[39m(text):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39;49mlower()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Remove hashtags\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/doris/University/Exchange/CS433/ML_project/BERT.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
          ]
        }
      ],
      "source": [
        "pos_path = 'data/twitter-datasets/train_pos.txt'\n",
        "neg_path = 'data/twitter-datasets/train_neg.txt'\n",
        "\n",
        "with open(pos_path, 'r') as f:\n",
        "    pos_tweets = f.readlines()\n",
        "with open(neg_path, 'r') as f:\n",
        "    neg_tweets = f.readlines()\n",
        "\n",
        "# TODO: preprocess data\n",
        "pos_tweets = remove_tags(pos_tweets)\n",
        "neg_tweets = remove_tags(neg_tweets)\n",
        "\n",
        "\n",
        "pos_labels = [1 for _ in range(len(pos_tweets))]\n",
        "neg_labels = [0 for _ in range(len(neg_tweets))]\n",
        "labels = pos_labels + neg_labels\n",
        "tweets = pos_tweets + neg_tweets\n",
        "\n",
        "train_tweets, val_tweets, train_labels, val_labels = train_test_split(tweets, labels, test_size=0.1)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True)\n",
        "train_encodings = tokenizer(train_tweets, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "val_encodings = tokenizer(val_tweets, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = TweetDataset(train_encodings, train_labels)\n",
        "val_dataset = TweetDataset(val_encodings, val_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dbdf4e8013ca45f78e131323c7437659",
            "02abcd45b1864d078cc550c667fdaf48",
            "7871b157ae36445cac915f7fe44f5856",
            "03b02aed55704de489049ff99a8794c3",
            "88a9c0743a344f3bb06c7c411730822d",
            "d2989b8f0d1e4896b6f348dd4dddfe2b",
            "102153cc6f3248949ab7ac5875b73907",
            "28c1be7267954ebd9b0811bb128016f8",
            "784f5867029247ecacfb9cf7912b490a",
            "ff749937033648f9a17b5f36a31d9765",
            "1d758595b9c04c4c8b5d097b05683d7a"
          ]
        },
        "id": "hhA0rrcSvkd-",
        "outputId": "aeaf57dc-8a80-44e4-a5c5-bed3a9eb60d6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbdf4e8013ca45f78e131323c7437659",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "Step 17505/22500 - Loss: 0.15061628818511963, Accuracy: 0.875\n",
            "Step 17506/22500 - Loss: 0.33853819966316223, Accuracy: 0.875\n",
            "Step 17507/22500 - Loss: 0.027762144804000854, Accuracy: 1.0\n",
            "Step 17508/22500 - Loss: 0.08470586687326431, Accuracy: 1.0\n",
            "Step 17509/22500 - Loss: 0.3344103693962097, Accuracy: 0.875\n",
            "Step 17510/22500 - Loss: 0.08903975039720535, Accuracy: 1.0\n",
            "Step 17511/22500 - Loss: 0.11428086459636688, Accuracy: 1.0\n",
            "Step 17512/22500 - Loss: 0.16558657586574554, Accuracy: 0.875\n",
            "Step 17513/22500 - Loss: 0.0924130231142044, Accuracy: 1.0\n",
            "Step 17514/22500 - Loss: 0.2806130647659302, Accuracy: 0.875\n",
            "Step 17515/22500 - Loss: 0.0034428469371050596, Accuracy: 1.0\n",
            "Step 17516/22500 - Loss: 0.1406453400850296, Accuracy: 0.875\n",
            "Step 17517/22500 - Loss: 0.4121395945549011, Accuracy: 0.875\n",
            "Step 17518/22500 - Loss: 0.2875213325023651, Accuracy: 0.875\n",
            "Step 17519/22500 - Loss: 0.11572179943323135, Accuracy: 1.0\n",
            "Step 17520/22500 - Loss: 0.05712210014462471, Accuracy: 1.0\n",
            "Step 17521/22500 - Loss: 0.12812823057174683, Accuracy: 0.875\n",
            "Step 17522/22500 - Loss: 0.4410046935081482, Accuracy: 0.875\n",
            "Step 17523/22500 - Loss: 0.31088972091674805, Accuracy: 0.875\n",
            "Step 17524/22500 - Loss: 0.1445986032485962, Accuracy: 1.0\n",
            "Step 17525/22500 - Loss: 0.46689069271087646, Accuracy: 0.875\n",
            "Step 17526/22500 - Loss: 0.03004397824406624, Accuracy: 1.0\n",
            "Step 17527/22500 - Loss: 0.40666964650154114, Accuracy: 0.875\n",
            "Step 17528/22500 - Loss: 0.1124405637383461, Accuracy: 1.0\n",
            "Step 17529/22500 - Loss: 0.12922030687332153, Accuracy: 1.0\n",
            "Step 17530/22500 - Loss: 0.04245895519852638, Accuracy: 1.0\n",
            "Step 17531/22500 - Loss: 0.033700719475746155, Accuracy: 1.0\n",
            "Step 17532/22500 - Loss: 0.10708628594875336, Accuracy: 1.0\n",
            "Step 17533/22500 - Loss: 0.053202152252197266, Accuracy: 1.0\n",
            "Step 17534/22500 - Loss: 0.011216230690479279, Accuracy: 1.0\n",
            "Step 17535/22500 - Loss: 0.06269406527280807, Accuracy: 1.0\n",
            "Step 17536/22500 - Loss: 0.04526468366384506, Accuracy: 1.0\n",
            "Step 17537/22500 - Loss: 0.016447385773062706, Accuracy: 1.0\n",
            "Step 17538/22500 - Loss: 0.103522390127182, Accuracy: 1.0\n",
            "Step 17539/22500 - Loss: 0.15041880309581757, Accuracy: 0.875\n",
            "Step 17540/22500 - Loss: 0.01042403094470501, Accuracy: 1.0\n",
            "Step 17541/22500 - Loss: 0.14772425591945648, Accuracy: 1.0\n",
            "Step 17542/22500 - Loss: 0.25744470953941345, Accuracy: 0.875\n",
            "Step 17543/22500 - Loss: 0.06355970352888107, Accuracy: 1.0\n",
            "Step 17544/22500 - Loss: 0.2016269564628601, Accuracy: 0.875\n",
            "Step 17545/22500 - Loss: 0.09477417171001434, Accuracy: 1.0\n",
            "Step 17546/22500 - Loss: 0.12622685730457306, Accuracy: 1.0\n",
            "Step 17547/22500 - Loss: 0.09355771541595459, Accuracy: 1.0\n",
            "Step 17548/22500 - Loss: 0.46896007657051086, Accuracy: 0.875\n",
            "Step 17549/22500 - Loss: 0.021952642127871513, Accuracy: 1.0\n",
            "Step 17550/22500 - Loss: 0.07326248288154602, Accuracy: 1.0\n",
            "Step 17551/22500 - Loss: 0.16329115629196167, Accuracy: 1.0\n",
            "Step 17552/22500 - Loss: 0.03303086385130882, Accuracy: 1.0\n",
            "Step 17553/22500 - Loss: 0.3855551779270172, Accuracy: 0.875\n",
            "Step 17554/22500 - Loss: 0.13499715924263, Accuracy: 1.0\n",
            "Step 17555/22500 - Loss: 0.07015576958656311, Accuracy: 1.0\n",
            "Step 17556/22500 - Loss: 0.5304660201072693, Accuracy: 0.875\n",
            "Step 17557/22500 - Loss: 0.04336152970790863, Accuracy: 1.0\n",
            "Step 17558/22500 - Loss: 0.26810094714164734, Accuracy: 0.875\n",
            "Step 17559/22500 - Loss: 0.09036082029342651, Accuracy: 1.0\n",
            "Step 17560/22500 - Loss: 0.007423593197017908, Accuracy: 1.0\n",
            "Step 17561/22500 - Loss: 0.028632119297981262, Accuracy: 1.0\n",
            "Step 17562/22500 - Loss: 0.41124165058135986, Accuracy: 0.875\n",
            "Step 17563/22500 - Loss: 0.10924524068832397, Accuracy: 0.875\n",
            "Step 17564/22500 - Loss: 0.008187123574316502, Accuracy: 1.0\n",
            "Step 17565/22500 - Loss: 0.162051260471344, Accuracy: 0.875\n",
            "Step 17566/22500 - Loss: 0.1761464923620224, Accuracy: 0.875\n",
            "Step 17567/22500 - Loss: 0.25639501214027405, Accuracy: 0.875\n",
            "Step 17568/22500 - Loss: 0.8008667230606079, Accuracy: 0.875\n",
            "Step 17569/22500 - Loss: 0.027188755571842194, Accuracy: 1.0\n",
            "Step 17570/22500 - Loss: 0.40824267268180847, Accuracy: 0.875\n",
            "Step 17571/22500 - Loss: 0.7009736895561218, Accuracy: 0.875\n",
            "Step 17572/22500 - Loss: 0.5340873599052429, Accuracy: 0.75\n",
            "Step 17573/22500 - Loss: 0.17122513055801392, Accuracy: 1.0\n",
            "Step 17574/22500 - Loss: 0.011235360987484455, Accuracy: 1.0\n",
            "Step 17575/22500 - Loss: 0.42219990491867065, Accuracy: 0.75\n",
            "Step 17576/22500 - Loss: 0.031764015555381775, Accuracy: 1.0\n",
            "Step 17577/22500 - Loss: 0.04273016378283501, Accuracy: 1.0\n",
            "Step 17578/22500 - Loss: 0.06759993731975555, Accuracy: 1.0\n",
            "Step 17579/22500 - Loss: 0.03536142408847809, Accuracy: 1.0\n",
            "Step 17580/22500 - Loss: 0.12218127399682999, Accuracy: 0.875\n",
            "Step 17581/22500 - Loss: 0.11055748909711838, Accuracy: 1.0\n",
            "Step 17582/22500 - Loss: 0.08015536516904831, Accuracy: 1.0\n",
            "Step 17583/22500 - Loss: 0.1728980839252472, Accuracy: 0.875\n",
            "Step 17584/22500 - Loss: 0.08632327616214752, Accuracy: 1.0\n",
            "Step 17585/22500 - Loss: 0.12217404693365097, Accuracy: 0.875\n",
            "Step 17586/22500 - Loss: 0.009596701711416245, Accuracy: 1.0\n",
            "Step 17587/22500 - Loss: 0.006334397010505199, Accuracy: 1.0\n",
            "Step 17588/22500 - Loss: 0.022543886676430702, Accuracy: 1.0\n",
            "Step 17589/22500 - Loss: 0.08855053037405014, Accuracy: 1.0\n",
            "Step 17590/22500 - Loss: 0.049943841993808746, Accuracy: 1.0\n",
            "Step 17591/22500 - Loss: 0.005837364122271538, Accuracy: 1.0\n",
            "Step 17592/22500 - Loss: 0.011916521936655045, Accuracy: 1.0\n",
            "Step 17593/22500 - Loss: 0.033399730920791626, Accuracy: 1.0\n",
            "Step 17594/22500 - Loss: 0.017007026821374893, Accuracy: 1.0\n",
            "Step 17595/22500 - Loss: 0.05824227258563042, Accuracy: 1.0\n",
            "Step 17596/22500 - Loss: 0.05257364735007286, Accuracy: 1.0\n",
            "Step 17597/22500 - Loss: 0.6450763940811157, Accuracy: 0.75\n",
            "Step 17598/22500 - Loss: 0.07851245254278183, Accuracy: 1.0\n",
            "Step 17599/22500 - Loss: 0.029287606477737427, Accuracy: 1.0\n",
            "Step 17600/22500 - Loss: 0.249619722366333, Accuracy: 0.875\n",
            "Step 17601/22500 - Loss: 0.05528037250041962, Accuracy: 1.0\n",
            "Step 17602/22500 - Loss: 0.12352374196052551, Accuracy: 1.0\n",
            "Step 17603/22500 - Loss: 0.08735926449298859, Accuracy: 1.0\n",
            "Step 17604/22500 - Loss: 0.015725787729024887, Accuracy: 1.0\n",
            "Step 17605/22500 - Loss: 0.054657481610774994, Accuracy: 1.0\n",
            "Step 17606/22500 - Loss: 0.3283919095993042, Accuracy: 0.875\n",
            "Step 17607/22500 - Loss: 0.21930861473083496, Accuracy: 0.875\n",
            "Step 17608/22500 - Loss: 0.09444892406463623, Accuracy: 1.0\n",
            "Step 17609/22500 - Loss: 0.025163773447275162, Accuracy: 1.0\n",
            "Step 17610/22500 - Loss: 0.4324064254760742, Accuracy: 0.75\n",
            "Step 17611/22500 - Loss: 0.008115720003843307, Accuracy: 1.0\n",
            "Step 17612/22500 - Loss: 0.03288042172789574, Accuracy: 1.0\n",
            "Step 17613/22500 - Loss: 0.04252633824944496, Accuracy: 1.0\n",
            "Step 17614/22500 - Loss: 0.1780736893415451, Accuracy: 0.875\n",
            "Step 17615/22500 - Loss: 0.020823467522859573, Accuracy: 1.0\n",
            "Step 17616/22500 - Loss: 0.011621658690273762, Accuracy: 1.0\n",
            "Step 17617/22500 - Loss: 0.025807170197367668, Accuracy: 1.0\n",
            "Step 17618/22500 - Loss: 0.17156288027763367, Accuracy: 0.875\n",
            "Step 17619/22500 - Loss: 0.012842503376305103, Accuracy: 1.0\n",
            "Step 17620/22500 - Loss: 0.02218913659453392, Accuracy: 1.0\n",
            "Step 17621/22500 - Loss: 0.07890234887599945, Accuracy: 1.0\n",
            "Step 17622/22500 - Loss: 0.1473885327577591, Accuracy: 1.0\n",
            "Step 17623/22500 - Loss: 0.20091558992862701, Accuracy: 0.875\n",
            "Step 17624/22500 - Loss: 0.49129775166511536, Accuracy: 0.75\n",
            "Step 17625/22500 - Loss: 0.07784554362297058, Accuracy: 1.0\n",
            "Step 17626/22500 - Loss: 0.09410975128412247, Accuracy: 1.0\n",
            "Step 17627/22500 - Loss: 0.030586034059524536, Accuracy: 1.0\n",
            "Step 17628/22500 - Loss: 1.0679513216018677, Accuracy: 0.625\n",
            "Step 17629/22500 - Loss: 0.3242206275463104, Accuracy: 0.75\n",
            "Step 17630/22500 - Loss: 0.033851172775030136, Accuracy: 1.0\n",
            "Step 17631/22500 - Loss: 0.04681142419576645, Accuracy: 1.0\n",
            "Step 17632/22500 - Loss: 0.06553764641284943, Accuracy: 1.0\n",
            "Step 17633/22500 - Loss: 0.0545637346804142, Accuracy: 1.0\n",
            "Step 17634/22500 - Loss: 0.027589688077569008, Accuracy: 1.0\n",
            "Step 17635/22500 - Loss: 0.06942591816186905, Accuracy: 1.0\n",
            "Step 17636/22500 - Loss: 0.10709825158119202, Accuracy: 1.0\n",
            "Step 17637/22500 - Loss: 0.01896710880100727, Accuracy: 1.0\n",
            "Step 17638/22500 - Loss: 0.050726551562547684, Accuracy: 1.0\n",
            "Step 17639/22500 - Loss: 0.07213722914457321, Accuracy: 1.0\n",
            "Step 17640/22500 - Loss: 0.05158984288573265, Accuracy: 1.0\n",
            "Step 17641/22500 - Loss: 0.03365607559680939, Accuracy: 1.0\n",
            "Step 17642/22500 - Loss: 0.08399669080972672, Accuracy: 1.0\n",
            "Step 17643/22500 - Loss: 0.009886414743959904, Accuracy: 1.0\n",
            "Step 17644/22500 - Loss: 0.02036442421376705, Accuracy: 1.0\n",
            "Step 17645/22500 - Loss: 0.1001238077878952, Accuracy: 0.875\n",
            "Step 17646/22500 - Loss: 0.04848496988415718, Accuracy: 1.0\n",
            "Step 17647/22500 - Loss: 0.006593680940568447, Accuracy: 1.0\n",
            "Step 17648/22500 - Loss: 0.016393061727285385, Accuracy: 1.0\n",
            "Step 17649/22500 - Loss: 0.14972524344921112, Accuracy: 0.875\n",
            "Step 17650/22500 - Loss: 0.0074998377822339535, Accuracy: 1.0\n",
            "Step 17651/22500 - Loss: 0.030189212411642075, Accuracy: 1.0\n",
            "Step 17652/22500 - Loss: 0.010727090761065483, Accuracy: 1.0\n",
            "Step 17653/22500 - Loss: 0.054162561893463135, Accuracy: 1.0\n",
            "Step 17654/22500 - Loss: 0.12278265506029129, Accuracy: 1.0\n",
            "Step 17655/22500 - Loss: 0.008020922541618347, Accuracy: 1.0\n",
            "Step 17656/22500 - Loss: 0.010341192595660686, Accuracy: 1.0\n",
            "Step 17657/22500 - Loss: 0.1347271353006363, Accuracy: 1.0\n",
            "Step 17658/22500 - Loss: 0.04080940783023834, Accuracy: 1.0\n",
            "Step 17659/22500 - Loss: 0.016461964696645737, Accuracy: 1.0\n",
            "Step 17660/22500 - Loss: 0.02176659367978573, Accuracy: 1.0\n",
            "Step 17661/22500 - Loss: 0.034862060099840164, Accuracy: 1.0\n",
            "Step 17662/22500 - Loss: 0.34466972947120667, Accuracy: 0.875\n",
            "Step 17663/22500 - Loss: 0.03194185346364975, Accuracy: 1.0\n",
            "Step 17664/22500 - Loss: 0.02762141451239586, Accuracy: 1.0\n",
            "Step 17665/22500 - Loss: 0.04273346811532974, Accuracy: 1.0\n",
            "Step 17666/22500 - Loss: 0.0009141594637185335, Accuracy: 1.0\n",
            "Step 17667/22500 - Loss: 0.23497281968593597, Accuracy: 0.875\n",
            "Step 17668/22500 - Loss: 0.031432997435331345, Accuracy: 1.0\n",
            "Step 17669/22500 - Loss: 0.021985404193401337, Accuracy: 1.0\n",
            "Step 17670/22500 - Loss: 0.007373043801635504, Accuracy: 1.0\n",
            "Step 17671/22500 - Loss: 0.33242711424827576, Accuracy: 0.875\n",
            "Step 17672/22500 - Loss: 0.5012409687042236, Accuracy: 0.75\n",
            "Step 17673/22500 - Loss: 0.12002848088741302, Accuracy: 0.875\n",
            "Step 17674/22500 - Loss: 0.017211316153407097, Accuracy: 1.0\n",
            "Step 17675/22500 - Loss: 0.009337237104773521, Accuracy: 1.0\n",
            "Step 17676/22500 - Loss: 0.02474791556596756, Accuracy: 1.0\n",
            "Step 17677/22500 - Loss: 0.044177357107400894, Accuracy: 1.0\n",
            "Step 17678/22500 - Loss: 0.13810589909553528, Accuracy: 0.875\n",
            "Step 17679/22500 - Loss: 0.0415564700961113, Accuracy: 1.0\n",
            "Step 17680/22500 - Loss: 0.1435467153787613, Accuracy: 0.875\n",
            "Step 17681/22500 - Loss: 0.02028800919651985, Accuracy: 1.0\n",
            "Step 17682/22500 - Loss: 0.02253780886530876, Accuracy: 1.0\n",
            "Step 17683/22500 - Loss: 0.013814299367368221, Accuracy: 1.0\n",
            "Step 17684/22500 - Loss: 0.029439879581332207, Accuracy: 1.0\n",
            "Step 17685/22500 - Loss: 0.08072885870933533, Accuracy: 1.0\n",
            "Step 17686/22500 - Loss: 0.05316120758652687, Accuracy: 1.0\n",
            "Step 17687/22500 - Loss: 0.26778438687324524, Accuracy: 0.875\n",
            "Step 17688/22500 - Loss: 0.010545962490141392, Accuracy: 1.0\n",
            "Step 17689/22500 - Loss: 0.22792081534862518, Accuracy: 0.875\n",
            "Step 17690/22500 - Loss: 0.1903907060623169, Accuracy: 0.875\n",
            "Step 17691/22500 - Loss: 0.23376552760601044, Accuracy: 0.875\n",
            "Step 17692/22500 - Loss: 0.02540704607963562, Accuracy: 1.0\n",
            "Step 17693/22500 - Loss: 0.36037808656692505, Accuracy: 0.875\n",
            "Step 17694/22500 - Loss: 0.09689772129058838, Accuracy: 1.0\n",
            "Step 17695/22500 - Loss: 0.016358476132154465, Accuracy: 1.0\n",
            "Step 17696/22500 - Loss: 0.026207249611616135, Accuracy: 1.0\n",
            "Step 17697/22500 - Loss: 0.15273529291152954, Accuracy: 0.875\n",
            "Step 17698/22500 - Loss: 0.07644418627023697, Accuracy: 1.0\n",
            "Step 17699/22500 - Loss: 0.006813517305999994, Accuracy: 1.0\n",
            "Step 17700/22500 - Loss: 0.1327107697725296, Accuracy: 1.0\n",
            "Step 17701/22500 - Loss: 0.047496963292360306, Accuracy: 1.0\n",
            "Step 17702/22500 - Loss: 0.46651095151901245, Accuracy: 0.75\n",
            "Step 17703/22500 - Loss: 0.07749010622501373, Accuracy: 1.0\n",
            "Step 17704/22500 - Loss: 0.035815853625535965, Accuracy: 1.0\n",
            "Step 17705/22500 - Loss: 0.028298260644078255, Accuracy: 1.0\n",
            "Step 17706/22500 - Loss: 0.26309826970100403, Accuracy: 0.875\n",
            "Step 17707/22500 - Loss: 0.0245822723954916, Accuracy: 1.0\n",
            "Step 17708/22500 - Loss: 0.11759158968925476, Accuracy: 0.875\n",
            "Step 17709/22500 - Loss: 0.032864078879356384, Accuracy: 1.0\n",
            "Step 17710/22500 - Loss: 0.20440076291561127, Accuracy: 0.875\n",
            "Step 17711/22500 - Loss: 0.16226555407047272, Accuracy: 0.875\n",
            "Step 17712/22500 - Loss: 0.0076096318662166595, Accuracy: 1.0\n",
            "Step 17713/22500 - Loss: 0.18029910326004028, Accuracy: 1.0\n",
            "Step 17714/22500 - Loss: 0.5613344311714172, Accuracy: 0.875\n",
            "Step 17715/22500 - Loss: 0.0773104876279831, Accuracy: 1.0\n",
            "Step 17716/22500 - Loss: 0.06814571470022202, Accuracy: 1.0\n",
            "Step 17717/22500 - Loss: 0.04079992324113846, Accuracy: 1.0\n",
            "Step 17718/22500 - Loss: 0.043258436024188995, Accuracy: 1.0\n",
            "Step 17719/22500 - Loss: 0.010161465033888817, Accuracy: 1.0\n",
            "Step 17720/22500 - Loss: 0.03575444594025612, Accuracy: 1.0\n",
            "Step 17721/22500 - Loss: 0.047141119837760925, Accuracy: 1.0\n",
            "Step 17722/22500 - Loss: 0.032805874943733215, Accuracy: 1.0\n",
            "Step 17723/22500 - Loss: 0.01629455015063286, Accuracy: 1.0\n",
            "Step 17724/22500 - Loss: 0.16392360627651215, Accuracy: 1.0\n",
            "Step 17725/22500 - Loss: 0.0892072543501854, Accuracy: 1.0\n",
            "Step 17726/22500 - Loss: 0.011028883047401905, Accuracy: 1.0\n",
            "Step 17727/22500 - Loss: 0.09280188381671906, Accuracy: 1.0\n",
            "Step 17728/22500 - Loss: 0.5653987526893616, Accuracy: 0.75\n",
            "Step 17729/22500 - Loss: 0.03170749172568321, Accuracy: 1.0\n",
            "Step 17730/22500 - Loss: 0.04603127762675285, Accuracy: 1.0\n",
            "Step 17731/22500 - Loss: 0.013262790627777576, Accuracy: 1.0\n",
            "Step 17732/22500 - Loss: 0.006268484052270651, Accuracy: 1.0\n",
            "Step 17733/22500 - Loss: 0.0651295930147171, Accuracy: 1.0\n",
            "Step 17734/22500 - Loss: 0.22080816328525543, Accuracy: 0.875\n",
            "Step 17735/22500 - Loss: 0.1256994754076004, Accuracy: 0.875\n",
            "Step 17736/22500 - Loss: 0.05884765088558197, Accuracy: 1.0\n",
            "Step 17737/22500 - Loss: 0.061229582875967026, Accuracy: 1.0\n",
            "Step 17738/22500 - Loss: 0.09185678511857986, Accuracy: 1.0\n",
            "Step 17739/22500 - Loss: 0.43352916836738586, Accuracy: 0.875\n",
            "Step 17740/22500 - Loss: 0.5217107534408569, Accuracy: 0.75\n",
            "Step 17741/22500 - Loss: 0.10024130344390869, Accuracy: 1.0\n",
            "Step 17742/22500 - Loss: 0.4240524470806122, Accuracy: 0.75\n",
            "Step 17743/22500 - Loss: 0.30216753482818604, Accuracy: 0.875\n",
            "Step 17744/22500 - Loss: 0.08956526964902878, Accuracy: 1.0\n",
            "Step 17745/22500 - Loss: 0.3971031606197357, Accuracy: 0.75\n",
            "Step 17746/22500 - Loss: 0.4521563947200775, Accuracy: 0.875\n",
            "Step 17747/22500 - Loss: 0.4990079402923584, Accuracy: 0.75\n",
            "Step 17748/22500 - Loss: 0.013751470483839512, Accuracy: 1.0\n",
            "Step 17749/22500 - Loss: 0.01572464220225811, Accuracy: 1.0\n",
            "Step 17750/22500 - Loss: 0.026293927803635597, Accuracy: 1.0\n",
            "Step 17751/22500 - Loss: 0.18516138195991516, Accuracy: 0.875\n",
            "Step 17752/22500 - Loss: 0.016919752582907677, Accuracy: 1.0\n",
            "Step 17753/22500 - Loss: 0.07330033928155899, Accuracy: 1.0\n",
            "Step 17754/22500 - Loss: 0.007336622569710016, Accuracy: 1.0\n",
            "Step 17755/22500 - Loss: 0.07853424549102783, Accuracy: 1.0\n",
            "Step 17756/22500 - Loss: 0.01678192801773548, Accuracy: 1.0\n",
            "Step 17757/22500 - Loss: 0.22591432929039001, Accuracy: 0.875\n",
            "Step 17758/22500 - Loss: 0.057887956500053406, Accuracy: 1.0\n",
            "Step 17759/22500 - Loss: 0.023908056318759918, Accuracy: 1.0\n",
            "Step 17760/22500 - Loss: 0.011980636045336723, Accuracy: 1.0\n",
            "Step 17761/22500 - Loss: 0.3509586751461029, Accuracy: 0.875\n",
            "Step 17762/22500 - Loss: 0.02206973358988762, Accuracy: 1.0\n",
            "Step 17763/22500 - Loss: 0.6663321852684021, Accuracy: 0.625\n",
            "Step 17764/22500 - Loss: 0.033012621104717255, Accuracy: 1.0\n",
            "Step 17765/22500 - Loss: 0.016836252063512802, Accuracy: 1.0\n",
            "Step 17766/22500 - Loss: 0.05051890015602112, Accuracy: 1.0\n",
            "Step 17767/22500 - Loss: 0.27890661358833313, Accuracy: 0.875\n",
            "Step 17768/22500 - Loss: 0.15944719314575195, Accuracy: 0.875\n",
            "Step 17769/22500 - Loss: 0.09091050922870636, Accuracy: 1.0\n",
            "Step 17770/22500 - Loss: 0.8142686486244202, Accuracy: 0.875\n",
            "Step 17771/22500 - Loss: 0.1489117592573166, Accuracy: 1.0\n",
            "Step 17772/22500 - Loss: 0.06825137883424759, Accuracy: 1.0\n",
            "Step 17773/22500 - Loss: 0.019483935087919235, Accuracy: 1.0\n",
            "Step 17774/22500 - Loss: 0.015122126787900925, Accuracy: 1.0\n",
            "Step 17775/22500 - Loss: 0.6852468848228455, Accuracy: 0.875\n",
            "Step 17776/22500 - Loss: 0.04427185282111168, Accuracy: 1.0\n",
            "Step 17777/22500 - Loss: 0.23747363686561584, Accuracy: 0.875\n",
            "Step 17778/22500 - Loss: 0.17761512100696564, Accuracy: 0.875\n",
            "Step 17779/22500 - Loss: 0.18344761431217194, Accuracy: 0.875\n",
            "Step 17780/22500 - Loss: 0.020114202052354813, Accuracy: 1.0\n",
            "Step 17781/22500 - Loss: 0.1965620219707489, Accuracy: 0.875\n",
            "Step 17782/22500 - Loss: 0.08578810095787048, Accuracy: 1.0\n",
            "Step 17783/22500 - Loss: 0.418900728225708, Accuracy: 0.75\n",
            "Step 17784/22500 - Loss: 0.04030852019786835, Accuracy: 1.0\n",
            "Step 17785/22500 - Loss: 0.013332809321582317, Accuracy: 1.0\n",
            "Step 17786/22500 - Loss: 0.08156909793615341, Accuracy: 1.0\n",
            "Step 17787/22500 - Loss: 0.012536331079900265, Accuracy: 1.0\n",
            "Step 17788/22500 - Loss: 0.26991376280784607, Accuracy: 0.875\n",
            "Step 17789/22500 - Loss: 0.4713193476200104, Accuracy: 0.875\n",
            "Step 17790/22500 - Loss: 0.047088608145713806, Accuracy: 1.0\n",
            "Step 17791/22500 - Loss: 1.0085017681121826, Accuracy: 0.75\n",
            "Step 17792/22500 - Loss: 0.22702258825302124, Accuracy: 0.875\n",
            "Step 17793/22500 - Loss: 0.015445119701325893, Accuracy: 1.0\n",
            "Step 17794/22500 - Loss: 0.3006088435649872, Accuracy: 0.875\n",
            "Step 17795/22500 - Loss: 0.061158161610364914, Accuracy: 1.0\n",
            "Step 17796/22500 - Loss: 0.0017013518372550607, Accuracy: 1.0\n",
            "Step 17797/22500 - Loss: 0.01619819365441799, Accuracy: 1.0\n",
            "Step 17798/22500 - Loss: 0.008484880439937115, Accuracy: 1.0\n",
            "Step 17799/22500 - Loss: 0.010979344137012959, Accuracy: 1.0\n",
            "Step 17800/22500 - Loss: 0.35152462124824524, Accuracy: 0.875\n",
            "Step 17801/22500 - Loss: 0.0771450623869896, Accuracy: 1.0\n",
            "Step 17802/22500 - Loss: 0.018626563251018524, Accuracy: 1.0\n",
            "Step 17803/22500 - Loss: 0.008221248164772987, Accuracy: 1.0\n",
            "Step 17804/22500 - Loss: 0.24817366898059845, Accuracy: 0.875\n",
            "Step 17805/22500 - Loss: 0.011588504537940025, Accuracy: 1.0\n",
            "Step 17806/22500 - Loss: 0.03032269887626171, Accuracy: 1.0\n",
            "Step 17807/22500 - Loss: 0.009123425930738449, Accuracy: 1.0\n",
            "Step 17808/22500 - Loss: 0.007774059660732746, Accuracy: 1.0\n",
            "Step 17809/22500 - Loss: 0.1945400834083557, Accuracy: 0.875\n",
            "Step 17810/22500 - Loss: 0.37502989172935486, Accuracy: 0.75\n",
            "Step 17811/22500 - Loss: 0.38001126050949097, Accuracy: 0.875\n",
            "Step 17812/22500 - Loss: 0.002955072559416294, Accuracy: 1.0\n",
            "Step 17813/22500 - Loss: 0.14566943049430847, Accuracy: 0.875\n",
            "Step 17814/22500 - Loss: 0.21168170869350433, Accuracy: 0.875\n",
            "Step 17815/22500 - Loss: 0.037835169583559036, Accuracy: 1.0\n",
            "Step 17816/22500 - Loss: 0.021039240062236786, Accuracy: 1.0\n",
            "Step 17817/22500 - Loss: 0.0786912590265274, Accuracy: 1.0\n",
            "Step 17818/22500 - Loss: 0.30056118965148926, Accuracy: 0.875\n",
            "Step 17819/22500 - Loss: 0.2308601438999176, Accuracy: 0.875\n",
            "Step 17820/22500 - Loss: 0.13504081964492798, Accuracy: 0.875\n",
            "Step 17821/22500 - Loss: 0.1309112310409546, Accuracy: 0.875\n",
            "Step 17822/22500 - Loss: 0.061023835092782974, Accuracy: 1.0\n",
            "Step 17823/22500 - Loss: 0.09602612257003784, Accuracy: 1.0\n",
            "Step 17824/22500 - Loss: 0.007699746638536453, Accuracy: 1.0\n",
            "Step 17825/22500 - Loss: 0.011175721883773804, Accuracy: 1.0\n",
            "Step 17826/22500 - Loss: 0.14296476542949677, Accuracy: 0.875\n",
            "Step 17827/22500 - Loss: 0.06609764695167542, Accuracy: 1.0\n",
            "Step 17828/22500 - Loss: 0.29783281683921814, Accuracy: 0.875\n",
            "Step 17829/22500 - Loss: 0.029648836702108383, Accuracy: 1.0\n",
            "Step 17830/22500 - Loss: 0.017042171210050583, Accuracy: 1.0\n",
            "Step 17831/22500 - Loss: 0.044944651424884796, Accuracy: 1.0\n",
            "Step 17832/22500 - Loss: 0.03798043727874756, Accuracy: 1.0\n",
            "Step 17833/22500 - Loss: 0.1588391661643982, Accuracy: 0.875\n",
            "Step 17834/22500 - Loss: 0.1870778203010559, Accuracy: 1.0\n",
            "Step 17835/22500 - Loss: 0.043193306773900986, Accuracy: 1.0\n",
            "Step 17836/22500 - Loss: 0.08642271161079407, Accuracy: 1.0\n",
            "Step 17837/22500 - Loss: 0.5760444402694702, Accuracy: 0.75\n",
            "Step 17838/22500 - Loss: 0.09676377475261688, Accuracy: 1.0\n",
            "Step 17839/22500 - Loss: 0.06961794197559357, Accuracy: 1.0\n",
            "Step 17840/22500 - Loss: 0.02277415245771408, Accuracy: 1.0\n",
            "Step 17841/22500 - Loss: 0.02262556180357933, Accuracy: 1.0\n",
            "Step 17842/22500 - Loss: 0.3818744719028473, Accuracy: 0.75\n",
            "Step 17843/22500 - Loss: 0.09720578789710999, Accuracy: 1.0\n",
            "Step 17844/22500 - Loss: 0.5076457262039185, Accuracy: 0.875\n",
            "Step 17845/22500 - Loss: 0.46098390221595764, Accuracy: 0.875\n",
            "Step 17846/22500 - Loss: 0.09783895313739777, Accuracy: 1.0\n",
            "Step 17847/22500 - Loss: 0.16165165603160858, Accuracy: 0.875\n",
            "Step 17848/22500 - Loss: 0.028617750853300095, Accuracy: 1.0\n",
            "Step 17849/22500 - Loss: 0.2805159389972687, Accuracy: 0.875\n",
            "Step 17850/22500 - Loss: 0.3715724050998688, Accuracy: 0.75\n",
            "Step 17851/22500 - Loss: 0.2405712604522705, Accuracy: 0.875\n",
            "Step 17852/22500 - Loss: 0.05002082511782646, Accuracy: 1.0\n",
            "Step 17853/22500 - Loss: 0.026639362797141075, Accuracy: 1.0\n",
            "Step 17854/22500 - Loss: 0.02792033553123474, Accuracy: 1.0\n",
            "Step 17855/22500 - Loss: 0.12152256071567535, Accuracy: 0.875\n",
            "Step 17856/22500 - Loss: 0.014026900753378868, Accuracy: 1.0\n",
            "Step 17857/22500 - Loss: 0.134623721241951, Accuracy: 1.0\n",
            "Step 17858/22500 - Loss: 0.02593747340142727, Accuracy: 1.0\n",
            "Step 17859/22500 - Loss: 0.05672239884734154, Accuracy: 1.0\n",
            "Step 17860/22500 - Loss: 0.08433225750923157, Accuracy: 1.0\n",
            "Step 17861/22500 - Loss: 0.03004363179206848, Accuracy: 1.0\n",
            "Step 17862/22500 - Loss: 0.1828261911869049, Accuracy: 0.875\n",
            "Step 17863/22500 - Loss: 0.1427391916513443, Accuracy: 1.0\n",
            "Step 17864/22500 - Loss: 0.574215829372406, Accuracy: 0.875\n",
            "Step 17865/22500 - Loss: 0.0396190881729126, Accuracy: 1.0\n",
            "Step 17866/22500 - Loss: 0.010762513615190983, Accuracy: 1.0\n",
            "Step 17867/22500 - Loss: 0.054951805621385574, Accuracy: 1.0\n",
            "Step 17868/22500 - Loss: 0.3350302577018738, Accuracy: 0.875\n",
            "Step 17869/22500 - Loss: 0.015543018467724323, Accuracy: 1.0\n",
            "Step 17870/22500 - Loss: 0.5283768177032471, Accuracy: 0.625\n",
            "Step 17871/22500 - Loss: 0.02920161560177803, Accuracy: 1.0\n",
            "Step 17872/22500 - Loss: 0.010508367791771889, Accuracy: 1.0\n",
            "Step 17873/22500 - Loss: 0.10130509734153748, Accuracy: 1.0\n",
            "Step 17874/22500 - Loss: 0.09918702393770218, Accuracy: 1.0\n",
            "Step 17875/22500 - Loss: 0.028628794476389885, Accuracy: 1.0\n",
            "Step 17876/22500 - Loss: 0.010773533023893833, Accuracy: 1.0\n",
            "Step 17877/22500 - Loss: 0.018423184752464294, Accuracy: 1.0\n",
            "Step 17878/22500 - Loss: 0.11378894001245499, Accuracy: 0.875\n",
            "Step 17879/22500 - Loss: 0.022187096998095512, Accuracy: 1.0\n",
            "Step 17880/22500 - Loss: 0.25346413254737854, Accuracy: 0.875\n",
            "Step 17881/22500 - Loss: 0.09629223495721817, Accuracy: 1.0\n",
            "Step 17882/22500 - Loss: 0.09437686949968338, Accuracy: 1.0\n",
            "Step 17883/22500 - Loss: 0.04587110877037048, Accuracy: 1.0\n",
            "Step 17884/22500 - Loss: 0.025462567806243896, Accuracy: 1.0\n",
            "Step 17885/22500 - Loss: 0.11671321094036102, Accuracy: 0.875\n",
            "Step 17886/22500 - Loss: 0.028930436819791794, Accuracy: 1.0\n",
            "Step 17887/22500 - Loss: 0.24017846584320068, Accuracy: 0.875\n",
            "Step 17888/22500 - Loss: 0.3227139413356781, Accuracy: 0.875\n",
            "Step 17889/22500 - Loss: 0.08603416383266449, Accuracy: 1.0\n",
            "Step 17890/22500 - Loss: 0.09034325927495956, Accuracy: 1.0\n",
            "Step 17891/22500 - Loss: 0.3614419400691986, Accuracy: 0.75\n",
            "Step 17892/22500 - Loss: 0.12787804007530212, Accuracy: 0.875\n",
            "Step 17893/22500 - Loss: 0.03309427201747894, Accuracy: 1.0\n",
            "Step 17894/22500 - Loss: 0.01946132257580757, Accuracy: 1.0\n",
            "Step 17895/22500 - Loss: 0.04396693781018257, Accuracy: 1.0\n",
            "Step 17896/22500 - Loss: 0.06364655494689941, Accuracy: 1.0\n",
            "Step 17897/22500 - Loss: 0.057067643851041794, Accuracy: 1.0\n",
            "Step 17898/22500 - Loss: 0.021820785477757454, Accuracy: 1.0\n",
            "Step 17899/22500 - Loss: 0.4264230728149414, Accuracy: 0.75\n",
            "Step 17900/22500 - Loss: 0.009217861108481884, Accuracy: 1.0\n",
            "Step 17901/22500 - Loss: 0.2887430787086487, Accuracy: 0.75\n",
            "Step 17902/22500 - Loss: 0.034220777451992035, Accuracy: 1.0\n",
            "Step 17903/22500 - Loss: 0.09308165311813354, Accuracy: 0.875\n",
            "Step 17904/22500 - Loss: 0.20159579813480377, Accuracy: 0.875\n",
            "Step 17905/22500 - Loss: 0.3058794140815735, Accuracy: 0.875\n",
            "Step 17906/22500 - Loss: 0.1990688592195511, Accuracy: 0.875\n",
            "Step 17907/22500 - Loss: 0.013423873111605644, Accuracy: 1.0\n",
            "Step 17908/22500 - Loss: 0.26347529888153076, Accuracy: 0.875\n",
            "Step 17909/22500 - Loss: 0.004387897439301014, Accuracy: 1.0\n",
            "Step 17910/22500 - Loss: 0.4613887667655945, Accuracy: 0.875\n",
            "Step 17911/22500 - Loss: 0.033781781792640686, Accuracy: 1.0\n",
            "Step 17912/22500 - Loss: 0.014164017513394356, Accuracy: 1.0\n",
            "Step 17913/22500 - Loss: 0.1402016133069992, Accuracy: 0.875\n",
            "Step 17914/22500 - Loss: 0.2351788878440857, Accuracy: 0.875\n",
            "Step 17915/22500 - Loss: 0.03282616287469864, Accuracy: 1.0\n",
            "Step 17916/22500 - Loss: 0.024323761463165283, Accuracy: 1.0\n",
            "Step 17917/22500 - Loss: 0.026683950796723366, Accuracy: 1.0\n",
            "Step 17918/22500 - Loss: 0.014549887739121914, Accuracy: 1.0\n",
            "Step 17919/22500 - Loss: 0.4246653616428375, Accuracy: 0.875\n",
            "Step 17920/22500 - Loss: 0.016334906220436096, Accuracy: 1.0\n",
            "Step 17921/22500 - Loss: 0.030694663524627686, Accuracy: 1.0\n",
            "Step 17922/22500 - Loss: 0.17222408950328827, Accuracy: 0.875\n",
            "Step 17923/22500 - Loss: 0.718205988407135, Accuracy: 0.75\n",
            "Step 17924/22500 - Loss: 0.45830583572387695, Accuracy: 0.875\n",
            "Step 17925/22500 - Loss: 0.066609226167202, Accuracy: 1.0\n",
            "Step 17926/22500 - Loss: 1.0503227710723877, Accuracy: 0.625\n",
            "Step 17927/22500 - Loss: 0.04256425425410271, Accuracy: 1.0\n",
            "Step 17928/22500 - Loss: 0.010051277466118336, Accuracy: 1.0\n",
            "Step 17929/22500 - Loss: 0.09409071505069733, Accuracy: 1.0\n",
            "Step 17930/22500 - Loss: 0.0026685555931180716, Accuracy: 1.0\n",
            "Step 17931/22500 - Loss: 0.057553790509700775, Accuracy: 1.0\n",
            "Step 17932/22500 - Loss: 0.12822593748569489, Accuracy: 1.0\n",
            "Step 17933/22500 - Loss: 0.062350764870643616, Accuracy: 1.0\n",
            "Step 17934/22500 - Loss: 0.05319564789533615, Accuracy: 1.0\n",
            "Step 17935/22500 - Loss: 0.010952901095151901, Accuracy: 1.0\n",
            "Step 17936/22500 - Loss: 0.48420286178588867, Accuracy: 0.875\n",
            "Step 17937/22500 - Loss: 0.03194247931241989, Accuracy: 1.0\n",
            "Step 17938/22500 - Loss: 0.0634303092956543, Accuracy: 1.0\n",
            "Step 17939/22500 - Loss: 0.09421318769454956, Accuracy: 1.0\n",
            "Step 17940/22500 - Loss: 0.09200923889875412, Accuracy: 0.875\n",
            "Step 17941/22500 - Loss: 0.22656822204589844, Accuracy: 0.875\n",
            "Step 17942/22500 - Loss: 0.08626819401979446, Accuracy: 1.0\n",
            "Step 17943/22500 - Loss: 0.1647280603647232, Accuracy: 0.875\n",
            "Step 17944/22500 - Loss: 0.3541378080844879, Accuracy: 0.875\n",
            "Step 17945/22500 - Loss: 0.08540315181016922, Accuracy: 1.0\n",
            "Step 17946/22500 - Loss: 0.008469939231872559, Accuracy: 1.0\n",
            "Step 17947/22500 - Loss: 0.13604971766471863, Accuracy: 1.0\n",
            "Step 17948/22500 - Loss: 0.17649424076080322, Accuracy: 0.875\n",
            "Step 17949/22500 - Loss: 0.06822460144758224, Accuracy: 1.0\n",
            "Step 17950/22500 - Loss: 0.4127607047557831, Accuracy: 0.875\n",
            "Step 17951/22500 - Loss: 0.32042163610458374, Accuracy: 0.875\n",
            "Step 17952/22500 - Loss: 0.0030968862120062113, Accuracy: 1.0\n",
            "Step 17953/22500 - Loss: 0.014952843077480793, Accuracy: 1.0\n",
            "Step 17954/22500 - Loss: 0.4406454563140869, Accuracy: 0.875\n",
            "Step 17955/22500 - Loss: 0.367574006319046, Accuracy: 0.875\n",
            "Step 17956/22500 - Loss: 0.040766023099422455, Accuracy: 1.0\n",
            "Step 17957/22500 - Loss: 0.19533474743366241, Accuracy: 1.0\n",
            "Step 17958/22500 - Loss: 0.05137016251683235, Accuracy: 1.0\n",
            "Step 17959/22500 - Loss: 0.036478761583566666, Accuracy: 1.0\n",
            "Step 17960/22500 - Loss: 0.011792772449553013, Accuracy: 1.0\n",
            "Step 17961/22500 - Loss: 0.19180047512054443, Accuracy: 0.875\n",
            "Step 17962/22500 - Loss: 0.03674008324742317, Accuracy: 1.0\n",
            "Step 17963/22500 - Loss: 0.03518795967102051, Accuracy: 1.0\n",
            "Step 17964/22500 - Loss: 0.2109796553850174, Accuracy: 0.875\n",
            "Step 17965/22500 - Loss: 0.14938417077064514, Accuracy: 1.0\n",
            "Step 17966/22500 - Loss: 0.005872686859220266, Accuracy: 1.0\n",
            "Step 17967/22500 - Loss: 0.14940664172172546, Accuracy: 0.875\n",
            "Step 17968/22500 - Loss: 0.020284291356801987, Accuracy: 1.0\n",
            "Step 17969/22500 - Loss: 0.009695024229586124, Accuracy: 1.0\n",
            "Step 17970/22500 - Loss: 0.02341543510556221, Accuracy: 1.0\n",
            "Step 17971/22500 - Loss: 0.007958791218698025, Accuracy: 1.0\n",
            "Step 17972/22500 - Loss: 0.005946693010628223, Accuracy: 1.0\n",
            "Step 17973/22500 - Loss: 0.4743490517139435, Accuracy: 0.875\n",
            "Step 17974/22500 - Loss: 0.017060156911611557, Accuracy: 1.0\n",
            "Step 17975/22500 - Loss: 0.03641887381672859, Accuracy: 1.0\n",
            "Step 17976/22500 - Loss: 0.16349001228809357, Accuracy: 0.875\n",
            "Step 17977/22500 - Loss: 0.16783921420574188, Accuracy: 0.875\n",
            "Step 17978/22500 - Loss: 0.07748833298683167, Accuracy: 1.0\n",
            "Step 17979/22500 - Loss: 0.05477609857916832, Accuracy: 1.0\n",
            "Step 17980/22500 - Loss: 0.3344072997570038, Accuracy: 0.875\n",
            "Step 17981/22500 - Loss: 0.12726710736751556, Accuracy: 0.875\n",
            "Step 17982/22500 - Loss: 0.21680358052253723, Accuracy: 0.875\n",
            "Step 17983/22500 - Loss: 0.026845566928386688, Accuracy: 1.0\n",
            "Step 17984/22500 - Loss: 0.025280674919486046, Accuracy: 1.0\n",
            "Step 17985/22500 - Loss: 0.05926555022597313, Accuracy: 1.0\n",
            "Step 17986/22500 - Loss: 0.2744963467121124, Accuracy: 0.875\n",
            "Step 17987/22500 - Loss: 0.05292736366391182, Accuracy: 1.0\n",
            "Step 17988/22500 - Loss: 0.29145723581314087, Accuracy: 0.75\n",
            "Step 17989/22500 - Loss: 0.4722604751586914, Accuracy: 0.75\n",
            "Step 17990/22500 - Loss: 0.05062108486890793, Accuracy: 1.0\n",
            "Step 17991/22500 - Loss: 0.08105650544166565, Accuracy: 1.0\n",
            "Step 17992/22500 - Loss: 0.05262616276741028, Accuracy: 1.0\n",
            "Step 17993/22500 - Loss: 0.02676030807197094, Accuracy: 1.0\n",
            "Step 17994/22500 - Loss: 0.1640569418668747, Accuracy: 1.0\n",
            "Step 17995/22500 - Loss: 0.6300098896026611, Accuracy: 0.875\n",
            "Step 17996/22500 - Loss: 0.1560746133327484, Accuracy: 0.875\n",
            "Step 17997/22500 - Loss: 0.20503218472003937, Accuracy: 0.875\n",
            "Step 17998/22500 - Loss: 0.09955187141895294, Accuracy: 1.0\n",
            "Step 17999/22500 - Loss: 0.014869560487568378, Accuracy: 1.0\n",
            "Step 18000/22500 - Loss: 0.08913388848304749, Accuracy: 1.0\n",
            "Step 18001/22500 - Loss: 0.5420558452606201, Accuracy: 0.875\n",
            "Step 18002/22500 - Loss: 0.5791140794754028, Accuracy: 0.625\n",
            "Step 18003/22500 - Loss: 0.044419147074222565, Accuracy: 1.0\n",
            "Step 18004/22500 - Loss: 0.07893210649490356, Accuracy: 1.0\n",
            "Step 18005/22500 - Loss: 0.3639959394931793, Accuracy: 0.875\n",
            "Step 18006/22500 - Loss: 0.06941155344247818, Accuracy: 1.0\n",
            "Step 18007/22500 - Loss: 0.02221663109958172, Accuracy: 1.0\n",
            "Step 18008/22500 - Loss: 0.24478565156459808, Accuracy: 0.875\n",
            "Step 18009/22500 - Loss: 0.11775793880224228, Accuracy: 1.0\n",
            "Step 18010/22500 - Loss: 0.6593925356864929, Accuracy: 0.875\n",
            "Step 18011/22500 - Loss: 0.3195003271102905, Accuracy: 0.75\n",
            "Step 18012/22500 - Loss: 0.20160970091819763, Accuracy: 0.875\n",
            "Step 18013/22500 - Loss: 0.00706118531525135, Accuracy: 1.0\n",
            "Step 18014/22500 - Loss: 0.0535251647233963, Accuracy: 1.0\n",
            "Step 18015/22500 - Loss: 0.026738345623016357, Accuracy: 1.0\n",
            "Step 18016/22500 - Loss: 0.03724326938390732, Accuracy: 1.0\n",
            "Step 18017/22500 - Loss: 0.025870153680443764, Accuracy: 1.0\n",
            "Step 18018/22500 - Loss: 0.029874751344323158, Accuracy: 1.0\n",
            "Step 18019/22500 - Loss: 0.1047719269990921, Accuracy: 1.0\n",
            "Step 18020/22500 - Loss: 0.08001819998025894, Accuracy: 1.0\n",
            "Step 18021/22500 - Loss: 0.22754696011543274, Accuracy: 0.875\n",
            "Step 18022/22500 - Loss: 0.1648021638393402, Accuracy: 1.0\n",
            "Step 18023/22500 - Loss: 0.007746904622763395, Accuracy: 1.0\n",
            "Step 18024/22500 - Loss: 0.03787992149591446, Accuracy: 1.0\n",
            "Step 18025/22500 - Loss: 0.010455194860696793, Accuracy: 1.0\n",
            "Step 18026/22500 - Loss: 0.42941513657569885, Accuracy: 0.75\n",
            "Step 18027/22500 - Loss: 0.04100647196173668, Accuracy: 1.0\n",
            "Step 18028/22500 - Loss: 0.07147224247455597, Accuracy: 1.0\n",
            "Step 18029/22500 - Loss: 0.13482515513896942, Accuracy: 1.0\n",
            "Step 18030/22500 - Loss: 0.23456956446170807, Accuracy: 0.875\n",
            "Step 18031/22500 - Loss: 0.024887345731258392, Accuracy: 1.0\n",
            "Step 18032/22500 - Loss: 0.14116314053535461, Accuracy: 0.875\n",
            "Step 18033/22500 - Loss: 0.07004651427268982, Accuracy: 1.0\n",
            "Step 18034/22500 - Loss: 0.01543751172721386, Accuracy: 1.0\n",
            "Step 18035/22500 - Loss: 0.11379384249448776, Accuracy: 1.0\n",
            "Step 18036/22500 - Loss: 0.04618221893906593, Accuracy: 1.0\n",
            "Step 18037/22500 - Loss: 0.11337705701589584, Accuracy: 1.0\n",
            "Step 18038/22500 - Loss: 0.6645671725273132, Accuracy: 0.875\n",
            "Step 18039/22500 - Loss: 0.07944446057081223, Accuracy: 1.0\n",
            "Step 18040/22500 - Loss: 0.0366208590567112, Accuracy: 1.0\n",
            "Step 18041/22500 - Loss: 0.09685024619102478, Accuracy: 0.875\n",
            "Step 18042/22500 - Loss: 0.15633955597877502, Accuracy: 0.875\n",
            "Step 18043/22500 - Loss: 0.030513713136315346, Accuracy: 1.0\n",
            "Step 18044/22500 - Loss: 0.03337671607732773, Accuracy: 1.0\n",
            "Step 18045/22500 - Loss: 0.1108611673116684, Accuracy: 0.875\n",
            "Step 18046/22500 - Loss: 0.6444343328475952, Accuracy: 0.75\n",
            "Step 18047/22500 - Loss: 0.04752308502793312, Accuracy: 1.0\n",
            "Step 18048/22500 - Loss: 0.19428279995918274, Accuracy: 0.875\n",
            "Step 18049/22500 - Loss: 0.17848104238510132, Accuracy: 0.875\n",
            "Step 18050/22500 - Loss: 0.05973219498991966, Accuracy: 1.0\n",
            "Step 18051/22500 - Loss: 0.3867388367652893, Accuracy: 0.875\n",
            "Step 18052/22500 - Loss: 0.19204629957675934, Accuracy: 0.875\n",
            "Step 18053/22500 - Loss: 0.0288776233792305, Accuracy: 1.0\n",
            "Step 18054/22500 - Loss: 0.010386181063950062, Accuracy: 1.0\n",
            "Step 18055/22500 - Loss: 0.12779344618320465, Accuracy: 0.875\n",
            "Step 18056/22500 - Loss: 0.003664350602775812, Accuracy: 1.0\n",
            "Step 18057/22500 - Loss: 0.02102808654308319, Accuracy: 1.0\n",
            "Step 18058/22500 - Loss: 0.006490382365882397, Accuracy: 1.0\n",
            "Step 18059/22500 - Loss: 0.009950337000191212, Accuracy: 1.0\n",
            "Step 18060/22500 - Loss: 0.05096156895160675, Accuracy: 1.0\n",
            "Step 18061/22500 - Loss: 0.33944422006607056, Accuracy: 0.75\n",
            "Step 18062/22500 - Loss: 0.23646695911884308, Accuracy: 0.875\n",
            "Step 18063/22500 - Loss: 0.03203875944018364, Accuracy: 1.0\n",
            "Step 18064/22500 - Loss: 0.3173655569553375, Accuracy: 0.875\n",
            "Step 18065/22500 - Loss: 0.06213323771953583, Accuracy: 1.0\n",
            "Step 18066/22500 - Loss: 0.04341144859790802, Accuracy: 1.0\n",
            "Step 18067/22500 - Loss: 0.016340244561433792, Accuracy: 1.0\n",
            "Step 18068/22500 - Loss: 0.11549708992242813, Accuracy: 0.875\n",
            "Step 18069/22500 - Loss: 0.021038219332695007, Accuracy: 1.0\n",
            "Step 18070/22500 - Loss: 0.19864891469478607, Accuracy: 1.0\n",
            "Step 18071/22500 - Loss: 0.026873666793107986, Accuracy: 1.0\n",
            "Step 18072/22500 - Loss: 0.10653527081012726, Accuracy: 1.0\n",
            "Step 18073/22500 - Loss: 0.11883639544248581, Accuracy: 1.0\n",
            "Step 18074/22500 - Loss: 0.010958594270050526, Accuracy: 1.0\n",
            "Step 18075/22500 - Loss: 0.027806302532553673, Accuracy: 1.0\n",
            "Step 18076/22500 - Loss: 0.007813225500285625, Accuracy: 1.0\n",
            "Step 18077/22500 - Loss: 0.09002354741096497, Accuracy: 1.0\n",
            "Step 18078/22500 - Loss: 0.0717928409576416, Accuracy: 1.0\n",
            "Step 18079/22500 - Loss: 0.030279237776994705, Accuracy: 1.0\n",
            "Step 18080/22500 - Loss: 0.08798494935035706, Accuracy: 1.0\n",
            "Step 18081/22500 - Loss: 0.13207708299160004, Accuracy: 0.875\n",
            "Step 18082/22500 - Loss: 0.03340129554271698, Accuracy: 1.0\n",
            "Step 18083/22500 - Loss: 0.035021692514419556, Accuracy: 1.0\n",
            "Step 18084/22500 - Loss: 0.04006103426218033, Accuracy: 1.0\n",
            "Step 18085/22500 - Loss: 0.23406267166137695, Accuracy: 0.875\n",
            "Step 18086/22500 - Loss: 0.0538816899061203, Accuracy: 1.0\n",
            "Step 18087/22500 - Loss: 0.017129147425293922, Accuracy: 1.0\n",
            "Step 18088/22500 - Loss: 0.014231843873858452, Accuracy: 1.0\n",
            "Step 18089/22500 - Loss: 0.02369912527501583, Accuracy: 1.0\n",
            "Step 18090/22500 - Loss: 0.21423675119876862, Accuracy: 0.875\n",
            "Step 18091/22500 - Loss: 0.1876843422651291, Accuracy: 0.875\n",
            "Step 18092/22500 - Loss: 0.008654065430164337, Accuracy: 1.0\n",
            "Step 18093/22500 - Loss: 0.01882380060851574, Accuracy: 1.0\n",
            "Step 18094/22500 - Loss: 0.47790807485580444, Accuracy: 0.75\n",
            "Step 18095/22500 - Loss: 0.11199334263801575, Accuracy: 0.875\n",
            "Step 18096/22500 - Loss: 0.2583349347114563, Accuracy: 0.875\n",
            "Step 18097/22500 - Loss: 0.09646382182836533, Accuracy: 1.0\n",
            "Step 18098/22500 - Loss: 0.24516336619853973, Accuracy: 0.875\n",
            "Step 18099/22500 - Loss: 0.014842812903225422, Accuracy: 1.0\n",
            "Step 18100/22500 - Loss: 0.0723470002412796, Accuracy: 1.0\n",
            "Step 18101/22500 - Loss: 0.005605069454759359, Accuracy: 1.0\n",
            "Step 18102/22500 - Loss: 0.2832483649253845, Accuracy: 0.75\n",
            "Step 18103/22500 - Loss: 0.1366381198167801, Accuracy: 0.875\n",
            "Step 18104/22500 - Loss: 0.5832201838493347, Accuracy: 0.875\n",
            "Step 18105/22500 - Loss: 0.0460236519575119, Accuracy: 1.0\n",
            "Step 18106/22500 - Loss: 0.14542709290981293, Accuracy: 1.0\n",
            "Step 18107/22500 - Loss: 0.02910505421459675, Accuracy: 1.0\n",
            "Step 18108/22500 - Loss: 0.03516798093914986, Accuracy: 1.0\n",
            "Step 18109/22500 - Loss: 0.016405414789915085, Accuracy: 1.0\n",
            "Step 18110/22500 - Loss: 0.0512549951672554, Accuracy: 1.0\n",
            "Step 18111/22500 - Loss: 0.07217276841402054, Accuracy: 1.0\n",
            "Step 18112/22500 - Loss: 0.0970439687371254, Accuracy: 1.0\n",
            "Step 18113/22500 - Loss: 0.17586691677570343, Accuracy: 0.875\n",
            "Step 18114/22500 - Loss: 0.010304417461156845, Accuracy: 1.0\n",
            "Step 18115/22500 - Loss: 0.015380951575934887, Accuracy: 1.0\n",
            "Step 18116/22500 - Loss: 0.029470941051840782, Accuracy: 1.0\n",
            "Step 18117/22500 - Loss: 0.05000564455986023, Accuracy: 1.0\n",
            "Step 18118/22500 - Loss: 0.0267688799649477, Accuracy: 1.0\n",
            "Step 18119/22500 - Loss: 0.06475386023521423, Accuracy: 1.0\n",
            "Step 18120/22500 - Loss: 0.00753177423030138, Accuracy: 1.0\n",
            "Step 18121/22500 - Loss: 0.01252307090908289, Accuracy: 1.0\n",
            "Step 18122/22500 - Loss: 0.02492671087384224, Accuracy: 1.0\n",
            "Step 18123/22500 - Loss: 0.4260677099227905, Accuracy: 0.75\n",
            "Step 18124/22500 - Loss: 0.013821872882544994, Accuracy: 1.0\n",
            "Step 18125/22500 - Loss: 0.031280454248189926, Accuracy: 1.0\n",
            "Step 18126/22500 - Loss: 0.06164928525686264, Accuracy: 1.0\n",
            "Step 18127/22500 - Loss: 0.047511521726846695, Accuracy: 1.0\n",
            "Step 18128/22500 - Loss: 0.3183528482913971, Accuracy: 0.875\n",
            "Step 18129/22500 - Loss: 0.017499780282378197, Accuracy: 1.0\n",
            "Step 18130/22500 - Loss: 0.05450797826051712, Accuracy: 1.0\n",
            "Step 18131/22500 - Loss: 0.02015575021505356, Accuracy: 1.0\n",
            "Step 18132/22500 - Loss: 0.15452870726585388, Accuracy: 1.0\n",
            "Step 18133/22500 - Loss: 0.03784266486763954, Accuracy: 1.0\n",
            "Step 18134/22500 - Loss: 0.004062139429152012, Accuracy: 1.0\n",
            "Step 18135/22500 - Loss: 0.029191048815846443, Accuracy: 1.0\n",
            "Step 18136/22500 - Loss: 0.20536527037620544, Accuracy: 0.875\n",
            "Step 18137/22500 - Loss: 0.028650397434830666, Accuracy: 1.0\n",
            "Step 18138/22500 - Loss: 0.06775662302970886, Accuracy: 1.0\n",
            "Step 18139/22500 - Loss: 0.34083110094070435, Accuracy: 0.875\n",
            "Step 18140/22500 - Loss: 0.6105303764343262, Accuracy: 0.75\n",
            "Step 18141/22500 - Loss: 0.3743492662906647, Accuracy: 0.875\n",
            "Step 18142/22500 - Loss: 0.009846597909927368, Accuracy: 1.0\n",
            "Step 18143/22500 - Loss: 0.13939079642295837, Accuracy: 0.875\n",
            "Step 18144/22500 - Loss: 0.07498861104249954, Accuracy: 1.0\n",
            "Step 18145/22500 - Loss: 0.027059057727456093, Accuracy: 1.0\n",
            "Step 18146/22500 - Loss: 0.2588411569595337, Accuracy: 0.875\n",
            "Step 18147/22500 - Loss: 0.05842988193035126, Accuracy: 1.0\n",
            "Step 18148/22500 - Loss: 0.08153755962848663, Accuracy: 1.0\n",
            "Step 18149/22500 - Loss: 0.030300581827759743, Accuracy: 1.0\n",
            "Step 18150/22500 - Loss: 0.011897677555680275, Accuracy: 1.0\n",
            "Step 18151/22500 - Loss: 0.18512177467346191, Accuracy: 0.875\n",
            "Step 18152/22500 - Loss: 0.10295691341161728, Accuracy: 1.0\n",
            "Step 18153/22500 - Loss: 0.05303545296192169, Accuracy: 1.0\n",
            "Step 18154/22500 - Loss: 0.09547785669565201, Accuracy: 1.0\n",
            "Step 18155/22500 - Loss: 0.008427892811596394, Accuracy: 1.0\n",
            "Step 18156/22500 - Loss: 0.0505048893392086, Accuracy: 1.0\n",
            "Step 18157/22500 - Loss: 0.47329413890838623, Accuracy: 0.875\n",
            "Step 18158/22500 - Loss: 0.8340839743614197, Accuracy: 0.75\n",
            "Step 18159/22500 - Loss: 0.27175474166870117, Accuracy: 0.75\n",
            "Step 18160/22500 - Loss: 0.1893462836742401, Accuracy: 0.875\n",
            "Step 18161/22500 - Loss: 0.023951154202222824, Accuracy: 1.0\n",
            "Step 18162/22500 - Loss: 0.001521775615401566, Accuracy: 1.0\n",
            "Step 18163/22500 - Loss: 0.03787897899746895, Accuracy: 1.0\n",
            "Step 18164/22500 - Loss: 0.23891694843769073, Accuracy: 0.875\n",
            "Step 18165/22500 - Loss: 0.010648969560861588, Accuracy: 1.0\n",
            "Step 18166/22500 - Loss: 0.7855806946754456, Accuracy: 0.75\n",
            "Step 18167/22500 - Loss: 0.024869075044989586, Accuracy: 1.0\n",
            "Step 18168/22500 - Loss: 0.025384947657585144, Accuracy: 1.0\n",
            "Step 18169/22500 - Loss: 0.11105334013700485, Accuracy: 0.875\n",
            "Step 18170/22500 - Loss: 0.06955020129680634, Accuracy: 1.0\n",
            "Step 18171/22500 - Loss: 0.024598687887191772, Accuracy: 1.0\n",
            "Step 18172/22500 - Loss: 0.020987048745155334, Accuracy: 1.0\n",
            "Step 18173/22500 - Loss: 0.03078388050198555, Accuracy: 1.0\n",
            "Step 18174/22500 - Loss: 0.5374259948730469, Accuracy: 0.75\n",
            "Step 18175/22500 - Loss: 0.024908263236284256, Accuracy: 1.0\n",
            "Step 18176/22500 - Loss: 0.054046403616666794, Accuracy: 1.0\n",
            "Step 18177/22500 - Loss: 0.2379446029663086, Accuracy: 1.0\n",
            "Step 18178/22500 - Loss: 0.11155048757791519, Accuracy: 1.0\n",
            "Step 18179/22500 - Loss: 0.27425244450569153, Accuracy: 0.875\n",
            "Step 18180/22500 - Loss: 0.010995417833328247, Accuracy: 1.0\n",
            "Step 18181/22500 - Loss: 0.1620960682630539, Accuracy: 0.875\n",
            "Step 18182/22500 - Loss: 0.07465242594480515, Accuracy: 1.0\n",
            "Step 18183/22500 - Loss: 0.01731778308749199, Accuracy: 1.0\n",
            "Step 18184/22500 - Loss: 0.39160317182540894, Accuracy: 0.875\n",
            "Step 18185/22500 - Loss: 0.02111327089369297, Accuracy: 1.0\n",
            "Step 18186/22500 - Loss: 0.006578205619007349, Accuracy: 1.0\n",
            "Step 18187/22500 - Loss: 0.26568421721458435, Accuracy: 0.875\n",
            "Step 18188/22500 - Loss: 0.1975516378879547, Accuracy: 0.875\n",
            "Step 18189/22500 - Loss: 0.35105326771736145, Accuracy: 0.875\n",
            "Step 18190/22500 - Loss: 0.0773182138800621, Accuracy: 1.0\n",
            "Step 18191/22500 - Loss: 0.00787290558218956, Accuracy: 1.0\n",
            "Step 18192/22500 - Loss: 0.019594913348555565, Accuracy: 1.0\n",
            "Step 18193/22500 - Loss: 0.08611694723367691, Accuracy: 1.0\n",
            "Step 18194/22500 - Loss: 0.0017439820803701878, Accuracy: 1.0\n",
            "Step 18195/22500 - Loss: 0.08948914706707001, Accuracy: 1.0\n",
            "Step 18196/22500 - Loss: 0.09339133650064468, Accuracy: 1.0\n",
            "Step 18197/22500 - Loss: 0.10624605417251587, Accuracy: 1.0\n",
            "Step 18198/22500 - Loss: 0.4677255153656006, Accuracy: 0.875\n",
            "Step 18199/22500 - Loss: 0.009561178274452686, Accuracy: 1.0\n",
            "Step 18200/22500 - Loss: 0.18468014895915985, Accuracy: 0.875\n",
            "Step 18201/22500 - Loss: 0.5004549026489258, Accuracy: 0.75\n",
            "Step 18202/22500 - Loss: 0.0857243537902832, Accuracy: 1.0\n",
            "Step 18203/22500 - Loss: 0.6041764616966248, Accuracy: 0.75\n",
            "Step 18204/22500 - Loss: 0.006173774600028992, Accuracy: 1.0\n",
            "Step 18205/22500 - Loss: 0.1870676875114441, Accuracy: 0.875\n",
            "Step 18206/22500 - Loss: 0.06374888867139816, Accuracy: 1.0\n",
            "Step 18207/22500 - Loss: 0.09287285804748535, Accuracy: 1.0\n",
            "Step 18208/22500 - Loss: 0.06243889778852463, Accuracy: 1.0\n",
            "Step 18209/22500 - Loss: 0.07523337751626968, Accuracy: 1.0\n",
            "Step 18210/22500 - Loss: 0.28488364815711975, Accuracy: 0.875\n",
            "Step 18211/22500 - Loss: 0.022724367678165436, Accuracy: 1.0\n",
            "Step 18212/22500 - Loss: 0.1794435828924179, Accuracy: 0.875\n",
            "Step 18213/22500 - Loss: 0.15165451169013977, Accuracy: 0.875\n",
            "Step 18214/22500 - Loss: 0.010281862691044807, Accuracy: 1.0\n",
            "Step 18215/22500 - Loss: 0.010631585493683815, Accuracy: 1.0\n",
            "Step 18216/22500 - Loss: 0.03889239579439163, Accuracy: 1.0\n",
            "Step 18217/22500 - Loss: 0.04583273082971573, Accuracy: 1.0\n",
            "Step 18218/22500 - Loss: 0.1290655881166458, Accuracy: 1.0\n",
            "Step 18219/22500 - Loss: 0.16650232672691345, Accuracy: 0.875\n",
            "Step 18220/22500 - Loss: 0.02540629357099533, Accuracy: 1.0\n",
            "Step 18221/22500 - Loss: 0.06688902527093887, Accuracy: 1.0\n",
            "Step 18222/22500 - Loss: 0.014694170095026493, Accuracy: 1.0\n",
            "Step 18223/22500 - Loss: 0.03502840921282768, Accuracy: 1.0\n",
            "Step 18224/22500 - Loss: 0.11115039885044098, Accuracy: 0.875\n",
            "Step 18225/22500 - Loss: 0.25966209173202515, Accuracy: 0.875\n",
            "Step 18226/22500 - Loss: 0.26917967200279236, Accuracy: 0.875\n",
            "Step 18227/22500 - Loss: 0.0883922129869461, Accuracy: 1.0\n",
            "Step 18228/22500 - Loss: 0.16191014647483826, Accuracy: 1.0\n",
            "Step 18229/22500 - Loss: 0.01826673001050949, Accuracy: 1.0\n",
            "Step 18230/22500 - Loss: 0.1290324479341507, Accuracy: 1.0\n",
            "Step 18231/22500 - Loss: 0.2203489989042282, Accuracy: 0.875\n",
            "Step 18232/22500 - Loss: 0.01710573025047779, Accuracy: 1.0\n",
            "Step 18233/22500 - Loss: 0.057027921080589294, Accuracy: 1.0\n",
            "Step 18234/22500 - Loss: 0.16084934771060944, Accuracy: 0.875\n",
            "Step 18235/22500 - Loss: 0.08175221085548401, Accuracy: 1.0\n",
            "Step 18236/22500 - Loss: 0.023723850026726723, Accuracy: 1.0\n",
            "Step 18237/22500 - Loss: 0.26542991399765015, Accuracy: 0.875\n",
            "Step 18238/22500 - Loss: 0.055989861488342285, Accuracy: 1.0\n",
            "Step 18239/22500 - Loss: 0.013861642219126225, Accuracy: 1.0\n",
            "Step 18240/22500 - Loss: 0.008359106257557869, Accuracy: 1.0\n",
            "Step 18241/22500 - Loss: 0.030091553926467896, Accuracy: 1.0\n",
            "Step 18242/22500 - Loss: 0.021948078647255898, Accuracy: 1.0\n",
            "Step 18243/22500 - Loss: 0.42536768317222595, Accuracy: 0.75\n",
            "Step 18244/22500 - Loss: 0.030856160447001457, Accuracy: 1.0\n",
            "Step 18245/22500 - Loss: 0.02704940177500248, Accuracy: 1.0\n",
            "Step 18246/22500 - Loss: 0.03502662479877472, Accuracy: 1.0\n",
            "Step 18247/22500 - Loss: 0.0809582769870758, Accuracy: 1.0\n",
            "Step 18248/22500 - Loss: 0.05329284071922302, Accuracy: 1.0\n",
            "Step 18249/22500 - Loss: 0.6051785945892334, Accuracy: 0.75\n",
            "Step 18250/22500 - Loss: 0.1128915399312973, Accuracy: 0.875\n",
            "Step 18251/22500 - Loss: 0.017436068505048752, Accuracy: 1.0\n",
            "Step 18252/22500 - Loss: 0.03430020064115524, Accuracy: 1.0\n",
            "Step 18253/22500 - Loss: 0.4008541703224182, Accuracy: 0.875\n",
            "Step 18254/22500 - Loss: 0.16206851601600647, Accuracy: 1.0\n",
            "Step 18255/22500 - Loss: 0.014233382418751717, Accuracy: 1.0\n",
            "Step 18256/22500 - Loss: 0.03280453011393547, Accuracy: 1.0\n",
            "Step 18257/22500 - Loss: 0.07339495420455933, Accuracy: 1.0\n",
            "Step 18258/22500 - Loss: 0.04534843936562538, Accuracy: 1.0\n",
            "Step 18259/22500 - Loss: 0.12305235862731934, Accuracy: 0.875\n",
            "Step 18260/22500 - Loss: 0.03025606833398342, Accuracy: 1.0\n",
            "Step 18261/22500 - Loss: 0.027362417429685593, Accuracy: 1.0\n",
            "Step 18262/22500 - Loss: 0.09062302112579346, Accuracy: 1.0\n",
            "Step 18263/22500 - Loss: 0.402339369058609, Accuracy: 0.75\n",
            "Step 18264/22500 - Loss: 0.01607455126941204, Accuracy: 1.0\n",
            "Step 18265/22500 - Loss: 0.010594523511826992, Accuracy: 1.0\n",
            "Step 18266/22500 - Loss: 0.012460398487746716, Accuracy: 1.0\n",
            "Step 18267/22500 - Loss: 0.17196637392044067, Accuracy: 0.875\n",
            "Step 18268/22500 - Loss: 0.04147128760814667, Accuracy: 1.0\n",
            "Step 18269/22500 - Loss: 0.326809287071228, Accuracy: 0.875\n",
            "Step 18270/22500 - Loss: 0.16790680587291718, Accuracy: 0.875\n",
            "Step 18271/22500 - Loss: 0.06395716965198517, Accuracy: 1.0\n",
            "Step 18272/22500 - Loss: 0.14190807938575745, Accuracy: 0.875\n",
            "Step 18273/22500 - Loss: 0.01458655297756195, Accuracy: 1.0\n",
            "Step 18274/22500 - Loss: 0.007565612904727459, Accuracy: 1.0\n",
            "Step 18275/22500 - Loss: 0.07702955603599548, Accuracy: 1.0\n",
            "Step 18276/22500 - Loss: 0.6677982211112976, Accuracy: 0.875\n",
            "Step 18277/22500 - Loss: 0.005516387987881899, Accuracy: 1.0\n",
            "Step 18278/22500 - Loss: 0.23024526238441467, Accuracy: 0.875\n",
            "Step 18279/22500 - Loss: 0.04161025211215019, Accuracy: 1.0\n",
            "Step 18280/22500 - Loss: 0.06012297794222832, Accuracy: 1.0\n",
            "Step 18281/22500 - Loss: 0.03267013281583786, Accuracy: 1.0\n",
            "Step 18282/22500 - Loss: 0.09170373529195786, Accuracy: 1.0\n",
            "Step 18283/22500 - Loss: 0.008728593587875366, Accuracy: 1.0\n",
            "Step 18284/22500 - Loss: 0.023876551538705826, Accuracy: 1.0\n",
            "Step 18285/22500 - Loss: 0.18771988153457642, Accuracy: 0.875\n",
            "Step 18286/22500 - Loss: 0.07765121012926102, Accuracy: 1.0\n",
            "Step 18287/22500 - Loss: 0.013041330501437187, Accuracy: 1.0\n",
            "Step 18288/22500 - Loss: 0.02995903044939041, Accuracy: 1.0\n",
            "Step 18289/22500 - Loss: 0.2116876244544983, Accuracy: 0.875\n",
            "Step 18290/22500 - Loss: 0.6612027883529663, Accuracy: 0.75\n",
            "Step 18291/22500 - Loss: 0.022800499573349953, Accuracy: 1.0\n",
            "Step 18292/22500 - Loss: 0.02252873405814171, Accuracy: 1.0\n",
            "Step 18293/22500 - Loss: 0.26291730999946594, Accuracy: 0.875\n",
            "Step 18294/22500 - Loss: 0.07687300443649292, Accuracy: 1.0\n",
            "Step 18295/22500 - Loss: 0.1497068703174591, Accuracy: 0.875\n",
            "Step 18296/22500 - Loss: 0.1989915817975998, Accuracy: 0.875\n",
            "Step 18297/22500 - Loss: 0.0725335106253624, Accuracy: 1.0\n",
            "Step 18298/22500 - Loss: 0.095557302236557, Accuracy: 0.875\n",
            "Step 18299/22500 - Loss: 0.01914132572710514, Accuracy: 1.0\n",
            "Step 18300/22500 - Loss: 0.007529351860284805, Accuracy: 1.0\n",
            "Step 18301/22500 - Loss: 0.018262213096022606, Accuracy: 1.0\n",
            "Step 18302/22500 - Loss: 0.24328917264938354, Accuracy: 0.875\n",
            "Step 18303/22500 - Loss: 0.407979816198349, Accuracy: 0.875\n",
            "Step 18304/22500 - Loss: 0.12118705362081528, Accuracy: 0.875\n",
            "Step 18305/22500 - Loss: 0.22782734036445618, Accuracy: 0.875\n",
            "Step 18306/22500 - Loss: 0.07036734372377396, Accuracy: 1.0\n",
            "Step 18307/22500 - Loss: 0.15087315440177917, Accuracy: 0.875\n",
            "Step 18308/22500 - Loss: 0.011792204342782497, Accuracy: 1.0\n",
            "Step 18309/22500 - Loss: 0.11784474551677704, Accuracy: 0.875\n",
            "Step 18310/22500 - Loss: 0.08013569563627243, Accuracy: 1.0\n",
            "Step 18311/22500 - Loss: 0.01047560479491949, Accuracy: 1.0\n",
            "Step 18312/22500 - Loss: 0.14071504771709442, Accuracy: 0.875\n",
            "Step 18313/22500 - Loss: 0.04707707092165947, Accuracy: 1.0\n",
            "Step 18314/22500 - Loss: 0.3124445974826813, Accuracy: 0.75\n",
            "Step 18315/22500 - Loss: 0.032050639390945435, Accuracy: 1.0\n",
            "Step 18316/22500 - Loss: 0.13004004955291748, Accuracy: 0.875\n",
            "Step 18317/22500 - Loss: 0.40440675616264343, Accuracy: 0.875\n",
            "Step 18318/22500 - Loss: 0.028468964621424675, Accuracy: 1.0\n",
            "Step 18319/22500 - Loss: 0.1052994653582573, Accuracy: 1.0\n",
            "Step 18320/22500 - Loss: 0.18928027153015137, Accuracy: 1.0\n",
            "Step 18321/22500 - Loss: 0.10752348601818085, Accuracy: 1.0\n",
            "Step 18322/22500 - Loss: 0.13248425722122192, Accuracy: 1.0\n",
            "Step 18323/22500 - Loss: 0.012844124808907509, Accuracy: 1.0\n",
            "Step 18324/22500 - Loss: 0.14544959366321564, Accuracy: 0.875\n",
            "Step 18325/22500 - Loss: 0.009495129808783531, Accuracy: 1.0\n",
            "Step 18326/22500 - Loss: 0.061558205634355545, Accuracy: 1.0\n",
            "Step 18327/22500 - Loss: 0.03992782160639763, Accuracy: 1.0\n",
            "Step 18328/22500 - Loss: 0.7942259907722473, Accuracy: 0.875\n",
            "Step 18329/22500 - Loss: 0.005855849012732506, Accuracy: 1.0\n",
            "Step 18330/22500 - Loss: 0.4474825859069824, Accuracy: 0.875\n",
            "Step 18331/22500 - Loss: 0.1452595591545105, Accuracy: 0.875\n",
            "Step 18332/22500 - Loss: 0.05652641877532005, Accuracy: 1.0\n",
            "Step 18333/22500 - Loss: 0.22760583460330963, Accuracy: 0.875\n",
            "Step 18334/22500 - Loss: 0.24511900544166565, Accuracy: 0.875\n",
            "Step 18335/22500 - Loss: 0.018441159278154373, Accuracy: 1.0\n",
            "Step 18336/22500 - Loss: 0.09166492521762848, Accuracy: 1.0\n",
            "Step 18337/22500 - Loss: 0.027537493035197258, Accuracy: 1.0\n",
            "Step 18338/22500 - Loss: 0.004490314517170191, Accuracy: 1.0\n",
            "Step 18339/22500 - Loss: 0.5721380114555359, Accuracy: 0.875\n",
            "Step 18340/22500 - Loss: 0.042836375534534454, Accuracy: 1.0\n",
            "Step 18341/22500 - Loss: 0.19201689958572388, Accuracy: 0.875\n",
            "Step 18342/22500 - Loss: 0.0760328471660614, Accuracy: 1.0\n",
            "Step 18343/22500 - Loss: 0.22399190068244934, Accuracy: 0.875\n",
            "Step 18344/22500 - Loss: 0.10864582657814026, Accuracy: 1.0\n",
            "Step 18345/22500 - Loss: 0.009336085990071297, Accuracy: 1.0\n",
            "Step 18346/22500 - Loss: 0.04637003317475319, Accuracy: 1.0\n",
            "Step 18347/22500 - Loss: 0.04295463487505913, Accuracy: 1.0\n",
            "Step 18348/22500 - Loss: 0.00589991919696331, Accuracy: 1.0\n",
            "Step 18349/22500 - Loss: 0.15286166965961456, Accuracy: 0.875\n",
            "Step 18350/22500 - Loss: 0.05248858034610748, Accuracy: 1.0\n",
            "Step 18351/22500 - Loss: 0.016701502725481987, Accuracy: 1.0\n",
            "Step 18352/22500 - Loss: 0.007904148660600185, Accuracy: 1.0\n",
            "Step 18353/22500 - Loss: 0.20367591083049774, Accuracy: 0.875\n",
            "Step 18354/22500 - Loss: 0.09777908027172089, Accuracy: 1.0\n",
            "Step 18355/22500 - Loss: 0.09596356004476547, Accuracy: 1.0\n",
            "Step 18356/22500 - Loss: 0.4912927448749542, Accuracy: 0.75\n",
            "Step 18357/22500 - Loss: 0.10690728574991226, Accuracy: 0.875\n",
            "Step 18358/22500 - Loss: 0.7588387727737427, Accuracy: 0.875\n",
            "Step 18359/22500 - Loss: 0.19979232549667358, Accuracy: 0.875\n",
            "Step 18360/22500 - Loss: 0.2522040605545044, Accuracy: 0.875\n",
            "Step 18361/22500 - Loss: 0.08632766455411911, Accuracy: 1.0\n",
            "Step 18362/22500 - Loss: 0.5343506932258606, Accuracy: 0.75\n",
            "Step 18363/22500 - Loss: 0.029418231919407845, Accuracy: 1.0\n",
            "Step 18364/22500 - Loss: 0.13317540287971497, Accuracy: 0.875\n",
            "Step 18365/22500 - Loss: 0.29342424869537354, Accuracy: 0.875\n",
            "Step 18366/22500 - Loss: 0.006001037545502186, Accuracy: 1.0\n",
            "Step 18367/22500 - Loss: 0.13168221712112427, Accuracy: 0.875\n",
            "Step 18368/22500 - Loss: 0.04831579327583313, Accuracy: 1.0\n",
            "Step 18369/22500 - Loss: 0.006348712369799614, Accuracy: 1.0\n",
            "Step 18370/22500 - Loss: 0.41846707463264465, Accuracy: 0.875\n",
            "Step 18371/22500 - Loss: 0.029334114864468575, Accuracy: 1.0\n",
            "Step 18372/22500 - Loss: 0.04569012671709061, Accuracy: 1.0\n",
            "Step 18373/22500 - Loss: 0.04199231043457985, Accuracy: 1.0\n",
            "Step 18374/22500 - Loss: 0.14679518342018127, Accuracy: 0.875\n",
            "Step 18375/22500 - Loss: 0.11265500634908676, Accuracy: 0.875\n",
            "Step 18376/22500 - Loss: 0.33126959204673767, Accuracy: 0.75\n",
            "Step 18377/22500 - Loss: 0.043817244470119476, Accuracy: 1.0\n",
            "Step 18378/22500 - Loss: 0.0057927523739635944, Accuracy: 1.0\n",
            "Step 18379/22500 - Loss: 0.06627009063959122, Accuracy: 1.0\n",
            "Step 18380/22500 - Loss: 0.06056003272533417, Accuracy: 1.0\n",
            "Step 18381/22500 - Loss: 0.026710448786616325, Accuracy: 1.0\n",
            "Step 18382/22500 - Loss: 0.05255093798041344, Accuracy: 1.0\n",
            "Step 18383/22500 - Loss: 0.17722319066524506, Accuracy: 0.875\n",
            "Step 18384/22500 - Loss: 0.027063550427556038, Accuracy: 1.0\n",
            "Step 18385/22500 - Loss: 0.009875139221549034, Accuracy: 1.0\n",
            "Step 18386/22500 - Loss: 0.03315320611000061, Accuracy: 1.0\n",
            "Step 18387/22500 - Loss: 0.01385562028735876, Accuracy: 1.0\n",
            "Step 18388/22500 - Loss: 0.05976809188723564, Accuracy: 1.0\n",
            "Step 18389/22500 - Loss: 0.09819342195987701, Accuracy: 0.875\n",
            "Step 18390/22500 - Loss: 0.020752983167767525, Accuracy: 1.0\n",
            "Step 18391/22500 - Loss: 0.43986064195632935, Accuracy: 0.875\n",
            "Step 18392/22500 - Loss: 0.029456457123160362, Accuracy: 1.0\n",
            "Step 18393/22500 - Loss: 0.011754260398447514, Accuracy: 1.0\n",
            "Step 18394/22500 - Loss: 0.039972443133592606, Accuracy: 1.0\n",
            "Step 18395/22500 - Loss: 0.02774866670370102, Accuracy: 1.0\n",
            "Step 18396/22500 - Loss: 0.1716773360967636, Accuracy: 0.875\n",
            "Step 18397/22500 - Loss: 0.062212444841861725, Accuracy: 1.0\n",
            "Step 18398/22500 - Loss: 0.023531438782811165, Accuracy: 1.0\n",
            "Step 18399/22500 - Loss: 0.04258667677640915, Accuracy: 1.0\n",
            "Step 18400/22500 - Loss: 0.97056645154953, Accuracy: 0.875\n",
            "Step 18401/22500 - Loss: 0.025746483355760574, Accuracy: 1.0\n",
            "Step 18402/22500 - Loss: 0.024707458913326263, Accuracy: 1.0\n",
            "Step 18403/22500 - Loss: 0.010382910259068012, Accuracy: 1.0\n",
            "Step 18404/22500 - Loss: 0.4803568720817566, Accuracy: 0.875\n",
            "Step 18405/22500 - Loss: 0.03176966309547424, Accuracy: 1.0\n",
            "Step 18406/22500 - Loss: 0.14810264110565186, Accuracy: 0.875\n",
            "Step 18407/22500 - Loss: 0.44404810667037964, Accuracy: 0.75\n",
            "Step 18408/22500 - Loss: 0.2102404087781906, Accuracy: 0.875\n",
            "Step 18409/22500 - Loss: 0.19097919762134552, Accuracy: 0.875\n",
            "Step 18410/22500 - Loss: 0.04871400445699692, Accuracy: 1.0\n",
            "Step 18411/22500 - Loss: 0.11409720033407211, Accuracy: 1.0\n",
            "Step 18412/22500 - Loss: 0.11882485449314117, Accuracy: 1.0\n",
            "Step 18413/22500 - Loss: 0.8226222395896912, Accuracy: 0.875\n",
            "Step 18414/22500 - Loss: 0.11749729514122009, Accuracy: 0.875\n",
            "Step 18415/22500 - Loss: 0.031013675034046173, Accuracy: 1.0\n",
            "Step 18416/22500 - Loss: 0.029550332576036453, Accuracy: 1.0\n",
            "Step 18417/22500 - Loss: 0.2759523391723633, Accuracy: 0.75\n",
            "Step 18418/22500 - Loss: 0.02741320990025997, Accuracy: 1.0\n",
            "Step 18419/22500 - Loss: 0.20760785043239594, Accuracy: 0.875\n",
            "Step 18420/22500 - Loss: 0.0992138683795929, Accuracy: 1.0\n",
            "Step 18421/22500 - Loss: 0.18030308187007904, Accuracy: 0.875\n",
            "Step 18422/22500 - Loss: 0.31600579619407654, Accuracy: 0.875\n",
            "Step 18423/22500 - Loss: 0.0049074552953243256, Accuracy: 1.0\n",
            "Step 18424/22500 - Loss: 0.02426181547343731, Accuracy: 1.0\n",
            "Step 18425/22500 - Loss: 0.15126089751720428, Accuracy: 0.875\n",
            "Step 18426/22500 - Loss: 0.011610394343733788, Accuracy: 1.0\n",
            "Step 18427/22500 - Loss: 0.02876240573823452, Accuracy: 1.0\n",
            "Step 18428/22500 - Loss: 0.015933986753225327, Accuracy: 1.0\n",
            "Step 18429/22500 - Loss: 0.02610311098396778, Accuracy: 1.0\n",
            "Step 18430/22500 - Loss: 0.009758208878338337, Accuracy: 1.0\n",
            "Step 18431/22500 - Loss: 0.05888451635837555, Accuracy: 1.0\n",
            "Step 18432/22500 - Loss: 0.21537373960018158, Accuracy: 0.875\n",
            "Step 18433/22500 - Loss: 0.038044895976781845, Accuracy: 1.0\n",
            "Step 18434/22500 - Loss: 0.07755996286869049, Accuracy: 1.0\n",
            "Step 18435/22500 - Loss: 0.010109166614711285, Accuracy: 1.0\n",
            "Step 18436/22500 - Loss: 0.028331438079476357, Accuracy: 1.0\n",
            "Step 18437/22500 - Loss: 0.03618399426341057, Accuracy: 1.0\n",
            "Step 18438/22500 - Loss: 0.4391855001449585, Accuracy: 0.875\n",
            "Step 18439/22500 - Loss: 0.23032091557979584, Accuracy: 0.875\n",
            "Step 18440/22500 - Loss: 0.582673192024231, Accuracy: 0.875\n",
            "Step 18441/22500 - Loss: 0.07718878239393234, Accuracy: 1.0\n",
            "Step 18442/22500 - Loss: 0.3885921239852905, Accuracy: 0.875\n",
            "Step 18443/22500 - Loss: 0.186893031001091, Accuracy: 0.875\n",
            "Step 18444/22500 - Loss: 0.008835232816636562, Accuracy: 1.0\n",
            "Step 18445/22500 - Loss: 0.12632083892822266, Accuracy: 0.875\n",
            "Step 18446/22500 - Loss: 0.04001608490943909, Accuracy: 1.0\n",
            "Step 18447/22500 - Loss: 0.6447124481201172, Accuracy: 0.75\n",
            "Step 18448/22500 - Loss: 0.09545454382896423, Accuracy: 1.0\n",
            "Step 18449/22500 - Loss: 0.02059204876422882, Accuracy: 1.0\n",
            "Step 18450/22500 - Loss: 0.08965612947940826, Accuracy: 1.0\n",
            "Step 18451/22500 - Loss: 0.019860675558447838, Accuracy: 1.0\n",
            "Step 18452/22500 - Loss: 0.08152953535318375, Accuracy: 1.0\n",
            "Step 18453/22500 - Loss: 0.02618076279759407, Accuracy: 1.0\n",
            "Step 18454/22500 - Loss: 0.025528620928525925, Accuracy: 1.0\n",
            "Step 18455/22500 - Loss: 0.05285239592194557, Accuracy: 1.0\n",
            "Step 18456/22500 - Loss: 0.33398354053497314, Accuracy: 0.875\n",
            "Step 18457/22500 - Loss: 0.009650156833231449, Accuracy: 1.0\n",
            "Step 18458/22500 - Loss: 0.08830121159553528, Accuracy: 1.0\n",
            "Step 18459/22500 - Loss: 0.5514112114906311, Accuracy: 0.875\n",
            "Step 18460/22500 - Loss: 0.0422188937664032, Accuracy: 1.0\n",
            "Step 18461/22500 - Loss: 0.05230415612459183, Accuracy: 1.0\n",
            "Step 18462/22500 - Loss: 0.012012727558612823, Accuracy: 1.0\n",
            "Step 18463/22500 - Loss: 0.07888728380203247, Accuracy: 1.0\n",
            "Step 18464/22500 - Loss: 0.37244275212287903, Accuracy: 0.75\n",
            "Step 18465/22500 - Loss: 0.141169935464859, Accuracy: 1.0\n",
            "Step 18466/22500 - Loss: 0.009591575711965561, Accuracy: 1.0\n",
            "Step 18467/22500 - Loss: 0.1468542516231537, Accuracy: 0.875\n",
            "Step 18468/22500 - Loss: 0.009190681390464306, Accuracy: 1.0\n",
            "Step 18469/22500 - Loss: 0.3014858663082123, Accuracy: 0.875\n",
            "Step 18470/22500 - Loss: 0.02990187145769596, Accuracy: 1.0\n",
            "Step 18471/22500 - Loss: 0.06421350687742233, Accuracy: 1.0\n",
            "Step 18472/22500 - Loss: 0.095991350710392, Accuracy: 0.875\n",
            "Step 18473/22500 - Loss: 0.025831636041402817, Accuracy: 1.0\n",
            "Step 18474/22500 - Loss: 0.03134560212492943, Accuracy: 1.0\n",
            "Step 18475/22500 - Loss: 0.09985511004924774, Accuracy: 1.0\n",
            "Step 18476/22500 - Loss: 0.024636073037981987, Accuracy: 1.0\n",
            "Step 18477/22500 - Loss: 0.2782022953033447, Accuracy: 0.875\n",
            "Step 18478/22500 - Loss: 0.03913941606879234, Accuracy: 1.0\n",
            "Step 18479/22500 - Loss: 0.00861971266567707, Accuracy: 1.0\n",
            "Step 18480/22500 - Loss: 0.6262394189834595, Accuracy: 0.625\n",
            "Step 18481/22500 - Loss: 0.12520217895507812, Accuracy: 1.0\n",
            "Step 18482/22500 - Loss: 0.03521137684583664, Accuracy: 1.0\n",
            "Step 18483/22500 - Loss: 0.08825842291116714, Accuracy: 1.0\n",
            "Step 18484/22500 - Loss: 0.03144179657101631, Accuracy: 1.0\n",
            "Step 18485/22500 - Loss: 0.0030852328054606915, Accuracy: 1.0\n",
            "Step 18486/22500 - Loss: 0.04773839935660362, Accuracy: 1.0\n",
            "Step 18487/22500 - Loss: 0.007685794960707426, Accuracy: 1.0\n",
            "Step 18488/22500 - Loss: 0.12996266782283783, Accuracy: 0.875\n",
            "Step 18489/22500 - Loss: 0.04049363359808922, Accuracy: 1.0\n",
            "Step 18490/22500 - Loss: 0.7653048038482666, Accuracy: 0.875\n",
            "Step 18491/22500 - Loss: 0.20827344059944153, Accuracy: 0.875\n",
            "Step 18492/22500 - Loss: 0.011637302115559578, Accuracy: 1.0\n",
            "Step 18493/22500 - Loss: 0.02907039038836956, Accuracy: 1.0\n",
            "Step 18494/22500 - Loss: 0.1700262576341629, Accuracy: 1.0\n",
            "Step 18495/22500 - Loss: 0.06033139303326607, Accuracy: 1.0\n",
            "Step 18496/22500 - Loss: 0.05414310842752457, Accuracy: 1.0\n",
            "Step 18497/22500 - Loss: 0.138143852353096, Accuracy: 0.875\n",
            "Step 18498/22500 - Loss: 0.5941149592399597, Accuracy: 0.875\n",
            "Step 18499/22500 - Loss: 0.0630369782447815, Accuracy: 1.0\n",
            "Step 18500/22500 - Loss: 0.13447369635105133, Accuracy: 0.875\n",
            "Step 18501/22500 - Loss: 0.14935076236724854, Accuracy: 1.0\n",
            "Step 18502/22500 - Loss: 0.0073759546503424644, Accuracy: 1.0\n",
            "Step 18503/22500 - Loss: 0.033929161727428436, Accuracy: 1.0\n",
            "Step 18504/22500 - Loss: 0.006372774951159954, Accuracy: 1.0\n",
            "Step 18505/22500 - Loss: 0.1308741718530655, Accuracy: 1.0\n",
            "Step 18506/22500 - Loss: 0.14981874823570251, Accuracy: 0.875\n",
            "Step 18507/22500 - Loss: 0.04405461996793747, Accuracy: 1.0\n",
            "Step 18508/22500 - Loss: 0.27814099192619324, Accuracy: 0.875\n",
            "Step 18509/22500 - Loss: 0.13746148347854614, Accuracy: 0.875\n",
            "Step 18510/22500 - Loss: 0.00481961527839303, Accuracy: 1.0\n",
            "Step 18511/22500 - Loss: 0.4379800856113434, Accuracy: 0.875\n",
            "Step 18512/22500 - Loss: 0.18221250176429749, Accuracy: 0.875\n",
            "Step 18513/22500 - Loss: 0.06463237851858139, Accuracy: 1.0\n",
            "Step 18514/22500 - Loss: 0.03994911536574364, Accuracy: 1.0\n",
            "Step 18515/22500 - Loss: 0.823386549949646, Accuracy: 0.75\n",
            "Step 18516/22500 - Loss: 0.15072858333587646, Accuracy: 0.875\n",
            "Step 18517/22500 - Loss: 0.692240297794342, Accuracy: 0.75\n",
            "Step 18518/22500 - Loss: 0.05615249276161194, Accuracy: 1.0\n",
            "Step 18519/22500 - Loss: 0.23973411321640015, Accuracy: 0.875\n",
            "Step 18520/22500 - Loss: 0.2897052764892578, Accuracy: 0.875\n",
            "Step 18521/22500 - Loss: 0.06478514522314072, Accuracy: 1.0\n",
            "Step 18522/22500 - Loss: 0.011472846381366253, Accuracy: 1.0\n",
            "Step 18523/22500 - Loss: 0.011396098881959915, Accuracy: 1.0\n",
            "Step 18524/22500 - Loss: 0.0644010379910469, Accuracy: 1.0\n",
            "Step 18525/22500 - Loss: 0.033172607421875, Accuracy: 1.0\n",
            "Step 18526/22500 - Loss: 0.31673663854599, Accuracy: 0.875\n",
            "Step 18527/22500 - Loss: 0.029943283647298813, Accuracy: 1.0\n",
            "Step 18528/22500 - Loss: 0.07604020833969116, Accuracy: 1.0\n",
            "Step 18529/22500 - Loss: 0.08006513863801956, Accuracy: 1.0\n",
            "Step 18530/22500 - Loss: 0.038296230137348175, Accuracy: 1.0\n",
            "Step 18531/22500 - Loss: 0.067875437438488, Accuracy: 1.0\n",
            "Step 18532/22500 - Loss: 0.014436395838856697, Accuracy: 1.0\n",
            "Step 18533/22500 - Loss: 0.10730750858783722, Accuracy: 1.0\n",
            "Step 18534/22500 - Loss: 0.5580336451530457, Accuracy: 0.875\n",
            "Step 18535/22500 - Loss: 0.028099635615944862, Accuracy: 1.0\n",
            "Step 18536/22500 - Loss: 0.08764535188674927, Accuracy: 1.0\n",
            "Step 18537/22500 - Loss: 0.16283836960792542, Accuracy: 0.875\n",
            "Step 18538/22500 - Loss: 0.6141217350959778, Accuracy: 0.875\n",
            "Step 18539/22500 - Loss: 0.0400264710187912, Accuracy: 1.0\n",
            "Step 18540/22500 - Loss: 0.03251735866069794, Accuracy: 1.0\n",
            "Step 18541/22500 - Loss: 0.2859342098236084, Accuracy: 0.875\n",
            "Step 18542/22500 - Loss: 0.0478692352771759, Accuracy: 1.0\n",
            "Step 18543/22500 - Loss: 0.0834292396903038, Accuracy: 1.0\n",
            "Step 18544/22500 - Loss: 0.24919600784778595, Accuracy: 0.875\n",
            "Step 18545/22500 - Loss: 0.039442699402570724, Accuracy: 1.0\n",
            "Step 18546/22500 - Loss: 0.01722947508096695, Accuracy: 1.0\n",
            "Step 18547/22500 - Loss: 0.21412155032157898, Accuracy: 0.875\n",
            "Step 18548/22500 - Loss: 0.04559047892689705, Accuracy: 1.0\n",
            "Step 18549/22500 - Loss: 0.04600030928850174, Accuracy: 1.0\n",
            "Step 18550/22500 - Loss: 0.006092671304941177, Accuracy: 1.0\n",
            "Step 18551/22500 - Loss: 0.014753933995962143, Accuracy: 1.0\n",
            "Step 18552/22500 - Loss: 0.08221199363470078, Accuracy: 1.0\n",
            "Step 18553/22500 - Loss: 0.031320251524448395, Accuracy: 1.0\n",
            "Step 18554/22500 - Loss: 0.015007874928414822, Accuracy: 1.0\n",
            "Step 18555/22500 - Loss: 0.44517821073532104, Accuracy: 0.75\n",
            "Step 18556/22500 - Loss: 0.23360195755958557, Accuracy: 0.875\n",
            "Step 18557/22500 - Loss: 0.589491605758667, Accuracy: 0.875\n",
            "Step 18558/22500 - Loss: 0.09121184051036835, Accuracy: 1.0\n",
            "Step 18559/22500 - Loss: 0.06679053604602814, Accuracy: 1.0\n",
            "Step 18560/22500 - Loss: 0.12815643846988678, Accuracy: 0.875\n",
            "Step 18561/22500 - Loss: 0.017927581444382668, Accuracy: 1.0\n",
            "Step 18562/22500 - Loss: 0.016829799860715866, Accuracy: 1.0\n",
            "Step 18563/22500 - Loss: 0.008223925717175007, Accuracy: 1.0\n",
            "Step 18564/22500 - Loss: 0.030376236885786057, Accuracy: 1.0\n",
            "Step 18565/22500 - Loss: 0.06530068069696426, Accuracy: 1.0\n",
            "Step 18566/22500 - Loss: 0.18718773126602173, Accuracy: 0.875\n",
            "Step 18567/22500 - Loss: 0.01890322007238865, Accuracy: 1.0\n",
            "Step 18568/22500 - Loss: 0.03257201239466667, Accuracy: 1.0\n",
            "Step 18569/22500 - Loss: 0.06160765886306763, Accuracy: 1.0\n",
            "Step 18570/22500 - Loss: 0.11971833556890488, Accuracy: 0.875\n",
            "Step 18571/22500 - Loss: 0.03433849290013313, Accuracy: 1.0\n",
            "Step 18572/22500 - Loss: 0.0026595969684422016, Accuracy: 1.0\n",
            "Step 18573/22500 - Loss: 0.014179118908941746, Accuracy: 1.0\n",
            "Step 18574/22500 - Loss: 0.0297700148075819, Accuracy: 1.0\n",
            "Step 18575/22500 - Loss: 0.2132391780614853, Accuracy: 0.875\n",
            "Step 18576/22500 - Loss: 0.2024395614862442, Accuracy: 0.875\n",
            "Step 18577/22500 - Loss: 0.012063518166542053, Accuracy: 1.0\n",
            "Step 18578/22500 - Loss: 0.031713444739580154, Accuracy: 1.0\n",
            "Step 18579/22500 - Loss: 0.002048405585810542, Accuracy: 1.0\n",
            "Step 18580/22500 - Loss: 0.03724479302763939, Accuracy: 1.0\n",
            "Step 18581/22500 - Loss: 0.2196280062198639, Accuracy: 0.875\n",
            "Step 18582/22500 - Loss: 0.004314083140343428, Accuracy: 1.0\n",
            "Step 18583/22500 - Loss: 0.3470494747161865, Accuracy: 0.75\n",
            "Step 18584/22500 - Loss: 0.13805733621120453, Accuracy: 0.875\n",
            "Step 18585/22500 - Loss: 0.04204147681593895, Accuracy: 1.0\n",
            "Step 18586/22500 - Loss: 0.229561910033226, Accuracy: 0.875\n",
            "Step 18587/22500 - Loss: 0.27997446060180664, Accuracy: 0.875\n",
            "Step 18588/22500 - Loss: 0.07324139773845673, Accuracy: 1.0\n",
            "Step 18589/22500 - Loss: 0.05278763175010681, Accuracy: 1.0\n",
            "Step 18590/22500 - Loss: 0.049770765006542206, Accuracy: 1.0\n",
            "Step 18591/22500 - Loss: 0.020244669169187546, Accuracy: 1.0\n",
            "Step 18592/22500 - Loss: 0.020136510953307152, Accuracy: 1.0\n",
            "Step 18593/22500 - Loss: 0.004415447823703289, Accuracy: 1.0\n",
            "Step 18594/22500 - Loss: 0.12515628337860107, Accuracy: 0.875\n",
            "Step 18595/22500 - Loss: 0.008238496258854866, Accuracy: 1.0\n",
            "Step 18596/22500 - Loss: 0.10763604193925858, Accuracy: 1.0\n",
            "Step 18597/22500 - Loss: 0.14458851516246796, Accuracy: 0.875\n",
            "Step 18598/22500 - Loss: 0.25343558192253113, Accuracy: 0.875\n",
            "Step 18599/22500 - Loss: 0.016739238053560257, Accuracy: 1.0\n",
            "Step 18600/22500 - Loss: 0.14981456100940704, Accuracy: 0.875\n",
            "Step 18601/22500 - Loss: 0.019064800813794136, Accuracy: 1.0\n",
            "Step 18602/22500 - Loss: 0.011950752697885036, Accuracy: 1.0\n",
            "Step 18603/22500 - Loss: 0.006379262078553438, Accuracy: 1.0\n",
            "Step 18604/22500 - Loss: 0.04669179394841194, Accuracy: 1.0\n",
            "Step 18605/22500 - Loss: 0.0054833246394991875, Accuracy: 1.0\n",
            "Step 18606/22500 - Loss: 0.603538453578949, Accuracy: 0.75\n",
            "Step 18607/22500 - Loss: 0.03751860558986664, Accuracy: 1.0\n",
            "Step 18608/22500 - Loss: 0.017694732174277306, Accuracy: 1.0\n",
            "Step 18609/22500 - Loss: 0.1280967742204666, Accuracy: 0.875\n",
            "Step 18610/22500 - Loss: 0.025669032707810402, Accuracy: 1.0\n",
            "Step 18611/22500 - Loss: 0.07821255922317505, Accuracy: 1.0\n",
            "Step 18612/22500 - Loss: 0.10494078695774078, Accuracy: 1.0\n",
            "Step 18613/22500 - Loss: 0.09154374152421951, Accuracy: 1.0\n",
            "Step 18614/22500 - Loss: 0.4114624857902527, Accuracy: 0.875\n",
            "Step 18615/22500 - Loss: 0.01531667448580265, Accuracy: 1.0\n",
            "Step 18616/22500 - Loss: 0.16021206974983215, Accuracy: 0.875\n",
            "Step 18617/22500 - Loss: 0.002111336449161172, Accuracy: 1.0\n",
            "Step 18618/22500 - Loss: 0.1473839432001114, Accuracy: 0.875\n",
            "Step 18619/22500 - Loss: 0.05183609575033188, Accuracy: 1.0\n",
            "Step 18620/22500 - Loss: 0.03381657972931862, Accuracy: 1.0\n",
            "Step 18621/22500 - Loss: 0.026019860059022903, Accuracy: 1.0\n",
            "Step 18622/22500 - Loss: 0.0027325295377522707, Accuracy: 1.0\n",
            "Step 18623/22500 - Loss: 0.06955205649137497, Accuracy: 1.0\n",
            "Step 18624/22500 - Loss: 0.13334262371063232, Accuracy: 0.875\n",
            "Step 18625/22500 - Loss: 0.03822328895330429, Accuracy: 1.0\n",
            "Step 18626/22500 - Loss: 0.08519341796636581, Accuracy: 1.0\n",
            "Step 18627/22500 - Loss: 0.23158280551433563, Accuracy: 0.875\n",
            "Step 18628/22500 - Loss: 0.04601404443383217, Accuracy: 1.0\n",
            "Step 18629/22500 - Loss: 0.4238815903663635, Accuracy: 0.875\n",
            "Step 18630/22500 - Loss: 0.03604820370674133, Accuracy: 1.0\n",
            "Step 18631/22500 - Loss: 0.013736211694777012, Accuracy: 1.0\n",
            "Step 18632/22500 - Loss: 0.022305907681584358, Accuracy: 1.0\n",
            "Step 18633/22500 - Loss: 0.11087669432163239, Accuracy: 1.0\n",
            "Step 18634/22500 - Loss: 0.024446384981274605, Accuracy: 1.0\n",
            "Step 18635/22500 - Loss: 0.08037535846233368, Accuracy: 1.0\n",
            "Step 18636/22500 - Loss: 0.05903126671910286, Accuracy: 1.0\n",
            "Step 18637/22500 - Loss: 0.15983812510967255, Accuracy: 0.875\n",
            "Step 18638/22500 - Loss: 0.1101025938987732, Accuracy: 0.875\n",
            "Step 18639/22500 - Loss: 0.601178765296936, Accuracy: 0.75\n",
            "Step 18640/22500 - Loss: 0.013776121661067009, Accuracy: 1.0\n",
            "Step 18641/22500 - Loss: 0.09250776469707489, Accuracy: 0.875\n",
            "Step 18642/22500 - Loss: 0.08865492790937424, Accuracy: 1.0\n",
            "Step 18643/22500 - Loss: 0.5430092215538025, Accuracy: 0.875\n",
            "Step 18644/22500 - Loss: 0.05405258759856224, Accuracy: 1.0\n",
            "Step 18645/22500 - Loss: 0.3656398057937622, Accuracy: 0.875\n",
            "Step 18646/22500 - Loss: 0.2929973900318146, Accuracy: 0.875\n",
            "Step 18647/22500 - Loss: 0.13243456184864044, Accuracy: 0.875\n",
            "Step 18648/22500 - Loss: 0.16205553710460663, Accuracy: 0.875\n",
            "Step 18649/22500 - Loss: 0.031569644808769226, Accuracy: 1.0\n",
            "Step 18650/22500 - Loss: 0.010317320004105568, Accuracy: 1.0\n",
            "Step 18651/22500 - Loss: 0.05911489576101303, Accuracy: 1.0\n",
            "Step 18652/22500 - Loss: 0.1509014368057251, Accuracy: 0.875\n",
            "Step 18653/22500 - Loss: 0.0957288146018982, Accuracy: 1.0\n",
            "Step 18654/22500 - Loss: 0.03252006322145462, Accuracy: 1.0\n",
            "Step 18655/22500 - Loss: 0.04127875715494156, Accuracy: 1.0\n",
            "Step 18656/22500 - Loss: 0.1552743911743164, Accuracy: 0.875\n",
            "Step 18657/22500 - Loss: 0.44579410552978516, Accuracy: 0.875\n",
            "Step 18658/22500 - Loss: 0.041705094277858734, Accuracy: 1.0\n",
            "Step 18659/22500 - Loss: 0.08487272262573242, Accuracy: 1.0\n",
            "Step 18660/22500 - Loss: 0.6276974081993103, Accuracy: 0.75\n",
            "Step 18661/22500 - Loss: 0.1801908165216446, Accuracy: 0.875\n",
            "Step 18662/22500 - Loss: 0.07728149741888046, Accuracy: 1.0\n",
            "Step 18663/22500 - Loss: 0.042914725840091705, Accuracy: 1.0\n",
            "Step 18664/22500 - Loss: 0.1350744366645813, Accuracy: 0.875\n",
            "Step 18665/22500 - Loss: 0.009106453508138657, Accuracy: 1.0\n",
            "Step 18666/22500 - Loss: 0.08955654501914978, Accuracy: 1.0\n",
            "Step 18667/22500 - Loss: 0.06452357023954391, Accuracy: 1.0\n",
            "Step 18668/22500 - Loss: 0.025830553844571114, Accuracy: 1.0\n",
            "Step 18669/22500 - Loss: 0.14075203239917755, Accuracy: 0.875\n",
            "Step 18670/22500 - Loss: 0.008778748102486134, Accuracy: 1.0\n",
            "Step 18671/22500 - Loss: 0.04451072961091995, Accuracy: 1.0\n",
            "Step 18672/22500 - Loss: 0.0442943200469017, Accuracy: 1.0\n",
            "Step 18673/22500 - Loss: 0.37455829977989197, Accuracy: 0.875\n",
            "Step 18674/22500 - Loss: 0.2907235622406006, Accuracy: 0.875\n",
            "Step 18675/22500 - Loss: 0.00778875220566988, Accuracy: 1.0\n",
            "Step 18676/22500 - Loss: 0.009442225098609924, Accuracy: 1.0\n",
            "Step 18677/22500 - Loss: 0.03647294640541077, Accuracy: 1.0\n",
            "Step 18678/22500 - Loss: 0.29619258642196655, Accuracy: 0.875\n",
            "Step 18679/22500 - Loss: 0.057193417102098465, Accuracy: 1.0\n",
            "Step 18680/22500 - Loss: 0.03307722508907318, Accuracy: 1.0\n",
            "Step 18681/22500 - Loss: 0.35431715846061707, Accuracy: 0.875\n",
            "Step 18682/22500 - Loss: 0.009253384545445442, Accuracy: 1.0\n",
            "Step 18683/22500 - Loss: 0.017129825428128242, Accuracy: 1.0\n",
            "Step 18684/22500 - Loss: 0.010074345394968987, Accuracy: 1.0\n",
            "Step 18685/22500 - Loss: 0.029722854495048523, Accuracy: 1.0\n",
            "Step 18686/22500 - Loss: 0.2037300169467926, Accuracy: 0.875\n",
            "Step 18687/22500 - Loss: 0.018091440200805664, Accuracy: 1.0\n",
            "Step 18688/22500 - Loss: 0.32767340540885925, Accuracy: 0.875\n",
            "Step 18689/22500 - Loss: 0.029663674533367157, Accuracy: 1.0\n",
            "Step 18690/22500 - Loss: 0.026740239933133125, Accuracy: 1.0\n",
            "Step 18691/22500 - Loss: 0.009972501546144485, Accuracy: 1.0\n",
            "Step 18692/22500 - Loss: 0.017771488055586815, Accuracy: 1.0\n",
            "Step 18693/22500 - Loss: 0.020960241556167603, Accuracy: 1.0\n",
            "Step 18694/22500 - Loss: 0.03279668092727661, Accuracy: 1.0\n",
            "Step 18695/22500 - Loss: 0.016778936609625816, Accuracy: 1.0\n",
            "Step 18696/22500 - Loss: 0.009067063219845295, Accuracy: 1.0\n",
            "Step 18697/22500 - Loss: 0.04071604460477829, Accuracy: 1.0\n",
            "Step 18698/22500 - Loss: 0.026209110394120216, Accuracy: 1.0\n",
            "Step 18699/22500 - Loss: 0.6012561917304993, Accuracy: 0.875\n",
            "Step 18700/22500 - Loss: 0.05906640738248825, Accuracy: 1.0\n",
            "Step 18701/22500 - Loss: 0.05879703909158707, Accuracy: 1.0\n",
            "Step 18702/22500 - Loss: 0.025671636685729027, Accuracy: 1.0\n",
            "Step 18703/22500 - Loss: 0.023448137566447258, Accuracy: 1.0\n",
            "Step 18704/22500 - Loss: 0.06465601176023483, Accuracy: 1.0\n",
            "Step 18705/22500 - Loss: 0.028004838153719902, Accuracy: 1.0\n",
            "Step 18706/22500 - Loss: 0.06369118392467499, Accuracy: 1.0\n",
            "Step 18707/22500 - Loss: 0.016108904033899307, Accuracy: 1.0\n",
            "Step 18708/22500 - Loss: 0.017360346391797066, Accuracy: 1.0\n",
            "Step 18709/22500 - Loss: 0.8496013283729553, Accuracy: 0.75\n",
            "Step 18710/22500 - Loss: 0.11251962184906006, Accuracy: 0.875\n",
            "Step 18711/22500 - Loss: 0.08838412910699844, Accuracy: 1.0\n",
            "Step 18712/22500 - Loss: 0.07918746024370193, Accuracy: 1.0\n",
            "Step 18713/22500 - Loss: 0.0161499734967947, Accuracy: 1.0\n",
            "Step 18714/22500 - Loss: 0.06844888627529144, Accuracy: 1.0\n",
            "Step 18715/22500 - Loss: 0.010931260883808136, Accuracy: 1.0\n",
            "Step 18716/22500 - Loss: 0.06697981804609299, Accuracy: 1.0\n",
            "Step 18717/22500 - Loss: 0.06755312532186508, Accuracy: 1.0\n",
            "Step 18718/22500 - Loss: 0.23979540169239044, Accuracy: 0.875\n",
            "Step 18719/22500 - Loss: 0.035529814660549164, Accuracy: 1.0\n",
            "Step 18720/22500 - Loss: 0.07603079825639725, Accuracy: 1.0\n",
            "Step 18721/22500 - Loss: 0.006748399697244167, Accuracy: 1.0\n",
            "Step 18722/22500 - Loss: 0.055406227707862854, Accuracy: 1.0\n",
            "Step 18723/22500 - Loss: 0.11447909474372864, Accuracy: 1.0\n",
            "Step 18724/22500 - Loss: 0.02540992572903633, Accuracy: 1.0\n",
            "Step 18725/22500 - Loss: 0.10158251225948334, Accuracy: 1.0\n",
            "Step 18726/22500 - Loss: 0.18205276131629944, Accuracy: 0.875\n",
            "Step 18727/22500 - Loss: 0.05068744346499443, Accuracy: 1.0\n",
            "Step 18728/22500 - Loss: 0.0037567601539194584, Accuracy: 1.0\n",
            "Step 18729/22500 - Loss: 0.028470538556575775, Accuracy: 1.0\n",
            "Step 18730/22500 - Loss: 0.15341752767562866, Accuracy: 0.875\n",
            "Step 18731/22500 - Loss: 0.06057025492191315, Accuracy: 1.0\n",
            "Step 18732/22500 - Loss: 1.2792538404464722, Accuracy: 0.625\n",
            "Step 18733/22500 - Loss: 0.009500582702457905, Accuracy: 1.0\n",
            "Step 18734/22500 - Loss: 0.011583899147808552, Accuracy: 1.0\n",
            "Step 18735/22500 - Loss: 0.12847359478473663, Accuracy: 0.875\n",
            "Step 18736/22500 - Loss: 0.032106440514326096, Accuracy: 1.0\n",
            "Step 18737/22500 - Loss: 0.010705282911658287, Accuracy: 1.0\n",
            "Step 18738/22500 - Loss: 0.09520111232995987, Accuracy: 1.0\n",
            "Step 18739/22500 - Loss: 0.0017481230897828937, Accuracy: 1.0\n",
            "Step 18740/22500 - Loss: 0.22617745399475098, Accuracy: 0.875\n",
            "Step 18741/22500 - Loss: 0.04823397845029831, Accuracy: 1.0\n",
            "Step 18742/22500 - Loss: 0.09155655652284622, Accuracy: 1.0\n",
            "Step 18743/22500 - Loss: 0.5909050703048706, Accuracy: 0.875\n",
            "Step 18744/22500 - Loss: 0.021467717364430428, Accuracy: 1.0\n",
            "Step 18745/22500 - Loss: 0.1653933972120285, Accuracy: 1.0\n",
            "Step 18746/22500 - Loss: 0.2034437209367752, Accuracy: 0.875\n",
            "Step 18747/22500 - Loss: 0.04283052682876587, Accuracy: 1.0\n",
            "Step 18748/22500 - Loss: 0.01050923764705658, Accuracy: 1.0\n",
            "Step 18749/22500 - Loss: 0.019977422431111336, Accuracy: 1.0\n",
            "Step 18750/22500 - Loss: 0.027199188247323036, Accuracy: 1.0\n",
            "Step 18751/22500 - Loss: 0.13442231714725494, Accuracy: 1.0\n",
            "Step 18752/22500 - Loss: 0.010501688346266747, Accuracy: 1.0\n",
            "Step 18753/22500 - Loss: 0.2758103907108307, Accuracy: 0.875\n",
            "Step 18754/22500 - Loss: 0.046098168939352036, Accuracy: 1.0\n",
            "Step 18755/22500 - Loss: 0.1089119240641594, Accuracy: 0.875\n",
            "Step 18756/22500 - Loss: 0.07881363481283188, Accuracy: 1.0\n",
            "Step 18757/22500 - Loss: 0.02793184295296669, Accuracy: 1.0\n",
            "Step 18758/22500 - Loss: 0.02108471840620041, Accuracy: 1.0\n",
            "Step 18759/22500 - Loss: 0.02368735522031784, Accuracy: 1.0\n",
            "Step 18760/22500 - Loss: 0.008406635373830795, Accuracy: 1.0\n",
            "Step 18761/22500 - Loss: 0.4806525707244873, Accuracy: 0.875\n",
            "Step 18762/22500 - Loss: 0.018849683925509453, Accuracy: 1.0\n",
            "Step 18763/22500 - Loss: 0.09323115646839142, Accuracy: 1.0\n",
            "Step 18764/22500 - Loss: 0.027837103232741356, Accuracy: 1.0\n",
            "Step 18765/22500 - Loss: 0.20072431862354279, Accuracy: 0.875\n",
            "Step 18766/22500 - Loss: 0.34248214960098267, Accuracy: 0.875\n",
            "Step 18767/22500 - Loss: 0.00863115955144167, Accuracy: 1.0\n",
            "Step 18768/22500 - Loss: 0.08230191469192505, Accuracy: 1.0\n",
            "Step 18769/22500 - Loss: 0.31854507327079773, Accuracy: 0.875\n",
            "Step 18770/22500 - Loss: 0.08245047926902771, Accuracy: 1.0\n",
            "Step 18771/22500 - Loss: 0.07935276627540588, Accuracy: 1.0\n",
            "Step 18772/22500 - Loss: 0.06470149755477905, Accuracy: 1.0\n",
            "Step 18773/22500 - Loss: 0.3605554401874542, Accuracy: 0.875\n",
            "Step 18774/22500 - Loss: 0.03542676568031311, Accuracy: 1.0\n",
            "Step 18775/22500 - Loss: 0.23136350512504578, Accuracy: 0.875\n",
            "Step 18776/22500 - Loss: 0.019702687859535217, Accuracy: 1.0\n",
            "Step 18777/22500 - Loss: 0.11181943118572235, Accuracy: 1.0\n",
            "Step 18778/22500 - Loss: 0.028464708477258682, Accuracy: 1.0\n",
            "Step 18779/22500 - Loss: 0.004087711684405804, Accuracy: 1.0\n",
            "Step 18780/22500 - Loss: 0.09257693588733673, Accuracy: 0.875\n",
            "Step 18781/22500 - Loss: 0.2494441270828247, Accuracy: 0.875\n",
            "Step 18782/22500 - Loss: 0.04118947312235832, Accuracy: 1.0\n",
            "Step 18783/22500 - Loss: 0.20612651109695435, Accuracy: 0.875\n",
            "Step 18784/22500 - Loss: 0.11266449838876724, Accuracy: 1.0\n",
            "Step 18785/22500 - Loss: 0.3890783488750458, Accuracy: 0.875\n",
            "Step 18786/22500 - Loss: 0.04953351244330406, Accuracy: 1.0\n",
            "Step 18787/22500 - Loss: 0.012188204564154148, Accuracy: 1.0\n",
            "Step 18788/22500 - Loss: 0.4286454916000366, Accuracy: 0.875\n",
            "Step 18789/22500 - Loss: 0.011243334040045738, Accuracy: 1.0\n",
            "Step 18790/22500 - Loss: 0.19667722284793854, Accuracy: 0.875\n",
            "Step 18791/22500 - Loss: 0.08207638561725616, Accuracy: 1.0\n",
            "Step 18792/22500 - Loss: 0.010097475722432137, Accuracy: 1.0\n",
            "Step 18793/22500 - Loss: 0.09453432261943817, Accuracy: 1.0\n",
            "Step 18794/22500 - Loss: 0.14459846913814545, Accuracy: 0.875\n",
            "Step 18795/22500 - Loss: 0.05341458320617676, Accuracy: 1.0\n",
            "Step 18796/22500 - Loss: 0.05965210124850273, Accuracy: 1.0\n",
            "Step 18797/22500 - Loss: 0.11328185349702835, Accuracy: 0.875\n",
            "Step 18798/22500 - Loss: 0.006366934161633253, Accuracy: 1.0\n",
            "Step 18799/22500 - Loss: 0.04213700070977211, Accuracy: 1.0\n",
            "Step 18800/22500 - Loss: 0.03483764827251434, Accuracy: 1.0\n",
            "Step 18801/22500 - Loss: 0.031236667186021805, Accuracy: 1.0\n",
            "Step 18802/22500 - Loss: 0.06110798940062523, Accuracy: 1.0\n",
            "Step 18803/22500 - Loss: 0.13221332430839539, Accuracy: 1.0\n",
            "Step 18804/22500 - Loss: 0.4070158898830414, Accuracy: 0.75\n",
            "Step 18805/22500 - Loss: 0.08187057822942734, Accuracy: 1.0\n",
            "Step 18806/22500 - Loss: 0.013159294612705708, Accuracy: 1.0\n",
            "Step 18807/22500 - Loss: 0.058976542204618454, Accuracy: 1.0\n",
            "Step 18808/22500 - Loss: 0.12230098992586136, Accuracy: 1.0\n",
            "Step 18809/22500 - Loss: 0.007695120759308338, Accuracy: 1.0\n",
            "Step 18810/22500 - Loss: 0.6309829354286194, Accuracy: 0.875\n",
            "Step 18811/22500 - Loss: 0.14219455420970917, Accuracy: 1.0\n",
            "Step 18812/22500 - Loss: 0.1126258373260498, Accuracy: 1.0\n",
            "Step 18813/22500 - Loss: 0.06857632845640182, Accuracy: 1.0\n",
            "Step 18814/22500 - Loss: 0.0871923640370369, Accuracy: 1.0\n",
            "Step 18815/22500 - Loss: 0.005035162903368473, Accuracy: 1.0\n",
            "Step 18816/22500 - Loss: 0.06289121508598328, Accuracy: 1.0\n",
            "Step 18817/22500 - Loss: 0.23616957664489746, Accuracy: 0.875\n",
            "Step 18818/22500 - Loss: 0.008672785945236683, Accuracy: 1.0\n",
            "Step 18819/22500 - Loss: 0.007224024273455143, Accuracy: 1.0\n",
            "Step 18820/22500 - Loss: 0.35282132029533386, Accuracy: 0.875\n",
            "Step 18821/22500 - Loss: 0.034249525517225266, Accuracy: 1.0\n",
            "Step 18822/22500 - Loss: 0.0024218722246587276, Accuracy: 1.0\n",
            "Step 18823/22500 - Loss: 0.008911527693271637, Accuracy: 1.0\n",
            "Step 18824/22500 - Loss: 0.09103339910507202, Accuracy: 1.0\n",
            "Step 18825/22500 - Loss: 0.11325748264789581, Accuracy: 1.0\n",
            "Step 18826/22500 - Loss: 0.08106040954589844, Accuracy: 1.0\n",
            "Step 18827/22500 - Loss: 0.020065678283572197, Accuracy: 1.0\n",
            "Step 18828/22500 - Loss: 0.008441896177828312, Accuracy: 1.0\n",
            "Step 18829/22500 - Loss: 0.318221777677536, Accuracy: 0.875\n",
            "Step 18830/22500 - Loss: 0.018735984340310097, Accuracy: 1.0\n",
            "Step 18831/22500 - Loss: 0.13494423031806946, Accuracy: 0.875\n",
            "Step 18832/22500 - Loss: 0.014326916076242924, Accuracy: 1.0\n",
            "Step 18833/22500 - Loss: 0.06493230909109116, Accuracy: 1.0\n",
            "Step 18834/22500 - Loss: 0.06352236866950989, Accuracy: 1.0\n",
            "Step 18835/22500 - Loss: 0.012267058715224266, Accuracy: 1.0\n",
            "Step 18836/22500 - Loss: 0.5880511403083801, Accuracy: 0.875\n",
            "Step 18837/22500 - Loss: 0.3677476644515991, Accuracy: 0.875\n",
            "Step 18838/22500 - Loss: 0.004511520732194185, Accuracy: 1.0\n",
            "Step 18839/22500 - Loss: 0.028883781284093857, Accuracy: 1.0\n",
            "Step 18840/22500 - Loss: 0.006449140142649412, Accuracy: 1.0\n",
            "Step 18841/22500 - Loss: 0.42054176330566406, Accuracy: 0.875\n",
            "Step 18842/22500 - Loss: 0.11333438009023666, Accuracy: 0.875\n",
            "Step 18843/22500 - Loss: 0.2519867718219757, Accuracy: 0.875\n",
            "Step 18844/22500 - Loss: 0.027515968307852745, Accuracy: 1.0\n",
            "Step 18845/22500 - Loss: 0.061791956424713135, Accuracy: 1.0\n",
            "Step 18846/22500 - Loss: 0.031767576932907104, Accuracy: 1.0\n",
            "Step 18847/22500 - Loss: 0.16496992111206055, Accuracy: 0.875\n",
            "Step 18848/22500 - Loss: 0.06100403890013695, Accuracy: 1.0\n",
            "Step 18849/22500 - Loss: 0.005112249404191971, Accuracy: 1.0\n",
            "Step 18850/22500 - Loss: 0.057942163199186325, Accuracy: 1.0\n",
            "Step 18851/22500 - Loss: 0.009465929120779037, Accuracy: 1.0\n",
            "Step 18852/22500 - Loss: 0.38447585701942444, Accuracy: 0.875\n",
            "Step 18853/22500 - Loss: 0.05884875729680061, Accuracy: 1.0\n",
            "Step 18854/22500 - Loss: 0.03140675649046898, Accuracy: 1.0\n",
            "Step 18855/22500 - Loss: 0.005749351345002651, Accuracy: 1.0\n",
            "Step 18856/22500 - Loss: 0.05143769830465317, Accuracy: 1.0\n",
            "Step 18857/22500 - Loss: 0.005470726639032364, Accuracy: 1.0\n",
            "Step 18858/22500 - Loss: 0.047967005521059036, Accuracy: 1.0\n",
            "Step 18859/22500 - Loss: 0.14424929022789001, Accuracy: 0.875\n",
            "Step 18860/22500 - Loss: 0.05928057059645653, Accuracy: 1.0\n",
            "Step 18861/22500 - Loss: 0.44820070266723633, Accuracy: 0.875\n",
            "Step 18862/22500 - Loss: 0.18311342597007751, Accuracy: 0.875\n",
            "Step 18863/22500 - Loss: 0.006353480741381645, Accuracy: 1.0\n",
            "Step 18864/22500 - Loss: 0.007354368455708027, Accuracy: 1.0\n",
            "Step 18865/22500 - Loss: 0.20713458955287933, Accuracy: 0.875\n",
            "Step 18866/22500 - Loss: 0.04997533932328224, Accuracy: 1.0\n",
            "Step 18867/22500 - Loss: 0.18230289220809937, Accuracy: 0.875\n",
            "Step 18868/22500 - Loss: 0.5795104503631592, Accuracy: 0.875\n",
            "Step 18869/22500 - Loss: 0.01634351536631584, Accuracy: 1.0\n",
            "Step 18870/22500 - Loss: 0.16936403512954712, Accuracy: 0.875\n",
            "Step 18871/22500 - Loss: 0.04621128737926483, Accuracy: 1.0\n",
            "Step 18872/22500 - Loss: 0.004177591763436794, Accuracy: 1.0\n",
            "Step 18873/22500 - Loss: 0.10465037077665329, Accuracy: 0.875\n",
            "Step 18874/22500 - Loss: 0.10448122769594193, Accuracy: 1.0\n",
            "Step 18875/22500 - Loss: 0.0009724411065690219, Accuracy: 1.0\n",
            "Step 18876/22500 - Loss: 0.10630827397108078, Accuracy: 1.0\n",
            "Step 18877/22500 - Loss: 0.13194021582603455, Accuracy: 1.0\n",
            "Step 18878/22500 - Loss: 0.0902671366930008, Accuracy: 1.0\n",
            "Step 18879/22500 - Loss: 0.02489367127418518, Accuracy: 1.0\n",
            "Step 18880/22500 - Loss: 0.05554398149251938, Accuracy: 1.0\n",
            "Step 18881/22500 - Loss: 0.045529745519161224, Accuracy: 1.0\n",
            "Step 18882/22500 - Loss: 0.04401647299528122, Accuracy: 1.0\n",
            "Step 18883/22500 - Loss: 0.022852489724755287, Accuracy: 1.0\n",
            "Step 18884/22500 - Loss: 0.010589376091957092, Accuracy: 1.0\n",
            "Step 18885/22500 - Loss: 0.958866536617279, Accuracy: 0.875\n",
            "Step 18886/22500 - Loss: 0.02091783657670021, Accuracy: 1.0\n",
            "Step 18887/22500 - Loss: 0.05386749282479286, Accuracy: 1.0\n",
            "Step 18888/22500 - Loss: 0.03828628733754158, Accuracy: 1.0\n",
            "Step 18889/22500 - Loss: 0.057798974215984344, Accuracy: 1.0\n",
            "Step 18890/22500 - Loss: 0.014811980538070202, Accuracy: 1.0\n",
            "Step 18891/22500 - Loss: 0.0034482020419090986, Accuracy: 1.0\n",
            "Step 18892/22500 - Loss: 0.028540626168251038, Accuracy: 1.0\n",
            "Step 18893/22500 - Loss: 0.07490096986293793, Accuracy: 1.0\n",
            "Step 18894/22500 - Loss: 0.06858637183904648, Accuracy: 1.0\n",
            "Step 18895/22500 - Loss: 0.16419699788093567, Accuracy: 0.875\n",
            "Step 18896/22500 - Loss: 0.05232090502977371, Accuracy: 1.0\n",
            "Step 18897/22500 - Loss: 1.0119973421096802, Accuracy: 0.5\n",
            "Step 18898/22500 - Loss: 0.2968898415565491, Accuracy: 0.875\n",
            "Step 18899/22500 - Loss: 0.09139534085988998, Accuracy: 1.0\n",
            "Step 18900/22500 - Loss: 0.04353618994355202, Accuracy: 1.0\n",
            "Step 18901/22500 - Loss: 0.011471902951598167, Accuracy: 1.0\n",
            "Step 18902/22500 - Loss: 0.044291902333498, Accuracy: 1.0\n",
            "Step 18903/22500 - Loss: 0.016800448298454285, Accuracy: 1.0\n",
            "Step 18904/22500 - Loss: 0.027055498212575912, Accuracy: 1.0\n",
            "Step 18905/22500 - Loss: 0.04438840597867966, Accuracy: 1.0\n",
            "Step 18906/22500 - Loss: 0.01925474964082241, Accuracy: 1.0\n",
            "Step 18907/22500 - Loss: 0.022939009591937065, Accuracy: 1.0\n",
            "Step 18908/22500 - Loss: 0.023070186376571655, Accuracy: 1.0\n",
            "Step 18909/22500 - Loss: 0.0284405630081892, Accuracy: 1.0\n",
            "Step 18910/22500 - Loss: 0.37490808963775635, Accuracy: 0.875\n",
            "Step 18911/22500 - Loss: 0.006252722814679146, Accuracy: 1.0\n",
            "Step 18912/22500 - Loss: 0.006894709542393684, Accuracy: 1.0\n",
            "Step 18913/22500 - Loss: 0.03853799030184746, Accuracy: 1.0\n",
            "Step 18914/22500 - Loss: 0.023907195776700974, Accuracy: 1.0\n",
            "Step 18915/22500 - Loss: 0.027373667806386948, Accuracy: 1.0\n",
            "Step 18916/22500 - Loss: 0.23408207297325134, Accuracy: 0.875\n",
            "Step 18917/22500 - Loss: 0.15087337791919708, Accuracy: 0.875\n",
            "Step 18918/22500 - Loss: 0.05942603945732117, Accuracy: 1.0\n",
            "Step 18919/22500 - Loss: 0.014687777496874332, Accuracy: 1.0\n",
            "Step 18920/22500 - Loss: 0.013855482451617718, Accuracy: 1.0\n",
            "Step 18921/22500 - Loss: 0.0631878450512886, Accuracy: 1.0\n",
            "Step 18922/22500 - Loss: 0.0014318126486614347, Accuracy: 1.0\n",
            "Step 18923/22500 - Loss: 0.038330599665641785, Accuracy: 1.0\n",
            "Step 18924/22500 - Loss: 0.01885165274143219, Accuracy: 1.0\n",
            "Step 18925/22500 - Loss: 0.492655485868454, Accuracy: 0.875\n",
            "Step 18926/22500 - Loss: 0.07399385422468185, Accuracy: 1.0\n",
            "Step 18927/22500 - Loss: 0.34431248903274536, Accuracy: 0.875\n",
            "Step 18928/22500 - Loss: 0.20786453783512115, Accuracy: 0.875\n",
            "Step 18929/22500 - Loss: 0.029889995232224464, Accuracy: 1.0\n",
            "Step 18930/22500 - Loss: 0.04190611094236374, Accuracy: 1.0\n",
            "Step 18931/22500 - Loss: 0.10462773591279984, Accuracy: 1.0\n",
            "Step 18932/22500 - Loss: 0.07638559490442276, Accuracy: 1.0\n",
            "Step 18933/22500 - Loss: 0.02814624458551407, Accuracy: 1.0\n",
            "Step 18934/22500 - Loss: 0.16148324310779572, Accuracy: 1.0\n",
            "Step 18935/22500 - Loss: 0.022116711363196373, Accuracy: 1.0\n",
            "Step 18936/22500 - Loss: 0.05124947428703308, Accuracy: 1.0\n",
            "Step 18937/22500 - Loss: 0.27772989869117737, Accuracy: 0.875\n",
            "Step 18938/22500 - Loss: 0.02545471303164959, Accuracy: 1.0\n",
            "Step 18939/22500 - Loss: 0.024042025208473206, Accuracy: 1.0\n",
            "Step 18940/22500 - Loss: 0.08898289501667023, Accuracy: 1.0\n",
            "Step 18941/22500 - Loss: 0.29432350397109985, Accuracy: 0.875\n",
            "Step 18942/22500 - Loss: 0.00421476736664772, Accuracy: 1.0\n",
            "Step 18943/22500 - Loss: 0.08151867985725403, Accuracy: 1.0\n",
            "Step 18944/22500 - Loss: 0.033983130007982254, Accuracy: 1.0\n",
            "Step 18945/22500 - Loss: 0.4146377742290497, Accuracy: 0.875\n",
            "Step 18946/22500 - Loss: 0.017937535420060158, Accuracy: 1.0\n",
            "Step 18947/22500 - Loss: 0.18984165787696838, Accuracy: 0.875\n",
            "Step 18948/22500 - Loss: 0.051353905349969864, Accuracy: 1.0\n",
            "Step 18949/22500 - Loss: 0.47861868143081665, Accuracy: 0.75\n",
            "Step 18950/22500 - Loss: 0.4628468155860901, Accuracy: 0.875\n",
            "Step 18951/22500 - Loss: 0.23136025667190552, Accuracy: 0.875\n",
            "Step 18952/22500 - Loss: 0.006922454573214054, Accuracy: 1.0\n",
            "Step 18953/22500 - Loss: 0.5519909858703613, Accuracy: 0.875\n",
            "Step 18954/22500 - Loss: 0.5353777408599854, Accuracy: 0.875\n",
            "Step 18955/22500 - Loss: 0.023086298257112503, Accuracy: 1.0\n",
            "Step 18956/22500 - Loss: 0.01787428930401802, Accuracy: 1.0\n",
            "Step 18957/22500 - Loss: 0.009045129641890526, Accuracy: 1.0\n",
            "Step 18958/22500 - Loss: 0.30311545729637146, Accuracy: 0.75\n",
            "Step 18959/22500 - Loss: 0.20639555156230927, Accuracy: 0.875\n",
            "Step 18960/22500 - Loss: 0.03140014410018921, Accuracy: 1.0\n",
            "Step 18961/22500 - Loss: 0.07063432782888412, Accuracy: 1.0\n",
            "Step 18962/22500 - Loss: 0.17338360846042633, Accuracy: 0.875\n",
            "Step 18963/22500 - Loss: 0.0692446380853653, Accuracy: 1.0\n",
            "Step 18964/22500 - Loss: 0.3246611952781677, Accuracy: 0.875\n",
            "Step 18965/22500 - Loss: 0.11025190353393555, Accuracy: 0.875\n",
            "Step 18966/22500 - Loss: 0.1400466412305832, Accuracy: 0.875\n",
            "Step 18967/22500 - Loss: 0.004920734092593193, Accuracy: 1.0\n",
            "Step 18968/22500 - Loss: 0.019826233386993408, Accuracy: 1.0\n",
            "Step 18969/22500 - Loss: 0.026464885100722313, Accuracy: 1.0\n",
            "Step 18970/22500 - Loss: 0.021232038736343384, Accuracy: 1.0\n",
            "Step 18971/22500 - Loss: 0.4475002884864807, Accuracy: 0.75\n",
            "Step 18972/22500 - Loss: 0.0970693975687027, Accuracy: 1.0\n",
            "Step 18973/22500 - Loss: 0.09838271886110306, Accuracy: 0.875\n",
            "Step 18974/22500 - Loss: 0.12831726670265198, Accuracy: 1.0\n",
            "Step 18975/22500 - Loss: 0.0025295440573245287, Accuracy: 1.0\n",
            "Step 18976/22500 - Loss: 0.007643509656190872, Accuracy: 1.0\n",
            "Step 18977/22500 - Loss: 0.025123588740825653, Accuracy: 1.0\n",
            "Step 18978/22500 - Loss: 0.03713716194033623, Accuracy: 1.0\n",
            "Step 18979/22500 - Loss: 0.0067033651284873486, Accuracy: 1.0\n",
            "Step 18980/22500 - Loss: 0.11397656798362732, Accuracy: 0.875\n",
            "Step 18981/22500 - Loss: 0.029452471062541008, Accuracy: 1.0\n",
            "Step 18982/22500 - Loss: 0.028787150979042053, Accuracy: 1.0\n",
            "Step 18983/22500 - Loss: 0.005871268454939127, Accuracy: 1.0\n",
            "Step 18984/22500 - Loss: 0.0030429940670728683, Accuracy: 1.0\n",
            "Step 18985/22500 - Loss: 0.21924170851707458, Accuracy: 0.875\n",
            "Step 18986/22500 - Loss: 0.058408915996551514, Accuracy: 1.0\n",
            "Step 18987/22500 - Loss: 0.07321745157241821, Accuracy: 1.0\n",
            "Step 18988/22500 - Loss: 0.028381386771798134, Accuracy: 1.0\n",
            "Step 18989/22500 - Loss: 0.008619992062449455, Accuracy: 1.0\n",
            "Step 18990/22500 - Loss: 0.007698163390159607, Accuracy: 1.0\n",
            "Step 18991/22500 - Loss: 0.06435275822877884, Accuracy: 1.0\n",
            "Step 18992/22500 - Loss: 0.2791854739189148, Accuracy: 0.875\n",
            "Step 18993/22500 - Loss: 0.23420774936676025, Accuracy: 0.875\n",
            "Step 18994/22500 - Loss: 0.16145004332065582, Accuracy: 0.875\n",
            "Step 18995/22500 - Loss: 0.08711887151002884, Accuracy: 1.0\n",
            "Step 18996/22500 - Loss: 0.03157325088977814, Accuracy: 1.0\n",
            "Step 18997/22500 - Loss: 0.05321448668837547, Accuracy: 1.0\n",
            "Step 18998/22500 - Loss: 0.048493433743715286, Accuracy: 1.0\n",
            "Step 18999/22500 - Loss: 0.8560590744018555, Accuracy: 0.75\n",
            "Step 19000/22500 - Loss: 0.019200453534722328, Accuracy: 1.0\n",
            "Step 19001/22500 - Loss: 0.06774752587080002, Accuracy: 1.0\n",
            "Step 19002/22500 - Loss: 0.06144189462065697, Accuracy: 1.0\n",
            "Step 19003/22500 - Loss: 0.1407116949558258, Accuracy: 1.0\n",
            "Step 19004/22500 - Loss: 0.005017382558435202, Accuracy: 1.0\n",
            "Step 19005/22500 - Loss: 0.3194164037704468, Accuracy: 0.75\n",
            "Step 19006/22500 - Loss: 0.04318587854504585, Accuracy: 1.0\n",
            "Step 19007/22500 - Loss: 0.14047841727733612, Accuracy: 0.875\n",
            "Step 19008/22500 - Loss: 0.6572040915489197, Accuracy: 0.75\n",
            "Step 19009/22500 - Loss: 0.08664131909608841, Accuracy: 1.0\n",
            "Step 19010/22500 - Loss: 0.21744567155838013, Accuracy: 0.875\n",
            "Step 19011/22500 - Loss: 0.014103071764111519, Accuracy: 1.0\n",
            "Step 19012/22500 - Loss: 0.0023672280367463827, Accuracy: 1.0\n",
            "Step 19013/22500 - Loss: 0.0277188029140234, Accuracy: 1.0\n",
            "Step 19014/22500 - Loss: 0.061103709042072296, Accuracy: 1.0\n",
            "Step 19015/22500 - Loss: 0.2267356812953949, Accuracy: 0.875\n",
            "Step 19016/22500 - Loss: 0.037457119673490524, Accuracy: 1.0\n",
            "Step 19017/22500 - Loss: 0.06439747661352158, Accuracy: 1.0\n",
            "Step 19018/22500 - Loss: 0.24491249024868011, Accuracy: 0.75\n",
            "Step 19019/22500 - Loss: 0.19555425643920898, Accuracy: 0.875\n",
            "Step 19020/22500 - Loss: 0.0314423143863678, Accuracy: 1.0\n",
            "Step 19021/22500 - Loss: 0.023366888985037804, Accuracy: 1.0\n",
            "Step 19022/22500 - Loss: 0.009972658008337021, Accuracy: 1.0\n",
            "Step 19023/22500 - Loss: 0.05654771998524666, Accuracy: 1.0\n",
            "Step 19024/22500 - Loss: 0.005252034403383732, Accuracy: 1.0\n",
            "Step 19025/22500 - Loss: 0.04933471605181694, Accuracy: 1.0\n",
            "Step 19026/22500 - Loss: 0.11979267001152039, Accuracy: 1.0\n",
            "Step 19027/22500 - Loss: 0.31458961963653564, Accuracy: 0.875\n",
            "Step 19028/22500 - Loss: 1.2517929077148438, Accuracy: 0.625\n",
            "Step 19029/22500 - Loss: 0.04403982684016228, Accuracy: 1.0\n",
            "Step 19030/22500 - Loss: 0.010560465045273304, Accuracy: 1.0\n",
            "Step 19031/22500 - Loss: 0.016368266195058823, Accuracy: 1.0\n",
            "Step 19032/22500 - Loss: 0.01713157631456852, Accuracy: 1.0\n",
            "Step 19033/22500 - Loss: 0.01960616558790207, Accuracy: 1.0\n",
            "Step 19034/22500 - Loss: 0.16148725152015686, Accuracy: 0.875\n",
            "Step 19035/22500 - Loss: 0.17475667595863342, Accuracy: 0.875\n",
            "Step 19036/22500 - Loss: 0.011808272451162338, Accuracy: 1.0\n",
            "Step 19037/22500 - Loss: 0.02766398712992668, Accuracy: 1.0\n",
            "Step 19038/22500 - Loss: 0.0033187002409249544, Accuracy: 1.0\n",
            "Step 19039/22500 - Loss: 0.1566682904958725, Accuracy: 1.0\n",
            "Step 19040/22500 - Loss: 0.043894361704587936, Accuracy: 1.0\n",
            "Step 19041/22500 - Loss: 0.03158220276236534, Accuracy: 1.0\n",
            "Step 19042/22500 - Loss: 0.05646350234746933, Accuracy: 1.0\n",
            "Step 19043/22500 - Loss: 0.18743063509464264, Accuracy: 0.875\n",
            "Step 19044/22500 - Loss: 0.09834989905357361, Accuracy: 1.0\n",
            "Step 19045/22500 - Loss: 0.1751174032688141, Accuracy: 0.875\n",
            "Step 19046/22500 - Loss: 0.048985909670591354, Accuracy: 1.0\n",
            "Step 19047/22500 - Loss: 0.04267534241080284, Accuracy: 1.0\n",
            "Step 19048/22500 - Loss: 0.032380424439907074, Accuracy: 1.0\n",
            "Step 19049/22500 - Loss: 0.1984991580247879, Accuracy: 0.875\n",
            "Step 19050/22500 - Loss: 0.161821648478508, Accuracy: 0.875\n",
            "Step 19051/22500 - Loss: 0.03335236757993698, Accuracy: 1.0\n",
            "Step 19052/22500 - Loss: 0.007911911234259605, Accuracy: 1.0\n",
            "Step 19053/22500 - Loss: 0.018779207020998, Accuracy: 1.0\n",
            "Step 19054/22500 - Loss: 0.40412482619285583, Accuracy: 0.75\n",
            "Step 19055/22500 - Loss: 0.03174539655447006, Accuracy: 1.0\n",
            "Step 19056/22500 - Loss: 0.5219096541404724, Accuracy: 0.875\n",
            "Step 19057/22500 - Loss: 0.07723388820886612, Accuracy: 1.0\n",
            "Step 19058/22500 - Loss: 0.050130024552345276, Accuracy: 1.0\n",
            "Step 19059/22500 - Loss: 0.24385154247283936, Accuracy: 0.875\n",
            "Step 19060/22500 - Loss: 0.20110081136226654, Accuracy: 0.875\n",
            "Step 19061/22500 - Loss: 0.03000454790890217, Accuracy: 1.0\n",
            "Step 19062/22500 - Loss: 0.05570952221751213, Accuracy: 1.0\n",
            "Step 19063/22500 - Loss: 0.00327576557174325, Accuracy: 1.0\n",
            "Step 19064/22500 - Loss: 0.005722047295421362, Accuracy: 1.0\n",
            "Step 19065/22500 - Loss: 0.06669212132692337, Accuracy: 1.0\n",
            "Step 19066/22500 - Loss: 0.015757350251078606, Accuracy: 1.0\n",
            "Step 19067/22500 - Loss: 0.00152552779763937, Accuracy: 1.0\n",
            "Step 19068/22500 - Loss: 0.011338732205331326, Accuracy: 1.0\n",
            "Step 19069/22500 - Loss: 0.3893265426158905, Accuracy: 0.875\n",
            "Step 19070/22500 - Loss: 0.027629395946860313, Accuracy: 1.0\n",
            "Step 19071/22500 - Loss: 0.8688692450523376, Accuracy: 0.875\n",
            "Step 19072/22500 - Loss: 0.023455921560525894, Accuracy: 1.0\n",
            "Step 19073/22500 - Loss: 0.027826381847262383, Accuracy: 1.0\n",
            "Step 19074/22500 - Loss: 0.0299477931112051, Accuracy: 1.0\n",
            "Step 19075/22500 - Loss: 0.018743401393294334, Accuracy: 1.0\n",
            "Step 19076/22500 - Loss: 0.050345778465270996, Accuracy: 1.0\n",
            "Step 19077/22500 - Loss: 0.010286523960530758, Accuracy: 1.0\n",
            "Step 19078/22500 - Loss: 0.0926528349518776, Accuracy: 1.0\n",
            "Step 19079/22500 - Loss: 0.13016313314437866, Accuracy: 0.875\n",
            "Step 19080/22500 - Loss: 0.052984487265348434, Accuracy: 1.0\n",
            "Step 19081/22500 - Loss: 0.017602464184165, Accuracy: 1.0\n",
            "Step 19082/22500 - Loss: 0.01591336913406849, Accuracy: 1.0\n",
            "Step 19083/22500 - Loss: 0.09168238937854767, Accuracy: 1.0\n",
            "Step 19084/22500 - Loss: 0.13674621284008026, Accuracy: 0.875\n",
            "Step 19085/22500 - Loss: 0.005278628319501877, Accuracy: 1.0\n",
            "Step 19086/22500 - Loss: 0.22812314331531525, Accuracy: 0.875\n",
            "Step 19087/22500 - Loss: 0.009405895136296749, Accuracy: 1.0\n",
            "Step 19088/22500 - Loss: 0.05777515843510628, Accuracy: 1.0\n",
            "Step 19089/22500 - Loss: 0.04643038660287857, Accuracy: 1.0\n",
            "Step 19090/22500 - Loss: 0.0424719862639904, Accuracy: 1.0\n",
            "Step 19091/22500 - Loss: 0.34129005670547485, Accuracy: 0.875\n",
            "Step 19092/22500 - Loss: 0.02386448346078396, Accuracy: 1.0\n",
            "Step 19093/22500 - Loss: 0.2707464098930359, Accuracy: 0.875\n",
            "Step 19094/22500 - Loss: 0.04930340126156807, Accuracy: 1.0\n",
            "Step 19095/22500 - Loss: 0.21965306997299194, Accuracy: 0.875\n",
            "Step 19096/22500 - Loss: 0.03397170454263687, Accuracy: 1.0\n",
            "Step 19097/22500 - Loss: 0.07332389056682587, Accuracy: 1.0\n",
            "Step 19098/22500 - Loss: 0.01084221713244915, Accuracy: 1.0\n",
            "Step 19099/22500 - Loss: 0.009936787188053131, Accuracy: 1.0\n",
            "Step 19100/22500 - Loss: 0.05640881136059761, Accuracy: 1.0\n",
            "Step 19101/22500 - Loss: 0.05769253149628639, Accuracy: 1.0\n",
            "Step 19102/22500 - Loss: 0.3461093604564667, Accuracy: 0.875\n",
            "Step 19103/22500 - Loss: 0.15204480290412903, Accuracy: 0.875\n",
            "Step 19104/22500 - Loss: 0.015504986047744751, Accuracy: 1.0\n",
            "Step 19105/22500 - Loss: 0.012372741475701332, Accuracy: 1.0\n",
            "Step 19106/22500 - Loss: 0.02650357037782669, Accuracy: 1.0\n",
            "Step 19107/22500 - Loss: 0.007186498027294874, Accuracy: 1.0\n",
            "Step 19108/22500 - Loss: 0.11343694478273392, Accuracy: 0.875\n",
            "Step 19109/22500 - Loss: 0.05455123633146286, Accuracy: 1.0\n",
            "Step 19110/22500 - Loss: 0.07034730166196823, Accuracy: 1.0\n",
            "Step 19111/22500 - Loss: 0.014710424467921257, Accuracy: 1.0\n",
            "Step 19112/22500 - Loss: 0.07956753671169281, Accuracy: 1.0\n",
            "Step 19113/22500 - Loss: 0.06056312844157219, Accuracy: 1.0\n",
            "Step 19114/22500 - Loss: 0.04353354126214981, Accuracy: 1.0\n",
            "Step 19115/22500 - Loss: 0.00461964076384902, Accuracy: 1.0\n",
            "Step 19116/22500 - Loss: 0.011630737222731113, Accuracy: 1.0\n",
            "Step 19117/22500 - Loss: 0.1004311591386795, Accuracy: 0.875\n",
            "Step 19118/22500 - Loss: 0.05098221078515053, Accuracy: 1.0\n",
            "Step 19119/22500 - Loss: 0.004574126563966274, Accuracy: 1.0\n",
            "Step 19120/22500 - Loss: 0.1295909285545349, Accuracy: 1.0\n",
            "Step 19121/22500 - Loss: 0.04026862978935242, Accuracy: 1.0\n",
            "Step 19122/22500 - Loss: 0.008202796801924706, Accuracy: 1.0\n",
            "Step 19123/22500 - Loss: 0.028019245713949203, Accuracy: 1.0\n",
            "Step 19124/22500 - Loss: 0.07404976338148117, Accuracy: 1.0\n",
            "Step 19125/22500 - Loss: 0.11530836671590805, Accuracy: 1.0\n",
            "Step 19126/22500 - Loss: 0.22006085515022278, Accuracy: 0.875\n",
            "Step 19127/22500 - Loss: 0.4718822240829468, Accuracy: 0.75\n",
            "Step 19128/22500 - Loss: 0.492678165435791, Accuracy: 0.75\n",
            "Step 19129/22500 - Loss: 0.8404006361961365, Accuracy: 0.875\n",
            "Step 19130/22500 - Loss: 0.1289886087179184, Accuracy: 0.875\n",
            "Step 19131/22500 - Loss: 0.02946353331208229, Accuracy: 1.0\n",
            "Step 19132/22500 - Loss: 0.002403555903583765, Accuracy: 1.0\n",
            "Step 19133/22500 - Loss: 0.6853289604187012, Accuracy: 0.875\n",
            "Step 19134/22500 - Loss: 0.15602466464042664, Accuracy: 0.875\n",
            "Step 19135/22500 - Loss: 0.015026343055069447, Accuracy: 1.0\n",
            "Step 19136/22500 - Loss: 0.003460654988884926, Accuracy: 1.0\n",
            "Step 19137/22500 - Loss: 0.06396682560443878, Accuracy: 1.0\n",
            "Step 19138/22500 - Loss: 0.027535196393728256, Accuracy: 1.0\n",
            "Step 19139/22500 - Loss: 0.083473339676857, Accuracy: 1.0\n",
            "Step 19140/22500 - Loss: 0.033780746161937714, Accuracy: 1.0\n",
            "Step 19141/22500 - Loss: 0.16668850183486938, Accuracy: 0.875\n",
            "Step 19142/22500 - Loss: 0.046023450791835785, Accuracy: 1.0\n",
            "Step 19143/22500 - Loss: 0.28969985246658325, Accuracy: 0.75\n",
            "Step 19144/22500 - Loss: 0.07483857125043869, Accuracy: 1.0\n",
            "Step 19145/22500 - Loss: 0.12706753611564636, Accuracy: 0.875\n",
            "Step 19146/22500 - Loss: 0.029770666733384132, Accuracy: 1.0\n",
            "Step 19147/22500 - Loss: 0.06553370505571365, Accuracy: 1.0\n",
            "Step 19148/22500 - Loss: 0.6594486832618713, Accuracy: 0.75\n",
            "Step 19149/22500 - Loss: 0.004722399637103081, Accuracy: 1.0\n",
            "Step 19150/22500 - Loss: 0.054882731288671494, Accuracy: 1.0\n",
            "Step 19151/22500 - Loss: 0.24569858610630035, Accuracy: 0.875\n",
            "Step 19152/22500 - Loss: 0.13280373811721802, Accuracy: 0.875\n",
            "Step 19153/22500 - Loss: 0.045139674097299576, Accuracy: 1.0\n",
            "Step 19154/22500 - Loss: 0.2331291139125824, Accuracy: 0.875\n",
            "Step 19155/22500 - Loss: 0.3944854140281677, Accuracy: 0.875\n",
            "Step 19156/22500 - Loss: 0.15799033641815186, Accuracy: 0.875\n",
            "Step 19157/22500 - Loss: 0.019271081313490868, Accuracy: 1.0\n",
            "Step 19158/22500 - Loss: 0.023550521582365036, Accuracy: 1.0\n",
            "Step 19159/22500 - Loss: 0.019838780164718628, Accuracy: 1.0\n",
            "Step 19160/22500 - Loss: 0.03045790269970894, Accuracy: 1.0\n",
            "Step 19161/22500 - Loss: 0.08588529378175735, Accuracy: 1.0\n",
            "Step 19162/22500 - Loss: 0.01793825626373291, Accuracy: 1.0\n",
            "Step 19163/22500 - Loss: 0.03806836158037186, Accuracy: 1.0\n",
            "Step 19164/22500 - Loss: 0.0658995509147644, Accuracy: 1.0\n",
            "Step 19165/22500 - Loss: 0.06002736836671829, Accuracy: 1.0\n",
            "Step 19166/22500 - Loss: 0.02114514261484146, Accuracy: 1.0\n",
            "Step 19167/22500 - Loss: 0.3107259273529053, Accuracy: 0.75\n",
            "Step 19168/22500 - Loss: 0.030474726110696793, Accuracy: 1.0\n",
            "Step 19169/22500 - Loss: 0.23151160776615143, Accuracy: 0.875\n",
            "Step 19170/22500 - Loss: 0.011262472718954086, Accuracy: 1.0\n",
            "Step 19171/22500 - Loss: 0.4493961036205292, Accuracy: 0.875\n",
            "Step 19172/22500 - Loss: 0.07214926928281784, Accuracy: 1.0\n",
            "Step 19173/22500 - Loss: 0.09165675193071365, Accuracy: 1.0\n",
            "Step 19174/22500 - Loss: 0.1046416386961937, Accuracy: 1.0\n",
            "Step 19175/22500 - Loss: 0.11003714799880981, Accuracy: 0.875\n",
            "Step 19176/22500 - Loss: 0.12242595851421356, Accuracy: 0.875\n",
            "Step 19177/22500 - Loss: 0.03895530104637146, Accuracy: 1.0\n",
            "Step 19178/22500 - Loss: 0.364699125289917, Accuracy: 0.875\n",
            "Step 19179/22500 - Loss: 0.00594890583306551, Accuracy: 1.0\n",
            "Step 19180/22500 - Loss: 0.25888732075691223, Accuracy: 0.875\n",
            "Step 19181/22500 - Loss: 0.042532965540885925, Accuracy: 1.0\n",
            "Step 19182/22500 - Loss: 0.21388530731201172, Accuracy: 0.875\n",
            "Step 19183/22500 - Loss: 0.05777227506041527, Accuracy: 1.0\n",
            "Step 19184/22500 - Loss: 0.563001275062561, Accuracy: 0.75\n",
            "Step 19185/22500 - Loss: 0.08319807052612305, Accuracy: 1.0\n",
            "Step 19186/22500 - Loss: 0.0038253054954111576, Accuracy: 1.0\n",
            "Step 19187/22500 - Loss: 0.3196621239185333, Accuracy: 0.875\n",
            "Step 19188/22500 - Loss: 0.3295351266860962, Accuracy: 0.75\n",
            "Step 19189/22500 - Loss: 0.09186416119337082, Accuracy: 1.0\n",
            "Step 19190/22500 - Loss: 0.2152591198682785, Accuracy: 0.875\n",
            "Step 19191/22500 - Loss: 0.022933274507522583, Accuracy: 1.0\n",
            "Step 19192/22500 - Loss: 0.29439181089401245, Accuracy: 0.875\n",
            "Step 19193/22500 - Loss: 0.05869869515299797, Accuracy: 1.0\n",
            "Step 19194/22500 - Loss: 0.0041571613401174545, Accuracy: 1.0\n",
            "Step 19195/22500 - Loss: 0.08989254385232925, Accuracy: 1.0\n",
            "Step 19196/22500 - Loss: 0.06425143778324127, Accuracy: 1.0\n",
            "Step 19197/22500 - Loss: 0.2561952769756317, Accuracy: 0.875\n",
            "Step 19198/22500 - Loss: 0.6582608222961426, Accuracy: 0.625\n",
            "Step 19199/22500 - Loss: 0.06482087075710297, Accuracy: 1.0\n",
            "Step 19200/22500 - Loss: 0.14557728171348572, Accuracy: 0.875\n",
            "Step 19201/22500 - Loss: 0.028675466775894165, Accuracy: 1.0\n",
            "Step 19202/22500 - Loss: 0.15455320477485657, Accuracy: 0.875\n",
            "Step 19203/22500 - Loss: 0.23363220691680908, Accuracy: 0.875\n",
            "Step 19204/22500 - Loss: 0.02402917668223381, Accuracy: 1.0\n",
            "Step 19205/22500 - Loss: 0.06202610582113266, Accuracy: 1.0\n",
            "Step 19206/22500 - Loss: 0.02503792941570282, Accuracy: 1.0\n",
            "Step 19207/22500 - Loss: 0.04987807944417, Accuracy: 1.0\n",
            "Step 19208/22500 - Loss: 0.433584064245224, Accuracy: 0.875\n",
            "Step 19209/22500 - Loss: 0.01953032612800598, Accuracy: 1.0\n",
            "Step 19210/22500 - Loss: 0.5082330703735352, Accuracy: 0.75\n",
            "Step 19211/22500 - Loss: 0.17671750485897064, Accuracy: 0.875\n",
            "Step 19212/22500 - Loss: 0.011427510529756546, Accuracy: 1.0\n",
            "Step 19213/22500 - Loss: 0.059545520693063736, Accuracy: 1.0\n",
            "Step 19214/22500 - Loss: 0.20888584852218628, Accuracy: 0.875\n",
            "Step 19215/22500 - Loss: 0.03461017459630966, Accuracy: 1.0\n",
            "Step 19216/22500 - Loss: 0.006017227191478014, Accuracy: 1.0\n",
            "Step 19217/22500 - Loss: 0.022048117592930794, Accuracy: 1.0\n",
            "Step 19218/22500 - Loss: 0.10465219616889954, Accuracy: 1.0\n",
            "Step 19219/22500 - Loss: 0.051549315452575684, Accuracy: 1.0\n",
            "Step 19220/22500 - Loss: 0.029280416667461395, Accuracy: 1.0\n",
            "Step 19221/22500 - Loss: 0.006243543699383736, Accuracy: 1.0\n",
            "Step 19222/22500 - Loss: 0.020004818215966225, Accuracy: 1.0\n",
            "Step 19223/22500 - Loss: 0.4438387453556061, Accuracy: 0.625\n",
            "Step 19224/22500 - Loss: 0.14804047346115112, Accuracy: 0.875\n",
            "Step 19225/22500 - Loss: 0.5204048752784729, Accuracy: 0.75\n",
            "Step 19226/22500 - Loss: 0.052027564495801926, Accuracy: 1.0\n",
            "Step 19227/22500 - Loss: 0.038272250443696976, Accuracy: 1.0\n",
            "Step 19228/22500 - Loss: 0.013552525080740452, Accuracy: 1.0\n",
            "Step 19229/22500 - Loss: 0.2093563675880432, Accuracy: 0.875\n",
            "Step 19230/22500 - Loss: 0.011254262179136276, Accuracy: 1.0\n",
            "Step 19231/22500 - Loss: 0.004628952592611313, Accuracy: 1.0\n",
            "Step 19232/22500 - Loss: 0.008774976246058941, Accuracy: 1.0\n",
            "Step 19233/22500 - Loss: 0.08870082348585129, Accuracy: 1.0\n",
            "Step 19234/22500 - Loss: 0.00340941920876503, Accuracy: 1.0\n",
            "Step 19235/22500 - Loss: 0.020444896072149277, Accuracy: 1.0\n",
            "Step 19236/22500 - Loss: 0.022019866853952408, Accuracy: 1.0\n",
            "Step 19237/22500 - Loss: 0.005680671893060207, Accuracy: 1.0\n",
            "Step 19238/22500 - Loss: 0.11386044323444366, Accuracy: 0.875\n",
            "Step 19239/22500 - Loss: 0.009257141500711441, Accuracy: 1.0\n",
            "Step 19240/22500 - Loss: 0.15022093057632446, Accuracy: 0.875\n",
            "Step 19241/22500 - Loss: 0.3560551702976227, Accuracy: 0.875\n",
            "Step 19242/22500 - Loss: 0.14252601563930511, Accuracy: 1.0\n",
            "Step 19243/22500 - Loss: 0.19614939391613007, Accuracy: 0.875\n",
            "Step 19244/22500 - Loss: 0.014106052927672863, Accuracy: 1.0\n",
            "Step 19245/22500 - Loss: 0.13087867200374603, Accuracy: 0.875\n",
            "Step 19246/22500 - Loss: 0.028980640694499016, Accuracy: 1.0\n",
            "Step 19247/22500 - Loss: 0.013704649172723293, Accuracy: 1.0\n",
            "Step 19248/22500 - Loss: 0.005361973773688078, Accuracy: 1.0\n",
            "Step 19249/22500 - Loss: 0.13097889721393585, Accuracy: 0.875\n",
            "Step 19250/22500 - Loss: 0.19804583489894867, Accuracy: 0.875\n",
            "Step 19251/22500 - Loss: 0.07988745719194412, Accuracy: 1.0\n",
            "Step 19252/22500 - Loss: 0.0024905502796173096, Accuracy: 1.0\n",
            "Step 19253/22500 - Loss: 0.012037960812449455, Accuracy: 1.0\n",
            "Step 19254/22500 - Loss: 0.0211070217192173, Accuracy: 1.0\n",
            "Step 19255/22500 - Loss: 0.04786461591720581, Accuracy: 1.0\n",
            "Step 19256/22500 - Loss: 0.10702874511480331, Accuracy: 0.875\n",
            "Step 19257/22500 - Loss: 0.02120724692940712, Accuracy: 1.0\n",
            "Step 19258/22500 - Loss: 0.1474989950656891, Accuracy: 0.875\n",
            "Step 19259/22500 - Loss: 0.1985088437795639, Accuracy: 0.875\n",
            "Step 19260/22500 - Loss: 0.0850699320435524, Accuracy: 1.0\n",
            "Step 19261/22500 - Loss: 0.22800803184509277, Accuracy: 0.875\n",
            "Step 19262/22500 - Loss: 0.34002071619033813, Accuracy: 0.75\n",
            "Step 19263/22500 - Loss: 0.061089079827070236, Accuracy: 1.0\n",
            "Step 19264/22500 - Loss: 0.030201196670532227, Accuracy: 1.0\n",
            "Step 19265/22500 - Loss: 0.02311149798333645, Accuracy: 1.0\n",
            "Step 19266/22500 - Loss: 0.013702955096960068, Accuracy: 1.0\n",
            "Step 19267/22500 - Loss: 0.03115546889603138, Accuracy: 1.0\n",
            "Step 19268/22500 - Loss: 0.03638506680727005, Accuracy: 1.0\n",
            "Step 19269/22500 - Loss: 0.21740931272506714, Accuracy: 0.875\n",
            "Step 19270/22500 - Loss: 0.4913724660873413, Accuracy: 0.875\n",
            "Step 19271/22500 - Loss: 0.5942942500114441, Accuracy: 0.875\n",
            "Step 19272/22500 - Loss: 0.16377505660057068, Accuracy: 1.0\n",
            "Step 19273/22500 - Loss: 0.018728602677583694, Accuracy: 1.0\n",
            "Step 19274/22500 - Loss: 0.01380186714231968, Accuracy: 1.0\n",
            "Step 19275/22500 - Loss: 0.027550511062145233, Accuracy: 1.0\n",
            "Step 19276/22500 - Loss: 0.009475256316363811, Accuracy: 1.0\n",
            "Step 19277/22500 - Loss: 0.006789055187255144, Accuracy: 1.0\n",
            "Step 19278/22500 - Loss: 0.4867842197418213, Accuracy: 0.75\n",
            "Step 19279/22500 - Loss: 0.26674672961235046, Accuracy: 0.75\n",
            "Step 19280/22500 - Loss: 0.034591540694236755, Accuracy: 1.0\n",
            "Step 19281/22500 - Loss: 0.007998465560376644, Accuracy: 1.0\n",
            "Step 19282/22500 - Loss: 0.3025311529636383, Accuracy: 0.875\n",
            "Step 19283/22500 - Loss: 0.04815889149904251, Accuracy: 1.0\n",
            "Step 19284/22500 - Loss: 0.021327978000044823, Accuracy: 1.0\n",
            "Step 19285/22500 - Loss: 0.15474039316177368, Accuracy: 0.875\n",
            "Step 19286/22500 - Loss: 0.1289566159248352, Accuracy: 0.875\n",
            "Step 19287/22500 - Loss: 0.05757184699177742, Accuracy: 1.0\n",
            "Step 19288/22500 - Loss: 0.044194385409355164, Accuracy: 1.0\n",
            "Step 19289/22500 - Loss: 0.011488096788525581, Accuracy: 1.0\n",
            "Step 19290/22500 - Loss: 0.01829843409359455, Accuracy: 1.0\n",
            "Step 19291/22500 - Loss: 0.07392965257167816, Accuracy: 1.0\n",
            "Step 19292/22500 - Loss: 0.34722307324409485, Accuracy: 0.875\n",
            "Step 19293/22500 - Loss: 0.01376672275364399, Accuracy: 1.0\n",
            "Step 19294/22500 - Loss: 0.034169021993875504, Accuracy: 1.0\n",
            "Step 19295/22500 - Loss: 0.2581884562969208, Accuracy: 0.875\n",
            "Step 19296/22500 - Loss: 0.1439388245344162, Accuracy: 1.0\n",
            "Step 19297/22500 - Loss: 0.02928655780851841, Accuracy: 1.0\n",
            "Step 19298/22500 - Loss: 0.003310583531856537, Accuracy: 1.0\n",
            "Step 19299/22500 - Loss: 0.1694345325231552, Accuracy: 0.875\n",
            "Step 19300/22500 - Loss: 0.05423571914434433, Accuracy: 1.0\n",
            "Step 19301/22500 - Loss: 0.035591524094343185, Accuracy: 1.0\n",
            "Step 19302/22500 - Loss: 0.009097588248550892, Accuracy: 1.0\n",
            "Step 19303/22500 - Loss: 0.35672804713249207, Accuracy: 0.875\n",
            "Step 19304/22500 - Loss: 0.024734070524573326, Accuracy: 1.0\n",
            "Step 19305/22500 - Loss: 0.01582232303917408, Accuracy: 1.0\n",
            "Step 19306/22500 - Loss: 0.27616170048713684, Accuracy: 0.875\n",
            "Step 19307/22500 - Loss: 0.04284564405679703, Accuracy: 1.0\n",
            "Step 19308/22500 - Loss: 0.025862406939268112, Accuracy: 1.0\n",
            "Step 19309/22500 - Loss: 0.00798097625374794, Accuracy: 1.0\n",
            "Step 19310/22500 - Loss: 0.3560372591018677, Accuracy: 0.75\n",
            "Step 19311/22500 - Loss: 0.2454742044210434, Accuracy: 0.875\n",
            "Step 19312/22500 - Loss: 0.052951253950595856, Accuracy: 1.0\n",
            "Step 19313/22500 - Loss: 0.015652744099497795, Accuracy: 1.0\n",
            "Step 19314/22500 - Loss: 0.21430933475494385, Accuracy: 0.875\n",
            "Step 19315/22500 - Loss: 0.05023304373025894, Accuracy: 1.0\n",
            "Step 19316/22500 - Loss: 0.0409601666033268, Accuracy: 1.0\n",
            "Step 19317/22500 - Loss: 0.19023868441581726, Accuracy: 1.0\n",
            "Step 19318/22500 - Loss: 0.039026543498039246, Accuracy: 1.0\n",
            "Step 19319/22500 - Loss: 0.016093796119093895, Accuracy: 1.0\n",
            "Step 19320/22500 - Loss: 0.1100168451666832, Accuracy: 0.875\n",
            "Step 19321/22500 - Loss: 0.029259324073791504, Accuracy: 1.0\n",
            "Step 19322/22500 - Loss: 0.011962559074163437, Accuracy: 1.0\n",
            "Step 19323/22500 - Loss: 0.45347797870635986, Accuracy: 0.875\n",
            "Step 19324/22500 - Loss: 0.014835447072982788, Accuracy: 1.0\n",
            "Step 19325/22500 - Loss: 0.31304076313972473, Accuracy: 0.75\n",
            "Step 19326/22500 - Loss: 0.049981117248535156, Accuracy: 1.0\n",
            "Step 19327/22500 - Loss: 0.17386506497859955, Accuracy: 0.875\n",
            "Step 19328/22500 - Loss: 0.09801717847585678, Accuracy: 1.0\n",
            "Step 19329/22500 - Loss: 0.003201663726940751, Accuracy: 1.0\n",
            "Step 19330/22500 - Loss: 0.3632548153400421, Accuracy: 0.875\n",
            "Step 19331/22500 - Loss: 0.44461309909820557, Accuracy: 0.875\n",
            "Step 19332/22500 - Loss: 0.05210027098655701, Accuracy: 1.0\n",
            "Step 19333/22500 - Loss: 0.04167884215712547, Accuracy: 1.0\n",
            "Step 19334/22500 - Loss: 0.10555993020534515, Accuracy: 0.875\n",
            "Step 19335/22500 - Loss: 0.9545904397964478, Accuracy: 0.75\n",
            "Step 19336/22500 - Loss: 0.01564154401421547, Accuracy: 1.0\n",
            "Step 19337/22500 - Loss: 0.030287107452750206, Accuracy: 1.0\n",
            "Step 19338/22500 - Loss: 0.17001716792583466, Accuracy: 0.875\n",
            "Step 19339/22500 - Loss: 0.9779053330421448, Accuracy: 0.75\n",
            "Step 19340/22500 - Loss: 0.03795953467488289, Accuracy: 1.0\n",
            "Step 19341/22500 - Loss: 0.3749324679374695, Accuracy: 0.875\n",
            "Step 19342/22500 - Loss: 0.19929133355617523, Accuracy: 0.875\n",
            "Step 19343/22500 - Loss: 0.19576163589954376, Accuracy: 0.875\n",
            "Step 19344/22500 - Loss: 0.019001862034201622, Accuracy: 1.0\n",
            "Step 19345/22500 - Loss: 0.017976287752389908, Accuracy: 1.0\n",
            "Step 19346/22500 - Loss: 0.0978747010231018, Accuracy: 1.0\n",
            "Step 19347/22500 - Loss: 0.04481274634599686, Accuracy: 1.0\n",
            "Step 19348/22500 - Loss: 0.008464615792036057, Accuracy: 1.0\n",
            "Step 19349/22500 - Loss: 0.31540048122406006, Accuracy: 0.875\n",
            "Step 19350/22500 - Loss: 0.14919565618038177, Accuracy: 0.875\n",
            "Step 19351/22500 - Loss: 0.01118774339556694, Accuracy: 1.0\n",
            "Step 19352/22500 - Loss: 0.5366858243942261, Accuracy: 0.75\n",
            "Step 19353/22500 - Loss: 0.46024441719055176, Accuracy: 0.875\n",
            "Step 19354/22500 - Loss: 0.0040322402492165565, Accuracy: 1.0\n",
            "Step 19355/22500 - Loss: 0.0657915323972702, Accuracy: 1.0\n",
            "Step 19356/22500 - Loss: 0.20761701464653015, Accuracy: 0.875\n",
            "Step 19357/22500 - Loss: 0.01729099452495575, Accuracy: 1.0\n",
            "Step 19358/22500 - Loss: 0.05858655273914337, Accuracy: 1.0\n",
            "Step 19359/22500 - Loss: 0.03820968046784401, Accuracy: 1.0\n",
            "Step 19360/22500 - Loss: 0.10534520447254181, Accuracy: 1.0\n",
            "Step 19361/22500 - Loss: 0.025732187554240227, Accuracy: 1.0\n",
            "Step 19362/22500 - Loss: 0.10710377246141434, Accuracy: 1.0\n",
            "Step 19363/22500 - Loss: 0.02873009815812111, Accuracy: 1.0\n",
            "Step 19364/22500 - Loss: 0.234464630484581, Accuracy: 0.875\n",
            "Step 19365/22500 - Loss: 0.48646047711372375, Accuracy: 0.75\n",
            "Step 19366/22500 - Loss: 0.007133203558623791, Accuracy: 1.0\n",
            "Step 19367/22500 - Loss: 0.045802731066942215, Accuracy: 1.0\n",
            "Step 19368/22500 - Loss: 0.02766723930835724, Accuracy: 1.0\n",
            "Step 19369/22500 - Loss: 0.1073434054851532, Accuracy: 0.875\n",
            "Step 19370/22500 - Loss: 0.034006282687187195, Accuracy: 1.0\n",
            "Step 19371/22500 - Loss: 0.03830152750015259, Accuracy: 1.0\n",
            "Step 19372/22500 - Loss: 0.008790372870862484, Accuracy: 1.0\n",
            "Step 19373/22500 - Loss: 0.12282095104455948, Accuracy: 0.875\n",
            "Step 19374/22500 - Loss: 0.0161223653703928, Accuracy: 1.0\n",
            "Step 19375/22500 - Loss: 0.5724719762802124, Accuracy: 0.875\n",
            "Step 19376/22500 - Loss: 0.0733174979686737, Accuracy: 1.0\n",
            "Step 19377/22500 - Loss: 0.007553393021225929, Accuracy: 1.0\n",
            "Step 19378/22500 - Loss: 0.3206660747528076, Accuracy: 0.875\n",
            "Step 19379/22500 - Loss: 0.1445382833480835, Accuracy: 0.875\n",
            "Step 19380/22500 - Loss: 0.02967168018221855, Accuracy: 1.0\n",
            "Step 19381/22500 - Loss: 0.04255158454179764, Accuracy: 1.0\n",
            "Step 19382/22500 - Loss: 0.012296848930418491, Accuracy: 1.0\n",
            "Step 19383/22500 - Loss: 0.025396179407835007, Accuracy: 1.0\n",
            "Step 19384/22500 - Loss: 0.006256151013076305, Accuracy: 1.0\n",
            "Step 19385/22500 - Loss: 0.011834604665637016, Accuracy: 1.0\n",
            "Step 19386/22500 - Loss: 0.020145811140537262, Accuracy: 1.0\n",
            "Step 19387/22500 - Loss: 0.031671736389398575, Accuracy: 1.0\n",
            "Step 19388/22500 - Loss: 0.142245814204216, Accuracy: 0.875\n",
            "Step 19389/22500 - Loss: 0.05173182487487793, Accuracy: 1.0\n",
            "Step 19390/22500 - Loss: 0.48875799775123596, Accuracy: 0.875\n",
            "Step 19391/22500 - Loss: 0.0028437701985239983, Accuracy: 1.0\n",
            "Step 19392/22500 - Loss: 0.006504302378743887, Accuracy: 1.0\n",
            "Step 19393/22500 - Loss: 0.11260773986577988, Accuracy: 0.875\n",
            "Step 19394/22500 - Loss: 0.005584109108895063, Accuracy: 1.0\n",
            "Step 19395/22500 - Loss: 0.30188387632369995, Accuracy: 0.875\n",
            "Step 19396/22500 - Loss: 0.019649822264909744, Accuracy: 1.0\n",
            "Step 19397/22500 - Loss: 0.1417115032672882, Accuracy: 1.0\n",
            "Step 19398/22500 - Loss: 0.021272653713822365, Accuracy: 1.0\n",
            "Step 19399/22500 - Loss: 0.21927548944950104, Accuracy: 0.875\n",
            "Step 19400/22500 - Loss: 0.011849255301058292, Accuracy: 1.0\n",
            "Step 19401/22500 - Loss: 0.021199028939008713, Accuracy: 1.0\n",
            "Step 19402/22500 - Loss: 0.34885331988334656, Accuracy: 0.75\n",
            "Step 19403/22500 - Loss: 0.2176235467195511, Accuracy: 0.875\n",
            "Step 19404/22500 - Loss: 0.16149573028087616, Accuracy: 0.875\n",
            "Step 19405/22500 - Loss: 0.1886688768863678, Accuracy: 0.875\n",
            "Step 19406/22500 - Loss: 0.027381956577301025, Accuracy: 1.0\n",
            "Step 19407/22500 - Loss: 0.05790916457772255, Accuracy: 1.0\n",
            "Step 19408/22500 - Loss: 0.08126169443130493, Accuracy: 1.0\n",
            "Step 19409/22500 - Loss: 0.06937692314386368, Accuracy: 1.0\n",
            "Step 19410/22500 - Loss: 0.19915355741977692, Accuracy: 0.875\n",
            "Step 19411/22500 - Loss: 0.0405271016061306, Accuracy: 1.0\n",
            "Step 19412/22500 - Loss: 0.43934664130210876, Accuracy: 0.875\n",
            "Step 19413/22500 - Loss: 0.13897985219955444, Accuracy: 1.0\n",
            "Step 19414/22500 - Loss: 0.016291722655296326, Accuracy: 1.0\n",
            "Step 19415/22500 - Loss: 0.013977836817502975, Accuracy: 1.0\n",
            "Step 19416/22500 - Loss: 0.04928407445549965, Accuracy: 1.0\n",
            "Step 19417/22500 - Loss: 0.011854525655508041, Accuracy: 1.0\n",
            "Step 19418/22500 - Loss: 0.04319972172379494, Accuracy: 1.0\n",
            "Step 19419/22500 - Loss: 0.007525497116148472, Accuracy: 1.0\n",
            "Step 19420/22500 - Loss: 0.1198771670460701, Accuracy: 0.875\n",
            "Step 19421/22500 - Loss: 0.08214952051639557, Accuracy: 1.0\n",
            "Step 19422/22500 - Loss: 0.2637823522090912, Accuracy: 0.875\n",
            "Step 19423/22500 - Loss: 0.03870593011379242, Accuracy: 1.0\n",
            "Step 19424/22500 - Loss: 0.03872814029455185, Accuracy: 1.0\n",
            "Step 19425/22500 - Loss: 0.01660940982401371, Accuracy: 1.0\n",
            "Step 19426/22500 - Loss: 0.16069968044757843, Accuracy: 0.875\n",
            "Step 19427/22500 - Loss: 0.08408328890800476, Accuracy: 1.0\n",
            "Step 19428/22500 - Loss: 0.00899233017116785, Accuracy: 1.0\n",
            "Step 19429/22500 - Loss: 0.21888041496276855, Accuracy: 0.875\n",
            "Step 19430/22500 - Loss: 0.21097999811172485, Accuracy: 0.875\n",
            "Step 19431/22500 - Loss: 0.023162949830293655, Accuracy: 1.0\n",
            "Step 19432/22500 - Loss: 0.34109485149383545, Accuracy: 0.75\n",
            "Step 19433/22500 - Loss: 0.09234047681093216, Accuracy: 1.0\n",
            "Step 19434/22500 - Loss: 0.04006561264395714, Accuracy: 1.0\n",
            "Step 19435/22500 - Loss: 0.3115032911300659, Accuracy: 0.875\n",
            "Step 19436/22500 - Loss: 0.05625123903155327, Accuracy: 1.0\n",
            "Step 19437/22500 - Loss: 0.020155567675828934, Accuracy: 1.0\n",
            "Step 19438/22500 - Loss: 0.04171484336256981, Accuracy: 1.0\n",
            "Step 19439/22500 - Loss: 0.06657686829566956, Accuracy: 1.0\n",
            "Step 19440/22500 - Loss: 0.1256512552499771, Accuracy: 1.0\n",
            "Step 19441/22500 - Loss: 0.2805120646953583, Accuracy: 0.875\n",
            "Step 19442/22500 - Loss: 0.21808433532714844, Accuracy: 0.875\n",
            "Step 19443/22500 - Loss: 0.05236257240176201, Accuracy: 1.0\n",
            "Step 19444/22500 - Loss: 0.24759253859519958, Accuracy: 0.875\n",
            "Step 19445/22500 - Loss: 0.009698965586721897, Accuracy: 1.0\n",
            "Step 19446/22500 - Loss: 0.012774430215358734, Accuracy: 1.0\n",
            "Step 19447/22500 - Loss: 0.11754940450191498, Accuracy: 1.0\n",
            "Step 19448/22500 - Loss: 0.04194977879524231, Accuracy: 1.0\n",
            "Step 19449/22500 - Loss: 0.012995967641472816, Accuracy: 1.0\n",
            "Step 19450/22500 - Loss: 0.1275816112756729, Accuracy: 0.875\n",
            "Step 19451/22500 - Loss: 0.04447495937347412, Accuracy: 1.0\n",
            "Step 19452/22500 - Loss: 0.019193321466445923, Accuracy: 1.0\n",
            "Step 19453/22500 - Loss: 0.157479926943779, Accuracy: 0.875\n",
            "Step 19454/22500 - Loss: 0.03194817900657654, Accuracy: 1.0\n",
            "Step 19455/22500 - Loss: 0.446858286857605, Accuracy: 0.875\n",
            "Step 19456/22500 - Loss: 0.0390123687684536, Accuracy: 1.0\n",
            "Step 19457/22500 - Loss: 0.01797386258840561, Accuracy: 1.0\n",
            "Step 19458/22500 - Loss: 0.38190922141075134, Accuracy: 0.875\n",
            "Step 19459/22500 - Loss: 0.007926191203296185, Accuracy: 1.0\n",
            "Step 19460/22500 - Loss: 0.14628542959690094, Accuracy: 1.0\n",
            "Step 19461/22500 - Loss: 0.013306649401783943, Accuracy: 1.0\n",
            "Step 19462/22500 - Loss: 0.34131431579589844, Accuracy: 0.875\n",
            "Step 19463/22500 - Loss: 0.07115316390991211, Accuracy: 1.0\n",
            "Step 19464/22500 - Loss: 0.02369285374879837, Accuracy: 1.0\n",
            "Step 19465/22500 - Loss: 0.012685997411608696, Accuracy: 1.0\n",
            "Step 19466/22500 - Loss: 0.12570777535438538, Accuracy: 0.875\n",
            "Step 19467/22500 - Loss: 0.011663392186164856, Accuracy: 1.0\n",
            "Step 19468/22500 - Loss: 0.017321273684501648, Accuracy: 1.0\n",
            "Step 19469/22500 - Loss: 0.023100046440958977, Accuracy: 1.0\n",
            "Step 19470/22500 - Loss: 0.0037914197891950607, Accuracy: 1.0\n",
            "Step 19471/22500 - Loss: 0.17913185060024261, Accuracy: 0.875\n",
            "Step 19472/22500 - Loss: 0.07849231362342834, Accuracy: 1.0\n",
            "Step 19473/22500 - Loss: 0.03614233434200287, Accuracy: 1.0\n",
            "Step 19474/22500 - Loss: 0.01628055050969124, Accuracy: 1.0\n",
            "Step 19475/22500 - Loss: 0.15072046220302582, Accuracy: 0.875\n",
            "Step 19476/22500 - Loss: 0.008027036674320698, Accuracy: 1.0\n",
            "Step 19477/22500 - Loss: 0.8031302094459534, Accuracy: 0.625\n",
            "Step 19478/22500 - Loss: 0.469614714384079, Accuracy: 0.875\n",
            "Step 19479/22500 - Loss: 0.5314803719520569, Accuracy: 0.875\n",
            "Step 19480/22500 - Loss: 0.31841981410980225, Accuracy: 0.75\n",
            "Step 19481/22500 - Loss: 0.06845875084400177, Accuracy: 1.0\n",
            "Step 19482/22500 - Loss: 0.051590558141469955, Accuracy: 1.0\n",
            "Step 19483/22500 - Loss: 0.6258156299591064, Accuracy: 0.875\n",
            "Step 19484/22500 - Loss: 0.11683224886655807, Accuracy: 1.0\n",
            "Step 19485/22500 - Loss: 0.03866994380950928, Accuracy: 1.0\n",
            "Step 19486/22500 - Loss: 0.4376067817211151, Accuracy: 0.875\n",
            "Step 19487/22500 - Loss: 0.019126389175653458, Accuracy: 1.0\n",
            "Step 19488/22500 - Loss: 0.2430143505334854, Accuracy: 0.875\n",
            "Step 19489/22500 - Loss: 0.13438671827316284, Accuracy: 1.0\n",
            "Step 19490/22500 - Loss: 0.002747077029198408, Accuracy: 1.0\n",
            "Step 19491/22500 - Loss: 0.044098641723394394, Accuracy: 1.0\n",
            "Step 19492/22500 - Loss: 0.29087796807289124, Accuracy: 0.75\n",
            "Step 19493/22500 - Loss: 0.005789345130324364, Accuracy: 1.0\n",
            "Step 19494/22500 - Loss: 0.09482135623693466, Accuracy: 1.0\n",
            "Step 19495/22500 - Loss: 0.06841538846492767, Accuracy: 1.0\n",
            "Step 19496/22500 - Loss: 0.1154744029045105, Accuracy: 0.875\n",
            "Step 19497/22500 - Loss: 0.013755555264651775, Accuracy: 1.0\n",
            "Step 19498/22500 - Loss: 0.18002356588840485, Accuracy: 0.875\n",
            "Step 19499/22500 - Loss: 0.1061406135559082, Accuracy: 0.875\n",
            "Step 19500/22500 - Loss: 0.38662779331207275, Accuracy: 0.875\n",
            "Step 19501/22500 - Loss: 0.0809987410902977, Accuracy: 1.0\n",
            "Step 19502/22500 - Loss: 0.03427906334400177, Accuracy: 1.0\n",
            "Step 19503/22500 - Loss: 0.14916503429412842, Accuracy: 0.875\n",
            "Step 19504/22500 - Loss: 0.1859663426876068, Accuracy: 0.875\n",
            "Step 19505/22500 - Loss: 0.34075719118118286, Accuracy: 0.875\n",
            "Step 19506/22500 - Loss: 0.20019148290157318, Accuracy: 0.875\n",
            "Step 19507/22500 - Loss: 0.11787363141775131, Accuracy: 1.0\n",
            "Step 19508/22500 - Loss: 0.006177318748086691, Accuracy: 1.0\n",
            "Step 19509/22500 - Loss: 0.09870580583810806, Accuracy: 0.875\n",
            "Step 19510/22500 - Loss: 0.008994711562991142, Accuracy: 1.0\n",
            "Step 19511/22500 - Loss: 0.3634294867515564, Accuracy: 0.875\n",
            "Step 19512/22500 - Loss: 0.014435225166380405, Accuracy: 1.0\n",
            "Step 19513/22500 - Loss: 0.002990037901327014, Accuracy: 1.0\n",
            "Step 19514/22500 - Loss: 0.059896428138017654, Accuracy: 1.0\n",
            "Step 19515/22500 - Loss: 0.0434664711356163, Accuracy: 1.0\n",
            "Step 19516/22500 - Loss: 0.38618993759155273, Accuracy: 0.875\n",
            "Step 19517/22500 - Loss: 0.3065217137336731, Accuracy: 0.875\n",
            "Step 19518/22500 - Loss: 0.02112375944852829, Accuracy: 1.0\n",
            "Step 19519/22500 - Loss: 0.15239572525024414, Accuracy: 0.875\n",
            "Step 19520/22500 - Loss: 0.05653447285294533, Accuracy: 1.0\n",
            "Step 19521/22500 - Loss: 0.3462279736995697, Accuracy: 0.75\n",
            "Step 19522/22500 - Loss: 0.34853628277778625, Accuracy: 0.875\n",
            "Step 19523/22500 - Loss: 0.12351232022047043, Accuracy: 1.0\n",
            "Step 19524/22500 - Loss: 0.06601673364639282, Accuracy: 1.0\n",
            "Step 19525/22500 - Loss: 0.00753653421998024, Accuracy: 1.0\n",
            "Step 19526/22500 - Loss: 0.12217216938734055, Accuracy: 0.875\n",
            "Step 19527/22500 - Loss: 0.10697183012962341, Accuracy: 1.0\n",
            "Step 19528/22500 - Loss: 0.02471346966922283, Accuracy: 1.0\n",
            "Step 19529/22500 - Loss: 0.008355017751455307, Accuracy: 1.0\n",
            "Step 19530/22500 - Loss: 0.19769287109375, Accuracy: 1.0\n",
            "Step 19531/22500 - Loss: 0.07716767489910126, Accuracy: 1.0\n",
            "Step 19532/22500 - Loss: 0.2814621925354004, Accuracy: 0.75\n",
            "Step 19533/22500 - Loss: 0.26677805185317993, Accuracy: 0.875\n",
            "Step 19534/22500 - Loss: 0.06669466942548752, Accuracy: 1.0\n",
            "Step 19535/22500 - Loss: 0.12531481683254242, Accuracy: 0.875\n",
            "Step 19536/22500 - Loss: 0.015981625765562057, Accuracy: 1.0\n",
            "Step 19537/22500 - Loss: 0.029779765754938126, Accuracy: 1.0\n",
            "Step 19538/22500 - Loss: 0.004751980770379305, Accuracy: 1.0\n",
            "Step 19539/22500 - Loss: 0.243035688996315, Accuracy: 0.875\n",
            "Step 19540/22500 - Loss: 0.01759006828069687, Accuracy: 1.0\n",
            "Step 19541/22500 - Loss: 0.08187971264123917, Accuracy: 1.0\n",
            "Step 19542/22500 - Loss: 0.01251426711678505, Accuracy: 1.0\n",
            "Step 19543/22500 - Loss: 0.0622805655002594, Accuracy: 1.0\n",
            "Step 19544/22500 - Loss: 0.028149813413619995, Accuracy: 1.0\n",
            "Step 19545/22500 - Loss: 0.3779853284358978, Accuracy: 0.75\n",
            "Step 19546/22500 - Loss: 0.2566462457180023, Accuracy: 0.875\n",
            "Step 19547/22500 - Loss: 0.05788368731737137, Accuracy: 1.0\n",
            "Step 19548/22500 - Loss: 0.16047100722789764, Accuracy: 0.875\n",
            "Step 19549/22500 - Loss: 0.0723617672920227, Accuracy: 1.0\n",
            "Step 19550/22500 - Loss: 0.023720277473330498, Accuracy: 1.0\n",
            "Step 19551/22500 - Loss: 0.04145614057779312, Accuracy: 1.0\n",
            "Step 19552/22500 - Loss: 0.04021598398685455, Accuracy: 1.0\n",
            "Step 19553/22500 - Loss: 0.4448069632053375, Accuracy: 0.75\n",
            "Step 19554/22500 - Loss: 0.07385211437940598, Accuracy: 1.0\n",
            "Step 19555/22500 - Loss: 0.07231908291578293, Accuracy: 1.0\n",
            "Step 19556/22500 - Loss: 0.035921141505241394, Accuracy: 1.0\n",
            "Step 19557/22500 - Loss: 0.05062844976782799, Accuracy: 1.0\n",
            "Step 19558/22500 - Loss: 0.009125879965722561, Accuracy: 1.0\n",
            "Step 19559/22500 - Loss: 0.007196010556071997, Accuracy: 1.0\n",
            "Step 19560/22500 - Loss: 0.678668737411499, Accuracy: 0.625\n",
            "Step 19561/22500 - Loss: 0.18820707499980927, Accuracy: 1.0\n",
            "Step 19562/22500 - Loss: 0.003962577786296606, Accuracy: 1.0\n",
            "Step 19563/22500 - Loss: 0.17087890207767487, Accuracy: 0.875\n",
            "Step 19564/22500 - Loss: 0.04747513309121132, Accuracy: 1.0\n",
            "Step 19565/22500 - Loss: 0.016011416912078857, Accuracy: 1.0\n",
            "Step 19566/22500 - Loss: 0.014104747213423252, Accuracy: 1.0\n",
            "Step 19567/22500 - Loss: 0.004596238490194082, Accuracy: 1.0\n",
            "Step 19568/22500 - Loss: 0.3466234505176544, Accuracy: 0.875\n",
            "Step 19569/22500 - Loss: 0.006391735747456551, Accuracy: 1.0\n",
            "Step 19570/22500 - Loss: 0.1939980834722519, Accuracy: 0.875\n",
            "Step 19571/22500 - Loss: 0.33938270807266235, Accuracy: 0.625\n",
            "Step 19572/22500 - Loss: 0.00934857688844204, Accuracy: 1.0\n",
            "Step 19573/22500 - Loss: 0.09310043603181839, Accuracy: 1.0\n",
            "Step 19574/22500 - Loss: 0.13553987443447113, Accuracy: 0.875\n",
            "Step 19575/22500 - Loss: 0.04284321889281273, Accuracy: 1.0\n",
            "Step 19576/22500 - Loss: 0.08080915361642838, Accuracy: 1.0\n",
            "Step 19577/22500 - Loss: 0.11440218240022659, Accuracy: 0.875\n",
            "Step 19578/22500 - Loss: 0.022413773462176323, Accuracy: 1.0\n",
            "Step 19579/22500 - Loss: 0.015612450428307056, Accuracy: 1.0\n",
            "Step 19580/22500 - Loss: 0.08695417642593384, Accuracy: 1.0\n",
            "Step 19581/22500 - Loss: 0.09843664616346359, Accuracy: 1.0\n",
            "Step 19582/22500 - Loss: 0.0383574552834034, Accuracy: 1.0\n",
            "Step 19583/22500 - Loss: 0.0036267053801566362, Accuracy: 1.0\n",
            "Step 19584/22500 - Loss: 0.037656430155038834, Accuracy: 1.0\n",
            "Step 19585/22500 - Loss: 0.06606414914131165, Accuracy: 1.0\n",
            "Step 19586/22500 - Loss: 0.21411152184009552, Accuracy: 0.875\n",
            "Step 19587/22500 - Loss: 0.001466067275032401, Accuracy: 1.0\n",
            "Step 19588/22500 - Loss: 0.005762874148786068, Accuracy: 1.0\n",
            "Step 19589/22500 - Loss: 0.053260691463947296, Accuracy: 1.0\n",
            "Step 19590/22500 - Loss: 0.41288501024246216, Accuracy: 0.75\n",
            "Step 19591/22500 - Loss: 0.027204234153032303, Accuracy: 1.0\n",
            "Step 19592/22500 - Loss: 0.2158435583114624, Accuracy: 0.875\n",
            "Step 19593/22500 - Loss: 0.042539358139038086, Accuracy: 1.0\n",
            "Step 19594/22500 - Loss: 0.883874773979187, Accuracy: 0.75\n",
            "Step 19595/22500 - Loss: 0.028284048661589622, Accuracy: 1.0\n",
            "Step 19596/22500 - Loss: 0.22314561903476715, Accuracy: 1.0\n",
            "Step 19597/22500 - Loss: 0.4225582778453827, Accuracy: 0.875\n",
            "Step 19598/22500 - Loss: 0.016189297661185265, Accuracy: 1.0\n",
            "Step 19599/22500 - Loss: 0.09813341498374939, Accuracy: 1.0\n",
            "Step 19600/22500 - Loss: 0.05302302539348602, Accuracy: 1.0\n",
            "Step 19601/22500 - Loss: 1.0206636190414429, Accuracy: 0.875\n",
            "Step 19602/22500 - Loss: 0.25207066535949707, Accuracy: 0.875\n",
            "Step 19603/22500 - Loss: 0.021509164944291115, Accuracy: 1.0\n",
            "Step 19604/22500 - Loss: 0.6864880323410034, Accuracy: 0.75\n",
            "Step 19605/22500 - Loss: 0.001723668072372675, Accuracy: 1.0\n",
            "Step 19606/22500 - Loss: 0.23239430785179138, Accuracy: 0.875\n",
            "Step 19607/22500 - Loss: 0.046510763466358185, Accuracy: 1.0\n",
            "Step 19608/22500 - Loss: 0.046216148883104324, Accuracy: 1.0\n",
            "Step 19609/22500 - Loss: 0.35009899735450745, Accuracy: 0.875\n",
            "Step 19610/22500 - Loss: 0.032096024602651596, Accuracy: 1.0\n",
            "Step 19611/22500 - Loss: 1.1340150833129883, Accuracy: 0.625\n",
            "Step 19612/22500 - Loss: 0.027005929499864578, Accuracy: 1.0\n",
            "Step 19613/22500 - Loss: 0.01647910475730896, Accuracy: 1.0\n",
            "Step 19614/22500 - Loss: 0.04168235883116722, Accuracy: 1.0\n",
            "Step 19615/22500 - Loss: 0.05475311353802681, Accuracy: 1.0\n",
            "Step 19616/22500 - Loss: 0.04136083275079727, Accuracy: 1.0\n",
            "Step 19617/22500 - Loss: 0.012130671180784702, Accuracy: 1.0\n",
            "Step 19618/22500 - Loss: 0.05719737708568573, Accuracy: 1.0\n",
            "Step 19619/22500 - Loss: 0.02141665108501911, Accuracy: 1.0\n",
            "Step 19620/22500 - Loss: 0.10019733011722565, Accuracy: 1.0\n",
            "Step 19621/22500 - Loss: 0.32628926634788513, Accuracy: 0.875\n",
            "Step 19622/22500 - Loss: 0.0030310098081827164, Accuracy: 1.0\n",
            "Step 19623/22500 - Loss: 0.029587073251605034, Accuracy: 1.0\n",
            "Step 19624/22500 - Loss: 0.07833955436944962, Accuracy: 1.0\n",
            "Step 19625/22500 - Loss: 0.03979836776852608, Accuracy: 1.0\n",
            "Step 19626/22500 - Loss: 0.15177731215953827, Accuracy: 0.875\n",
            "Step 19627/22500 - Loss: 0.3248738944530487, Accuracy: 0.75\n",
            "Step 19628/22500 - Loss: 0.21751907467842102, Accuracy: 0.875\n",
            "Step 19629/22500 - Loss: 0.0053672874346375465, Accuracy: 1.0\n",
            "Step 19630/22500 - Loss: 0.09306736290454865, Accuracy: 0.875\n",
            "Step 19631/22500 - Loss: 0.038157716393470764, Accuracy: 1.0\n",
            "Step 19632/22500 - Loss: 0.042342543601989746, Accuracy: 1.0\n",
            "Step 19633/22500 - Loss: 0.007177607621997595, Accuracy: 1.0\n",
            "Step 19634/22500 - Loss: 0.061647795140743256, Accuracy: 1.0\n",
            "Step 19635/22500 - Loss: 0.019069189205765724, Accuracy: 1.0\n",
            "Step 19636/22500 - Loss: 0.011877392418682575, Accuracy: 1.0\n",
            "Step 19637/22500 - Loss: 0.17683671414852142, Accuracy: 1.0\n",
            "Step 19638/22500 - Loss: 0.16694019734859467, Accuracy: 0.875\n",
            "Step 19639/22500 - Loss: 0.0038611057680100203, Accuracy: 1.0\n",
            "Step 19640/22500 - Loss: 0.2158559113740921, Accuracy: 0.875\n",
            "Step 19641/22500 - Loss: 0.2626287639141083, Accuracy: 0.75\n",
            "Step 19642/22500 - Loss: 0.10422199964523315, Accuracy: 0.875\n",
            "Step 19643/22500 - Loss: 0.2459113597869873, Accuracy: 0.875\n",
            "Step 19644/22500 - Loss: 0.06253723055124283, Accuracy: 1.0\n",
            "Step 19645/22500 - Loss: 0.24500665068626404, Accuracy: 0.875\n",
            "Step 19646/22500 - Loss: 0.014817357994616032, Accuracy: 1.0\n",
            "Step 19647/22500 - Loss: 0.03103107213973999, Accuracy: 1.0\n",
            "Step 19648/22500 - Loss: 0.2341480851173401, Accuracy: 0.875\n",
            "Step 19649/22500 - Loss: 0.17142978310585022, Accuracy: 0.875\n",
            "Step 19650/22500 - Loss: 0.170329287648201, Accuracy: 0.875\n",
            "Step 19651/22500 - Loss: 0.211217999458313, Accuracy: 0.875\n",
            "Step 19652/22500 - Loss: 0.06310680508613586, Accuracy: 1.0\n",
            "Step 19653/22500 - Loss: 0.027477316558361053, Accuracy: 1.0\n",
            "Step 19654/22500 - Loss: 0.03908104822039604, Accuracy: 1.0\n",
            "Step 19655/22500 - Loss: 0.007260956801474094, Accuracy: 1.0\n",
            "Step 19656/22500 - Loss: 0.12485045194625854, Accuracy: 0.875\n",
            "Step 19657/22500 - Loss: 0.019643446430563927, Accuracy: 1.0\n",
            "Step 19658/22500 - Loss: 0.16211505234241486, Accuracy: 0.875\n",
            "Step 19659/22500 - Loss: 0.006996016018092632, Accuracy: 1.0\n",
            "Step 19660/22500 - Loss: 0.037686899304389954, Accuracy: 1.0\n",
            "Step 19661/22500 - Loss: 0.15844406187534332, Accuracy: 0.875\n",
            "Step 19662/22500 - Loss: 0.010676011443138123, Accuracy: 1.0\n",
            "Step 19663/22500 - Loss: 0.006884075701236725, Accuracy: 1.0\n",
            "Step 19664/22500 - Loss: 0.007927927188575268, Accuracy: 1.0\n",
            "Step 19665/22500 - Loss: 0.002996653551235795, Accuracy: 1.0\n",
            "Step 19666/22500 - Loss: 0.05933884531259537, Accuracy: 1.0\n",
            "Step 19667/22500 - Loss: 0.06466861069202423, Accuracy: 1.0\n",
            "Step 19668/22500 - Loss: 0.014792096801102161, Accuracy: 1.0\n",
            "Step 19669/22500 - Loss: 0.6498165726661682, Accuracy: 0.75\n",
            "Step 19670/22500 - Loss: 0.06149543076753616, Accuracy: 1.0\n",
            "Step 19671/22500 - Loss: 0.16614460945129395, Accuracy: 0.875\n",
            "Step 19672/22500 - Loss: 0.015500184148550034, Accuracy: 1.0\n",
            "Step 19673/22500 - Loss: 0.047180116176605225, Accuracy: 1.0\n",
            "Step 19674/22500 - Loss: 0.1666930913925171, Accuracy: 1.0\n",
            "Step 19675/22500 - Loss: 0.4081389605998993, Accuracy: 0.875\n",
            "Step 19676/22500 - Loss: 0.2153766006231308, Accuracy: 0.875\n",
            "Step 19677/22500 - Loss: 0.07605449855327606, Accuracy: 1.0\n",
            "Step 19678/22500 - Loss: 0.028272505849599838, Accuracy: 1.0\n",
            "Step 19679/22500 - Loss: 0.09982380270957947, Accuracy: 1.0\n",
            "Step 19680/22500 - Loss: 0.14368605613708496, Accuracy: 1.0\n",
            "Step 19681/22500 - Loss: 0.010561833158135414, Accuracy: 1.0\n",
            "Step 19682/22500 - Loss: 0.04929550737142563, Accuracy: 1.0\n",
            "Step 19683/22500 - Loss: 0.09255240857601166, Accuracy: 1.0\n",
            "Step 19684/22500 - Loss: 0.057163551449775696, Accuracy: 1.0\n",
            "Step 19685/22500 - Loss: 0.013608301989734173, Accuracy: 1.0\n",
            "Step 19686/22500 - Loss: 0.025555379688739777, Accuracy: 1.0\n",
            "Step 19687/22500 - Loss: 0.01749553345143795, Accuracy: 1.0\n",
            "Step 19688/22500 - Loss: 0.013432575389742851, Accuracy: 1.0\n",
            "Step 19689/22500 - Loss: 0.039257343858480453, Accuracy: 1.0\n",
            "Step 19690/22500 - Loss: 0.07855382561683655, Accuracy: 1.0\n",
            "Step 19691/22500 - Loss: 0.02323954924941063, Accuracy: 1.0\n",
            "Step 19692/22500 - Loss: 0.04257705807685852, Accuracy: 1.0\n",
            "Step 19693/22500 - Loss: 0.26247406005859375, Accuracy: 0.875\n",
            "Step 19694/22500 - Loss: 0.16545294225215912, Accuracy: 0.875\n",
            "Step 19695/22500 - Loss: 0.09690495580434799, Accuracy: 1.0\n",
            "Step 19696/22500 - Loss: 0.06153925880789757, Accuracy: 1.0\n",
            "Step 19697/22500 - Loss: 0.2887340188026428, Accuracy: 0.875\n",
            "Step 19698/22500 - Loss: 0.129652202129364, Accuracy: 0.875\n",
            "Step 19699/22500 - Loss: 0.07120087742805481, Accuracy: 1.0\n",
            "Step 19700/22500 - Loss: 0.025922581553459167, Accuracy: 1.0\n",
            "Step 19701/22500 - Loss: 0.5013386011123657, Accuracy: 0.875\n",
            "Step 19702/22500 - Loss: 0.12545841932296753, Accuracy: 0.875\n",
            "Step 19703/22500 - Loss: 0.45363956689834595, Accuracy: 0.875\n",
            "Step 19704/22500 - Loss: 0.04871430620551109, Accuracy: 1.0\n",
            "Step 19705/22500 - Loss: 0.41851016879081726, Accuracy: 0.875\n",
            "Step 19706/22500 - Loss: 1.0182976722717285, Accuracy: 0.75\n",
            "Step 19707/22500 - Loss: 0.16771650314331055, Accuracy: 0.875\n",
            "Step 19708/22500 - Loss: 0.029696766287088394, Accuracy: 1.0\n",
            "Step 19709/22500 - Loss: 0.23274192214012146, Accuracy: 0.875\n",
            "Step 19710/22500 - Loss: 0.027877505868673325, Accuracy: 1.0\n",
            "Step 19711/22500 - Loss: 0.00607161782681942, Accuracy: 1.0\n",
            "Step 19712/22500 - Loss: 0.22859907150268555, Accuracy: 0.875\n",
            "Step 19713/22500 - Loss: 0.03801136836409569, Accuracy: 1.0\n",
            "Step 19714/22500 - Loss: 0.019773390144109726, Accuracy: 1.0\n",
            "Step 19715/22500 - Loss: 0.03620794415473938, Accuracy: 1.0\n",
            "Step 19716/22500 - Loss: 0.43711647391319275, Accuracy: 0.75\n",
            "Step 19717/22500 - Loss: 0.004920142702758312, Accuracy: 1.0\n",
            "Step 19718/22500 - Loss: 0.007972899824380875, Accuracy: 1.0\n",
            "Step 19719/22500 - Loss: 0.04238049313426018, Accuracy: 1.0\n",
            "Step 19720/22500 - Loss: 0.400071382522583, Accuracy: 0.875\n",
            "Step 19721/22500 - Loss: 0.00803174264729023, Accuracy: 1.0\n",
            "Step 19722/22500 - Loss: 0.752830982208252, Accuracy: 0.625\n",
            "Step 19723/22500 - Loss: 0.06415555626153946, Accuracy: 1.0\n",
            "Step 19724/22500 - Loss: 0.04294973611831665, Accuracy: 1.0\n",
            "Step 19725/22500 - Loss: 0.005803494714200497, Accuracy: 1.0\n",
            "Step 19726/22500 - Loss: 0.02868044562637806, Accuracy: 1.0\n",
            "Step 19727/22500 - Loss: 0.06420677155256271, Accuracy: 1.0\n",
            "Step 19728/22500 - Loss: 0.030567407608032227, Accuracy: 1.0\n",
            "Step 19729/22500 - Loss: 0.8264822959899902, Accuracy: 0.75\n",
            "Step 19730/22500 - Loss: 0.016818659380078316, Accuracy: 1.0\n",
            "Step 19731/22500 - Loss: 0.17734521627426147, Accuracy: 0.875\n",
            "Step 19732/22500 - Loss: 0.048784635961055756, Accuracy: 1.0\n",
            "Step 19733/22500 - Loss: 0.013902987353503704, Accuracy: 1.0\n",
            "Step 19734/22500 - Loss: 0.0032138985116034746, Accuracy: 1.0\n",
            "Step 19735/22500 - Loss: 0.11099464446306229, Accuracy: 1.0\n",
            "Step 19736/22500 - Loss: 0.014268919825553894, Accuracy: 1.0\n",
            "Step 19737/22500 - Loss: 0.014368637464940548, Accuracy: 1.0\n",
            "Step 19738/22500 - Loss: 0.1874050796031952, Accuracy: 0.875\n",
            "Step 19739/22500 - Loss: 0.5249407291412354, Accuracy: 0.75\n",
            "Step 19740/22500 - Loss: 0.16073860228061676, Accuracy: 0.875\n",
            "Step 19741/22500 - Loss: 0.04260662943124771, Accuracy: 1.0\n",
            "Step 19742/22500 - Loss: 0.02173706330358982, Accuracy: 1.0\n",
            "Step 19743/22500 - Loss: 0.42391812801361084, Accuracy: 0.875\n",
            "Step 19744/22500 - Loss: 0.11139161139726639, Accuracy: 0.875\n",
            "Step 19745/22500 - Loss: 0.03429223224520683, Accuracy: 1.0\n",
            "Step 19746/22500 - Loss: 0.9105425477027893, Accuracy: 0.75\n",
            "Step 19747/22500 - Loss: 0.20279201865196228, Accuracy: 0.875\n",
            "Step 19748/22500 - Loss: 0.04481932520866394, Accuracy: 1.0\n",
            "Step 19749/22500 - Loss: 0.04135318472981453, Accuracy: 1.0\n",
            "Step 19750/22500 - Loss: 0.09815451502799988, Accuracy: 1.0\n",
            "Step 19751/22500 - Loss: 0.04232048988342285, Accuracy: 1.0\n",
            "Step 19752/22500 - Loss: 0.012742431834340096, Accuracy: 1.0\n",
            "Step 19753/22500 - Loss: 0.010856745764613152, Accuracy: 1.0\n",
            "Step 19754/22500 - Loss: 0.09148658066987991, Accuracy: 1.0\n",
            "Step 19755/22500 - Loss: 0.06014406681060791, Accuracy: 1.0\n",
            "Step 19756/22500 - Loss: 0.10785257816314697, Accuracy: 1.0\n",
            "Step 19757/22500 - Loss: 0.02292836457490921, Accuracy: 1.0\n",
            "Step 19758/22500 - Loss: 0.7594485878944397, Accuracy: 0.875\n",
            "Step 19759/22500 - Loss: 0.3724380433559418, Accuracy: 0.875\n",
            "Step 19760/22500 - Loss: 0.03948494791984558, Accuracy: 1.0\n",
            "Step 19761/22500 - Loss: 0.24028614163398743, Accuracy: 0.875\n",
            "Step 19762/22500 - Loss: 0.4054849445819855, Accuracy: 0.875\n",
            "Step 19763/22500 - Loss: 0.2440929412841797, Accuracy: 0.875\n",
            "Step 19764/22500 - Loss: 0.05934666469693184, Accuracy: 1.0\n",
            "Step 19765/22500 - Loss: 0.044139474630355835, Accuracy: 1.0\n",
            "Step 19766/22500 - Loss: 0.008222177624702454, Accuracy: 1.0\n",
            "Step 19767/22500 - Loss: 0.5597473978996277, Accuracy: 0.875\n",
            "Step 19768/22500 - Loss: 0.011351944878697395, Accuracy: 1.0\n",
            "Step 19769/22500 - Loss: 0.0997648537158966, Accuracy: 1.0\n",
            "Step 19770/22500 - Loss: 0.11769117414951324, Accuracy: 1.0\n",
            "Step 19771/22500 - Loss: 0.4538462460041046, Accuracy: 0.75\n",
            "Step 19772/22500 - Loss: 0.017638517543673515, Accuracy: 1.0\n",
            "Step 19773/22500 - Loss: 0.04479910805821419, Accuracy: 1.0\n",
            "Step 19774/22500 - Loss: 0.12218474596738815, Accuracy: 1.0\n",
            "Step 19775/22500 - Loss: 0.005321793258190155, Accuracy: 1.0\n",
            "Step 19776/22500 - Loss: 0.01989726908504963, Accuracy: 1.0\n",
            "Step 19777/22500 - Loss: 0.02002650499343872, Accuracy: 1.0\n",
            "Step 19778/22500 - Loss: 0.04282047599554062, Accuracy: 1.0\n",
            "Step 19779/22500 - Loss: 0.4108176529407501, Accuracy: 0.875\n",
            "Step 19780/22500 - Loss: 0.305997371673584, Accuracy: 0.875\n",
            "Step 19781/22500 - Loss: 0.0035495543852448463, Accuracy: 1.0\n",
            "Step 19782/22500 - Loss: 0.014631412923336029, Accuracy: 1.0\n",
            "Step 19783/22500 - Loss: 0.03268361836671829, Accuracy: 1.0\n",
            "Step 19784/22500 - Loss: 0.011388899758458138, Accuracy: 1.0\n",
            "Step 19785/22500 - Loss: 0.018615761771798134, Accuracy: 1.0\n",
            "Step 19786/22500 - Loss: 0.01309279166162014, Accuracy: 1.0\n",
            "Step 19787/22500 - Loss: 0.23665381968021393, Accuracy: 0.875\n",
            "Step 19788/22500 - Loss: 0.06017722561955452, Accuracy: 1.0\n",
            "Step 19789/22500 - Loss: 0.031103961169719696, Accuracy: 1.0\n",
            "Step 19790/22500 - Loss: 0.012347427196800709, Accuracy: 1.0\n",
            "Step 19791/22500 - Loss: 0.014872653409838676, Accuracy: 1.0\n",
            "Step 19792/22500 - Loss: 0.17259672284126282, Accuracy: 0.875\n",
            "Step 19793/22500 - Loss: 0.020473556593060493, Accuracy: 1.0\n",
            "Step 19794/22500 - Loss: 0.05059114098548889, Accuracy: 1.0\n",
            "Step 19795/22500 - Loss: 0.03118477389216423, Accuracy: 1.0\n",
            "Step 19796/22500 - Loss: 0.019511884078383446, Accuracy: 1.0\n",
            "Step 19797/22500 - Loss: 0.07354259490966797, Accuracy: 1.0\n",
            "Step 19798/22500 - Loss: 0.022339392453432083, Accuracy: 1.0\n",
            "Step 19799/22500 - Loss: 0.009217205457389355, Accuracy: 1.0\n",
            "Step 19800/22500 - Loss: 0.01626218669116497, Accuracy: 1.0\n",
            "Step 19801/22500 - Loss: 0.12959101796150208, Accuracy: 0.875\n",
            "Step 19802/22500 - Loss: 0.17013557255268097, Accuracy: 0.875\n",
            "Step 19803/22500 - Loss: 0.16341225802898407, Accuracy: 0.875\n",
            "Step 19804/22500 - Loss: 0.028937458992004395, Accuracy: 1.0\n",
            "Step 19805/22500 - Loss: 0.03808501362800598, Accuracy: 1.0\n",
            "Step 19806/22500 - Loss: 0.06370256841182709, Accuracy: 1.0\n",
            "Step 19807/22500 - Loss: 0.10785306990146637, Accuracy: 0.875\n",
            "Step 19808/22500 - Loss: 0.020710818469524384, Accuracy: 1.0\n",
            "Step 19809/22500 - Loss: 0.16191266477108002, Accuracy: 0.875\n",
            "Step 19810/22500 - Loss: 0.008558137342333794, Accuracy: 1.0\n",
            "Step 19811/22500 - Loss: 0.06940784305334091, Accuracy: 1.0\n",
            "Step 19812/22500 - Loss: 0.013170327991247177, Accuracy: 1.0\n",
            "Step 19813/22500 - Loss: 0.023743076249957085, Accuracy: 1.0\n",
            "Step 19814/22500 - Loss: 0.09069274365901947, Accuracy: 1.0\n",
            "Step 19815/22500 - Loss: 0.09795532375574112, Accuracy: 1.0\n",
            "Step 19816/22500 - Loss: 0.7777811884880066, Accuracy: 0.75\n",
            "Step 19817/22500 - Loss: 0.2559570074081421, Accuracy: 0.875\n",
            "Step 19818/22500 - Loss: 0.07489151507616043, Accuracy: 1.0\n",
            "Step 19819/22500 - Loss: 0.04714100807905197, Accuracy: 1.0\n",
            "Step 19820/22500 - Loss: 0.24320493638515472, Accuracy: 0.875\n",
            "Step 19821/22500 - Loss: 0.12995032966136932, Accuracy: 0.875\n",
            "Step 19822/22500 - Loss: 0.3031415045261383, Accuracy: 0.75\n",
            "Step 19823/22500 - Loss: 0.003458654507994652, Accuracy: 1.0\n",
            "Step 19824/22500 - Loss: 0.11609328538179398, Accuracy: 0.875\n",
            "Step 19825/22500 - Loss: 0.17245598137378693, Accuracy: 0.875\n",
            "Step 19826/22500 - Loss: 0.018082881346344948, Accuracy: 1.0\n",
            "Step 19827/22500 - Loss: 0.02083541452884674, Accuracy: 1.0\n",
            "Step 19828/22500 - Loss: 0.008823522366583347, Accuracy: 1.0\n",
            "Step 19829/22500 - Loss: 0.018157467246055603, Accuracy: 1.0\n",
            "Step 19830/22500 - Loss: 0.06759241223335266, Accuracy: 1.0\n",
            "Step 19831/22500 - Loss: 0.016363035887479782, Accuracy: 1.0\n",
            "Step 19832/22500 - Loss: 0.2049330472946167, Accuracy: 0.875\n",
            "Step 19833/22500 - Loss: 0.005048142746090889, Accuracy: 1.0\n",
            "Step 19834/22500 - Loss: 0.16345544159412384, Accuracy: 0.875\n",
            "Step 19835/22500 - Loss: 0.012862619943916798, Accuracy: 1.0\n",
            "Step 19836/22500 - Loss: 0.06389611959457397, Accuracy: 1.0\n",
            "Step 19837/22500 - Loss: 0.10281667113304138, Accuracy: 1.0\n",
            "Step 19838/22500 - Loss: 0.032615985721349716, Accuracy: 1.0\n",
            "Step 19839/22500 - Loss: 0.01878700777888298, Accuracy: 1.0\n",
            "Step 19840/22500 - Loss: 0.12444201111793518, Accuracy: 0.875\n",
            "Step 19841/22500 - Loss: 0.041648074984550476, Accuracy: 1.0\n",
            "Step 19842/22500 - Loss: 0.43663546442985535, Accuracy: 0.75\n",
            "Step 19843/22500 - Loss: 0.014772706665098667, Accuracy: 1.0\n",
            "Step 19844/22500 - Loss: 0.06787483394145966, Accuracy: 1.0\n",
            "Step 19845/22500 - Loss: 0.05679577961564064, Accuracy: 1.0\n",
            "Step 19846/22500 - Loss: 0.037679411470890045, Accuracy: 1.0\n",
            "Step 19847/22500 - Loss: 0.026892386376857758, Accuracy: 1.0\n",
            "Step 19848/22500 - Loss: 0.09100967645645142, Accuracy: 1.0\n",
            "Step 19849/22500 - Loss: 0.07764094322919846, Accuracy: 1.0\n",
            "Step 19850/22500 - Loss: 0.034714654088020325, Accuracy: 1.0\n",
            "Step 19851/22500 - Loss: 0.1598774939775467, Accuracy: 0.875\n",
            "Step 19852/22500 - Loss: 0.0660516619682312, Accuracy: 1.0\n",
            "Step 19853/22500 - Loss: 0.04142553359270096, Accuracy: 1.0\n",
            "Step 19854/22500 - Loss: 0.10292408615350723, Accuracy: 0.875\n",
            "Step 19855/22500 - Loss: 0.08602937310934067, Accuracy: 1.0\n",
            "Step 19856/22500 - Loss: 0.5567916035652161, Accuracy: 0.875\n",
            "Step 19857/22500 - Loss: 0.2783081829547882, Accuracy: 0.875\n",
            "Step 19858/22500 - Loss: 0.0366610623896122, Accuracy: 1.0\n",
            "Step 19859/22500 - Loss: 0.5230555534362793, Accuracy: 0.875\n",
            "Step 19860/22500 - Loss: 0.13422688841819763, Accuracy: 1.0\n",
            "Step 19861/22500 - Loss: 0.10131307691335678, Accuracy: 0.875\n",
            "Step 19862/22500 - Loss: 0.05804472416639328, Accuracy: 1.0\n",
            "Step 19863/22500 - Loss: 0.09210902452468872, Accuracy: 1.0\n",
            "Step 19864/22500 - Loss: 0.01782410219311714, Accuracy: 1.0\n",
            "Step 19865/22500 - Loss: 0.45949891209602356, Accuracy: 0.875\n",
            "Step 19866/22500 - Loss: 0.04120432212948799, Accuracy: 1.0\n",
            "Step 19867/22500 - Loss: 0.056371547281742096, Accuracy: 1.0\n",
            "Step 19868/22500 - Loss: 0.2313562035560608, Accuracy: 0.875\n",
            "Step 19869/22500 - Loss: 0.38737109303474426, Accuracy: 0.875\n",
            "Step 19870/22500 - Loss: 0.05127929523587227, Accuracy: 1.0\n",
            "Step 19871/22500 - Loss: 0.10170090943574905, Accuracy: 0.875\n",
            "Step 19872/22500 - Loss: 0.058020614087581635, Accuracy: 1.0\n",
            "Step 19873/22500 - Loss: 0.058183200657367706, Accuracy: 1.0\n",
            "Step 19874/22500 - Loss: 0.03146589547395706, Accuracy: 1.0\n",
            "Step 19875/22500 - Loss: 0.03892047330737114, Accuracy: 1.0\n",
            "Step 19876/22500 - Loss: 0.011269580572843552, Accuracy: 1.0\n",
            "Step 19877/22500 - Loss: 0.038102421909570694, Accuracy: 1.0\n",
            "Step 19878/22500 - Loss: 0.055571362376213074, Accuracy: 1.0\n",
            "Step 19879/22500 - Loss: 0.10266011208295822, Accuracy: 0.875\n",
            "Step 19880/22500 - Loss: 0.00960822869092226, Accuracy: 1.0\n",
            "Step 19881/22500 - Loss: 0.03251659497618675, Accuracy: 1.0\n",
            "Step 19882/22500 - Loss: 0.23076027631759644, Accuracy: 0.875\n",
            "Step 19883/22500 - Loss: 0.01893029548227787, Accuracy: 1.0\n",
            "Step 19884/22500 - Loss: 0.1407385915517807, Accuracy: 0.875\n",
            "Step 19885/22500 - Loss: 0.06535124033689499, Accuracy: 1.0\n",
            "Step 19886/22500 - Loss: 0.17843446135520935, Accuracy: 0.875\n",
            "Step 19887/22500 - Loss: 0.2675859034061432, Accuracy: 0.875\n",
            "Step 19888/22500 - Loss: 0.07309551537036896, Accuracy: 1.0\n",
            "Step 19889/22500 - Loss: 0.06816152483224869, Accuracy: 1.0\n",
            "Step 19890/22500 - Loss: 0.059031788259744644, Accuracy: 1.0\n",
            "Step 19891/22500 - Loss: 0.08011087030172348, Accuracy: 1.0\n",
            "Step 19892/22500 - Loss: 0.020563840866088867, Accuracy: 1.0\n",
            "Step 19893/22500 - Loss: 0.011630690656602383, Accuracy: 1.0\n",
            "Step 19894/22500 - Loss: 0.18908271193504333, Accuracy: 0.875\n",
            "Step 19895/22500 - Loss: 0.3162268102169037, Accuracy: 0.875\n",
            "Step 19896/22500 - Loss: 0.058435648679733276, Accuracy: 1.0\n",
            "Step 19897/22500 - Loss: 0.034417614340782166, Accuracy: 1.0\n",
            "Step 19898/22500 - Loss: 0.012965040281414986, Accuracy: 1.0\n",
            "Step 19899/22500 - Loss: 0.3730986416339874, Accuracy: 0.875\n",
            "Step 19900/22500 - Loss: 0.037639640271663666, Accuracy: 1.0\n",
            "Step 19901/22500 - Loss: 0.5773171782493591, Accuracy: 0.875\n",
            "Step 19902/22500 - Loss: 0.11077556759119034, Accuracy: 0.875\n",
            "Step 19903/22500 - Loss: 0.010419867001473904, Accuracy: 1.0\n",
            "Step 19904/22500 - Loss: 0.08162983506917953, Accuracy: 1.0\n",
            "Step 19905/22500 - Loss: 0.01526887621730566, Accuracy: 1.0\n",
            "Step 19906/22500 - Loss: 0.1557721495628357, Accuracy: 0.875\n",
            "Step 19907/22500 - Loss: 0.19251888990402222, Accuracy: 0.875\n",
            "Step 19908/22500 - Loss: 0.49272677302360535, Accuracy: 0.875\n",
            "Step 19909/22500 - Loss: 0.14149095118045807, Accuracy: 0.875\n",
            "Step 19910/22500 - Loss: 0.2625523805618286, Accuracy: 0.875\n",
            "Step 19911/22500 - Loss: 0.7586695551872253, Accuracy: 0.875\n",
            "Step 19912/22500 - Loss: 0.0383203886449337, Accuracy: 1.0\n",
            "Step 19913/22500 - Loss: 0.011332855559885502, Accuracy: 1.0\n",
            "Step 19914/22500 - Loss: 0.03310078755021095, Accuracy: 1.0\n",
            "Step 19915/22500 - Loss: 0.5671479105949402, Accuracy: 0.75\n",
            "Step 19916/22500 - Loss: 0.2861729562282562, Accuracy: 0.875\n",
            "Step 19917/22500 - Loss: 0.06311613321304321, Accuracy: 1.0\n",
            "Step 19918/22500 - Loss: 0.10312213748693466, Accuracy: 1.0\n",
            "Step 19919/22500 - Loss: 0.06842666864395142, Accuracy: 1.0\n",
            "Step 19920/22500 - Loss: 0.5156893134117126, Accuracy: 0.875\n",
            "Step 19921/22500 - Loss: 0.583476722240448, Accuracy: 0.75\n",
            "Step 19922/22500 - Loss: 0.011478951200842857, Accuracy: 1.0\n",
            "Step 19923/22500 - Loss: 0.47508373856544495, Accuracy: 0.875\n",
            "Step 19924/22500 - Loss: 0.016244670376181602, Accuracy: 1.0\n",
            "Step 19925/22500 - Loss: 0.029084647074341774, Accuracy: 1.0\n",
            "Step 19926/22500 - Loss: 0.034151192754507065, Accuracy: 1.0\n",
            "Step 19927/22500 - Loss: 0.20163360238075256, Accuracy: 0.875\n",
            "Step 19928/22500 - Loss: 0.15549024939537048, Accuracy: 0.875\n",
            "Step 19929/22500 - Loss: 0.0673239678144455, Accuracy: 1.0\n",
            "Step 19930/22500 - Loss: 0.10261831432580948, Accuracy: 0.875\n",
            "Step 19931/22500 - Loss: 0.12648828327655792, Accuracy: 0.875\n",
            "Step 19932/22500 - Loss: 0.32520970702171326, Accuracy: 0.875\n",
            "Step 19933/22500 - Loss: 0.2794063091278076, Accuracy: 0.875\n",
            "Step 19934/22500 - Loss: 0.10074954479932785, Accuracy: 1.0\n",
            "Step 19935/22500 - Loss: 0.2563141882419586, Accuracy: 0.875\n",
            "Step 19936/22500 - Loss: 0.040143657475709915, Accuracy: 1.0\n",
            "Step 19937/22500 - Loss: 0.06784200668334961, Accuracy: 1.0\n",
            "Step 19938/22500 - Loss: 0.6646556854248047, Accuracy: 0.75\n",
            "Step 19939/22500 - Loss: 0.1588737815618515, Accuracy: 0.875\n",
            "Step 19940/22500 - Loss: 0.11154535412788391, Accuracy: 0.875\n",
            "Step 19941/22500 - Loss: 0.005497659556567669, Accuracy: 1.0\n",
            "Step 19942/22500 - Loss: 0.0033980722073465586, Accuracy: 1.0\n",
            "Step 19943/22500 - Loss: 0.14386141300201416, Accuracy: 1.0\n",
            "Step 19944/22500 - Loss: 0.09169379621744156, Accuracy: 1.0\n",
            "Step 19945/22500 - Loss: 0.09484365582466125, Accuracy: 1.0\n",
            "Step 19946/22500 - Loss: 0.012055782601237297, Accuracy: 1.0\n",
            "Step 19947/22500 - Loss: 0.03019304759800434, Accuracy: 1.0\n",
            "Step 19948/22500 - Loss: 0.040758565068244934, Accuracy: 1.0\n",
            "Step 19949/22500 - Loss: 0.007140436675399542, Accuracy: 1.0\n",
            "Step 19950/22500 - Loss: 0.12840460240840912, Accuracy: 0.875\n",
            "Step 19951/22500 - Loss: 0.03472808375954628, Accuracy: 1.0\n",
            "Step 19952/22500 - Loss: 0.04190953075885773, Accuracy: 1.0\n",
            "Step 19953/22500 - Loss: 0.4904152452945709, Accuracy: 0.875\n",
            "Step 19954/22500 - Loss: 0.005838543642312288, Accuracy: 1.0\n",
            "Step 19955/22500 - Loss: 0.6605923771858215, Accuracy: 0.75\n",
            "Step 19956/22500 - Loss: 0.40424028038978577, Accuracy: 0.875\n",
            "Step 19957/22500 - Loss: 0.04471750557422638, Accuracy: 1.0\n",
            "Step 19958/22500 - Loss: 0.625192403793335, Accuracy: 0.75\n",
            "Step 19959/22500 - Loss: 0.275755912065506, Accuracy: 0.875\n",
            "Step 19960/22500 - Loss: 0.006398988422006369, Accuracy: 1.0\n",
            "Step 19961/22500 - Loss: 0.3630027770996094, Accuracy: 0.875\n",
            "Step 19962/22500 - Loss: 0.027247333899140358, Accuracy: 1.0\n",
            "Step 19963/22500 - Loss: 0.3607833683490753, Accuracy: 0.75\n",
            "Step 19964/22500 - Loss: 0.025302749127149582, Accuracy: 1.0\n",
            "Step 19965/22500 - Loss: 0.007748591713607311, Accuracy: 1.0\n",
            "Step 19966/22500 - Loss: 0.04939670115709305, Accuracy: 1.0\n",
            "Step 19967/22500 - Loss: 0.05695655941963196, Accuracy: 1.0\n",
            "Step 19968/22500 - Loss: 0.06684986501932144, Accuracy: 1.0\n",
            "Step 19969/22500 - Loss: 0.03601083904504776, Accuracy: 1.0\n",
            "Step 19970/22500 - Loss: 0.07738818973302841, Accuracy: 1.0\n",
            "Step 19971/22500 - Loss: 0.020215654745697975, Accuracy: 1.0\n",
            "Step 19972/22500 - Loss: 0.03134441375732422, Accuracy: 1.0\n",
            "Step 19973/22500 - Loss: 0.13256503641605377, Accuracy: 1.0\n",
            "Step 19974/22500 - Loss: 0.0416862815618515, Accuracy: 1.0\n",
            "Step 19975/22500 - Loss: 0.15142425894737244, Accuracy: 1.0\n",
            "Step 19976/22500 - Loss: 0.29163727164268494, Accuracy: 0.75\n",
            "Step 19977/22500 - Loss: 0.3086654841899872, Accuracy: 0.875\n",
            "Step 19978/22500 - Loss: 0.3119505047798157, Accuracy: 0.875\n",
            "Step 19979/22500 - Loss: 0.03583130985498428, Accuracy: 1.0\n",
            "Step 19980/22500 - Loss: 0.18141572177410126, Accuracy: 0.875\n",
            "Step 19981/22500 - Loss: 0.13764715194702148, Accuracy: 0.875\n",
            "Step 19982/22500 - Loss: 0.02868596650660038, Accuracy: 1.0\n",
            "Step 19983/22500 - Loss: 0.026129012927412987, Accuracy: 1.0\n",
            "Step 19984/22500 - Loss: 0.027983125299215317, Accuracy: 1.0\n",
            "Step 19985/22500 - Loss: 0.12180658429861069, Accuracy: 1.0\n",
            "Step 19986/22500 - Loss: 0.027478119358420372, Accuracy: 1.0\n",
            "Step 19987/22500 - Loss: 0.040784429758787155, Accuracy: 1.0\n",
            "Step 19988/22500 - Loss: 0.6519756317138672, Accuracy: 0.875\n",
            "Step 19989/22500 - Loss: 0.08368420600891113, Accuracy: 1.0\n",
            "Step 19990/22500 - Loss: 0.6217771768569946, Accuracy: 0.875\n",
            "Step 19991/22500 - Loss: 0.04457741230726242, Accuracy: 1.0\n",
            "Step 19992/22500 - Loss: 0.03433915227651596, Accuracy: 1.0\n",
            "Step 19993/22500 - Loss: 0.03768051415681839, Accuracy: 1.0\n",
            "Step 19994/22500 - Loss: 0.03644971549510956, Accuracy: 1.0\n",
            "Step 19995/22500 - Loss: 0.01933477632701397, Accuracy: 1.0\n",
            "Step 19996/22500 - Loss: 0.24641095101833344, Accuracy: 0.875\n",
            "Step 19997/22500 - Loss: 0.38951224088668823, Accuracy: 0.875\n",
            "Step 19998/22500 - Loss: 0.05827184394001961, Accuracy: 1.0\n",
            "Step 19999/22500 - Loss: 0.4095638394355774, Accuracy: 0.875\n",
            "Step 20000/22500 - Loss: 0.01334589347243309, Accuracy: 1.0\n",
            "Step 20001/22500 - Loss: 0.07886892557144165, Accuracy: 1.0\n",
            "Step 20002/22500 - Loss: 0.01006996352225542, Accuracy: 1.0\n",
            "Step 20003/22500 - Loss: 0.46931156516075134, Accuracy: 0.875\n",
            "Step 20004/22500 - Loss: 0.05011642351746559, Accuracy: 1.0\n",
            "Step 20005/22500 - Loss: 0.054653070867061615, Accuracy: 1.0\n",
            "Step 20006/22500 - Loss: 0.007752618752419949, Accuracy: 1.0\n",
            "Step 20007/22500 - Loss: 0.015111114829778671, Accuracy: 1.0\n",
            "Step 20008/22500 - Loss: 0.02265075221657753, Accuracy: 1.0\n",
            "Step 20009/22500 - Loss: 0.41984227299690247, Accuracy: 0.75\n",
            "Step 20010/22500 - Loss: 0.016794897615909576, Accuracy: 1.0\n",
            "Step 20011/22500 - Loss: 0.048831384629011154, Accuracy: 1.0\n",
            "Step 20012/22500 - Loss: 0.13375224173069, Accuracy: 1.0\n",
            "Step 20013/22500 - Loss: 0.12635397911071777, Accuracy: 1.0\n",
            "Step 20014/22500 - Loss: 0.5577104091644287, Accuracy: 0.875\n",
            "Step 20015/22500 - Loss: 0.041161973029375076, Accuracy: 1.0\n",
            "Step 20016/22500 - Loss: 0.1296832263469696, Accuracy: 1.0\n",
            "Step 20017/22500 - Loss: 0.19058342278003693, Accuracy: 0.875\n",
            "Step 20018/22500 - Loss: 0.005448898766189814, Accuracy: 1.0\n",
            "Step 20019/22500 - Loss: 0.026878949254751205, Accuracy: 1.0\n",
            "Step 20020/22500 - Loss: 0.0333724170923233, Accuracy: 1.0\n",
            "Step 20021/22500 - Loss: 0.05962108448147774, Accuracy: 1.0\n",
            "Step 20022/22500 - Loss: 0.283692330121994, Accuracy: 0.875\n",
            "Step 20023/22500 - Loss: 0.36536291241645813, Accuracy: 0.875\n",
            "Step 20024/22500 - Loss: 0.03751734644174576, Accuracy: 1.0\n",
            "Step 20025/22500 - Loss: 0.11704818159341812, Accuracy: 0.875\n",
            "Step 20026/22500 - Loss: 0.053036730736494064, Accuracy: 1.0\n",
            "Step 20027/22500 - Loss: 0.12238850444555283, Accuracy: 0.875\n",
            "Step 20028/22500 - Loss: 0.01832742616534233, Accuracy: 1.0\n",
            "Step 20029/22500 - Loss: 0.40471604466438293, Accuracy: 0.875\n",
            "Step 20030/22500 - Loss: 0.016206610947847366, Accuracy: 1.0\n",
            "Step 20031/22500 - Loss: 0.06381738185882568, Accuracy: 1.0\n",
            "Step 20032/22500 - Loss: 0.007644561119377613, Accuracy: 1.0\n",
            "Step 20033/22500 - Loss: 0.03634610399603844, Accuracy: 1.0\n",
            "Step 20034/22500 - Loss: 0.39844852685928345, Accuracy: 0.75\n",
            "Step 20035/22500 - Loss: 0.06483838707208633, Accuracy: 1.0\n",
            "Step 20036/22500 - Loss: 0.4148270785808563, Accuracy: 0.875\n",
            "Step 20037/22500 - Loss: 0.013963647186756134, Accuracy: 1.0\n",
            "Step 20038/22500 - Loss: 0.3220127820968628, Accuracy: 0.875\n",
            "Step 20039/22500 - Loss: 0.1541922688484192, Accuracy: 0.875\n",
            "Step 20040/22500 - Loss: 0.05293256789445877, Accuracy: 1.0\n",
            "Step 20041/22500 - Loss: 0.07316748797893524, Accuracy: 1.0\n",
            "Step 20042/22500 - Loss: 0.021325647830963135, Accuracy: 1.0\n",
            "Step 20043/22500 - Loss: 0.03240777179598808, Accuracy: 1.0\n",
            "Step 20044/22500 - Loss: 0.054501403123140335, Accuracy: 1.0\n",
            "Step 20045/22500 - Loss: 0.0610637441277504, Accuracy: 1.0\n",
            "Step 20046/22500 - Loss: 0.02106001414358616, Accuracy: 1.0\n",
            "Step 20047/22500 - Loss: 0.2633530795574188, Accuracy: 0.875\n",
            "Step 20048/22500 - Loss: 0.032629359513521194, Accuracy: 1.0\n",
            "Step 20049/22500 - Loss: 0.27483171224594116, Accuracy: 0.875\n",
            "Step 20050/22500 - Loss: 0.014175969175994396, Accuracy: 1.0\n",
            "Step 20051/22500 - Loss: 0.05403728783130646, Accuracy: 1.0\n",
            "Step 20052/22500 - Loss: 0.059386640787124634, Accuracy: 1.0\n",
            "Step 20053/22500 - Loss: 0.04278550669550896, Accuracy: 1.0\n",
            "Step 20054/22500 - Loss: 0.006824615877121687, Accuracy: 1.0\n",
            "Step 20055/22500 - Loss: 0.004187315236777067, Accuracy: 1.0\n",
            "Step 20056/22500 - Loss: 0.029081443324685097, Accuracy: 1.0\n",
            "Step 20057/22500 - Loss: 0.01676204986870289, Accuracy: 1.0\n",
            "Step 20058/22500 - Loss: 0.029387276619672775, Accuracy: 1.0\n",
            "Step 20059/22500 - Loss: 0.010430858470499516, Accuracy: 1.0\n",
            "Step 20060/22500 - Loss: 0.02644820138812065, Accuracy: 1.0\n",
            "Step 20061/22500 - Loss: 0.42931506037712097, Accuracy: 0.875\n",
            "Step 20062/22500 - Loss: 0.1777816116809845, Accuracy: 0.875\n",
            "Step 20063/22500 - Loss: 0.00901059340685606, Accuracy: 1.0\n",
            "Step 20064/22500 - Loss: 0.020382441580295563, Accuracy: 1.0\n",
            "Step 20065/22500 - Loss: 0.07975868880748749, Accuracy: 1.0\n",
            "Step 20066/22500 - Loss: 0.0029761570040136576, Accuracy: 1.0\n",
            "Step 20067/22500 - Loss: 0.10754401981830597, Accuracy: 1.0\n",
            "Step 20068/22500 - Loss: 0.14503410458564758, Accuracy: 0.875\n",
            "Step 20069/22500 - Loss: 0.1748637706041336, Accuracy: 0.875\n",
            "Step 20070/22500 - Loss: 0.030422255396842957, Accuracy: 1.0\n",
            "Step 20071/22500 - Loss: 0.14010678231716156, Accuracy: 0.875\n",
            "Step 20072/22500 - Loss: 0.01452949270606041, Accuracy: 1.0\n",
            "Step 20073/22500 - Loss: 0.09687790274620056, Accuracy: 1.0\n",
            "Step 20074/22500 - Loss: 0.030916661024093628, Accuracy: 1.0\n",
            "Step 20075/22500 - Loss: 0.36019566655158997, Accuracy: 0.875\n",
            "Step 20076/22500 - Loss: 0.15254035592079163, Accuracy: 0.875\n",
            "Step 20077/22500 - Loss: 0.2712215185165405, Accuracy: 0.875\n",
            "Step 20078/22500 - Loss: 0.03720569238066673, Accuracy: 1.0\n",
            "Step 20079/22500 - Loss: 0.14188678562641144, Accuracy: 1.0\n",
            "Step 20080/22500 - Loss: 0.027452193200588226, Accuracy: 1.0\n",
            "Step 20081/22500 - Loss: 0.06789101660251617, Accuracy: 1.0\n",
            "Step 20082/22500 - Loss: 0.1109737679362297, Accuracy: 1.0\n",
            "Step 20083/22500 - Loss: 0.011983278207480907, Accuracy: 1.0\n",
            "Step 20084/22500 - Loss: 0.15842615067958832, Accuracy: 0.875\n",
            "Step 20085/22500 - Loss: 0.6297814249992371, Accuracy: 0.75\n",
            "Step 20086/22500 - Loss: 0.043938759714365005, Accuracy: 1.0\n",
            "Step 20087/22500 - Loss: 0.005160253494977951, Accuracy: 1.0\n",
            "Step 20088/22500 - Loss: 0.03994640335440636, Accuracy: 1.0\n",
            "Step 20089/22500 - Loss: 0.03130340576171875, Accuracy: 1.0\n",
            "Step 20090/22500 - Loss: 0.0036040148697793484, Accuracy: 1.0\n",
            "Step 20091/22500 - Loss: 0.009704254567623138, Accuracy: 1.0\n",
            "Step 20092/22500 - Loss: 0.2569091022014618, Accuracy: 0.875\n",
            "Step 20093/22500 - Loss: 0.07905542850494385, Accuracy: 1.0\n",
            "Step 20094/22500 - Loss: 0.012468342669308186, Accuracy: 1.0\n",
            "Step 20095/22500 - Loss: 0.08194092661142349, Accuracy: 1.0\n",
            "Step 20096/22500 - Loss: 0.1067204624414444, Accuracy: 1.0\n",
            "Step 20097/22500 - Loss: 0.062336377799510956, Accuracy: 1.0\n",
            "Step 20098/22500 - Loss: 0.019568026065826416, Accuracy: 1.0\n",
            "Step 20099/22500 - Loss: 0.030329270288348198, Accuracy: 1.0\n",
            "Step 20100/22500 - Loss: 0.04627786949276924, Accuracy: 1.0\n",
            "Step 20101/22500 - Loss: 0.24497917294502258, Accuracy: 0.875\n",
            "Step 20102/22500 - Loss: 0.053156156092882156, Accuracy: 1.0\n",
            "Step 20103/22500 - Loss: 0.4867667257785797, Accuracy: 0.75\n",
            "Step 20104/22500 - Loss: 0.21301674842834473, Accuracy: 0.875\n",
            "Step 20105/22500 - Loss: 0.01953176222741604, Accuracy: 1.0\n",
            "Step 20106/22500 - Loss: 0.0752001479268074, Accuracy: 1.0\n",
            "Step 20107/22500 - Loss: 0.019598552957177162, Accuracy: 1.0\n",
            "Step 20108/22500 - Loss: 0.024802973493933678, Accuracy: 1.0\n",
            "Step 20109/22500 - Loss: 0.021457351744174957, Accuracy: 1.0\n",
            "Step 20110/22500 - Loss: 0.023452023044228554, Accuracy: 1.0\n",
            "Step 20111/22500 - Loss: 0.017396114766597748, Accuracy: 1.0\n",
            "Step 20112/22500 - Loss: 0.04913943260908127, Accuracy: 1.0\n",
            "Step 20113/22500 - Loss: 0.23915381729602814, Accuracy: 0.875\n",
            "Step 20114/22500 - Loss: 0.08606326580047607, Accuracy: 1.0\n",
            "Step 20115/22500 - Loss: 0.1777898669242859, Accuracy: 1.0\n",
            "Step 20116/22500 - Loss: 0.10524791479110718, Accuracy: 0.875\n",
            "Step 20117/22500 - Loss: 0.009771524928510189, Accuracy: 1.0\n",
            "Step 20118/22500 - Loss: 0.06641488522291183, Accuracy: 1.0\n",
            "Step 20119/22500 - Loss: 0.07754149287939072, Accuracy: 1.0\n",
            "Step 20120/22500 - Loss: 0.16454637050628662, Accuracy: 0.875\n",
            "Step 20121/22500 - Loss: 0.025613829493522644, Accuracy: 1.0\n",
            "Step 20122/22500 - Loss: 0.10909811407327652, Accuracy: 1.0\n",
            "Step 20123/22500 - Loss: 0.08858837187290192, Accuracy: 1.0\n",
            "Step 20124/22500 - Loss: 0.03592952713370323, Accuracy: 1.0\n",
            "Step 20125/22500 - Loss: 0.025861795991659164, Accuracy: 1.0\n",
            "Step 20126/22500 - Loss: 0.034024760127067566, Accuracy: 1.0\n",
            "Step 20127/22500 - Loss: 0.007682381197810173, Accuracy: 1.0\n",
            "Step 20128/22500 - Loss: 0.031495317816734314, Accuracy: 1.0\n",
            "Step 20129/22500 - Loss: 0.42723119258880615, Accuracy: 0.75\n",
            "Step 20130/22500 - Loss: 0.04975476488471031, Accuracy: 1.0\n",
            "Step 20131/22500 - Loss: 0.2647072672843933, Accuracy: 0.875\n",
            "Step 20132/22500 - Loss: 0.11214955896139145, Accuracy: 0.875\n",
            "Step 20133/22500 - Loss: 0.018072936683893204, Accuracy: 1.0\n",
            "Step 20134/22500 - Loss: 0.025713196024298668, Accuracy: 1.0\n",
            "Step 20135/22500 - Loss: 0.15503078699111938, Accuracy: 0.875\n",
            "Step 20136/22500 - Loss: 0.008829676546156406, Accuracy: 1.0\n",
            "Step 20137/22500 - Loss: 0.03750945255160332, Accuracy: 1.0\n",
            "Step 20138/22500 - Loss: 0.07024218887090683, Accuracy: 1.0\n",
            "Step 20139/22500 - Loss: 0.2052357941865921, Accuracy: 0.875\n",
            "Step 20140/22500 - Loss: 0.020613742992281914, Accuracy: 1.0\n",
            "Step 20141/22500 - Loss: 0.10971692204475403, Accuracy: 1.0\n",
            "Step 20142/22500 - Loss: 0.10543898493051529, Accuracy: 1.0\n",
            "Step 20143/22500 - Loss: 0.02896084263920784, Accuracy: 1.0\n",
            "Step 20144/22500 - Loss: 0.20849847793579102, Accuracy: 0.875\n",
            "Step 20145/22500 - Loss: 0.047995224595069885, Accuracy: 1.0\n",
            "Step 20146/22500 - Loss: 0.33286339044570923, Accuracy: 0.875\n",
            "Step 20147/22500 - Loss: 0.1579797863960266, Accuracy: 0.875\n",
            "Step 20148/22500 - Loss: 0.1385408490896225, Accuracy: 0.875\n",
            "Step 20149/22500 - Loss: 0.10899113118648529, Accuracy: 0.875\n",
            "Step 20150/22500 - Loss: 0.018270006403326988, Accuracy: 1.0\n",
            "Step 20151/22500 - Loss: 0.7782946825027466, Accuracy: 0.75\n",
            "Step 20152/22500 - Loss: 0.17304837703704834, Accuracy: 0.875\n",
            "Step 20153/22500 - Loss: 0.02671244367957115, Accuracy: 1.0\n",
            "Step 20154/22500 - Loss: 0.0535360611975193, Accuracy: 1.0\n",
            "Step 20155/22500 - Loss: 0.12969952821731567, Accuracy: 0.875\n",
            "Step 20156/22500 - Loss: 0.031692542135715485, Accuracy: 1.0\n",
            "Step 20157/22500 - Loss: 0.3047909736633301, Accuracy: 0.875\n",
            "Step 20158/22500 - Loss: 0.1724267601966858, Accuracy: 1.0\n",
            "Step 20159/22500 - Loss: 0.019704636186361313, Accuracy: 1.0\n",
            "Step 20160/22500 - Loss: 0.011758745647966862, Accuracy: 1.0\n",
            "Step 20161/22500 - Loss: 0.5406534671783447, Accuracy: 0.75\n",
            "Step 20162/22500 - Loss: 0.20294108986854553, Accuracy: 0.875\n",
            "Step 20163/22500 - Loss: 0.06312137097120285, Accuracy: 1.0\n",
            "Step 20164/22500 - Loss: 0.38575035333633423, Accuracy: 0.75\n",
            "Step 20165/22500 - Loss: 0.014136376790702343, Accuracy: 1.0\n",
            "Step 20166/22500 - Loss: 0.034273307770490646, Accuracy: 1.0\n",
            "Step 20167/22500 - Loss: 0.20194140076637268, Accuracy: 0.875\n",
            "Step 20168/22500 - Loss: 0.09958546608686447, Accuracy: 1.0\n",
            "Step 20169/22500 - Loss: 0.6576012372970581, Accuracy: 0.875\n",
            "Step 20170/22500 - Loss: 0.008097507059574127, Accuracy: 1.0\n",
            "Step 20171/22500 - Loss: 0.016703475266695023, Accuracy: 1.0\n",
            "Step 20172/22500 - Loss: 0.25772735476493835, Accuracy: 0.875\n",
            "Step 20173/22500 - Loss: 0.041652534157037735, Accuracy: 1.0\n",
            "Step 20174/22500 - Loss: 0.29121097922325134, Accuracy: 0.875\n",
            "Step 20175/22500 - Loss: 0.06533369421958923, Accuracy: 1.0\n",
            "Step 20176/22500 - Loss: 0.26499029994010925, Accuracy: 0.75\n",
            "Step 20177/22500 - Loss: 0.030326280742883682, Accuracy: 1.0\n",
            "Step 20178/22500 - Loss: 0.009573930874466896, Accuracy: 1.0\n",
            "Step 20179/22500 - Loss: 0.43695682287216187, Accuracy: 0.75\n",
            "Step 20180/22500 - Loss: 0.0264567993581295, Accuracy: 1.0\n",
            "Step 20181/22500 - Loss: 0.06345835328102112, Accuracy: 1.0\n",
            "Step 20182/22500 - Loss: 0.05274388566613197, Accuracy: 1.0\n",
            "Step 20183/22500 - Loss: 0.08872222900390625, Accuracy: 1.0\n",
            "Step 20184/22500 - Loss: 0.005165561102330685, Accuracy: 1.0\n",
            "Step 20185/22500 - Loss: 0.14967839419841766, Accuracy: 0.875\n",
            "Step 20186/22500 - Loss: 0.24428510665893555, Accuracy: 0.75\n",
            "Step 20187/22500 - Loss: 0.14338769018650055, Accuracy: 0.875\n",
            "Step 20188/22500 - Loss: 0.01431796420365572, Accuracy: 1.0\n",
            "Step 20189/22500 - Loss: 0.011263028718531132, Accuracy: 1.0\n",
            "Step 20190/22500 - Loss: 0.004867286887019873, Accuracy: 1.0\n",
            "Step 20191/22500 - Loss: 0.03891708329319954, Accuracy: 1.0\n",
            "Step 20192/22500 - Loss: 0.042989544570446014, Accuracy: 1.0\n",
            "Step 20193/22500 - Loss: 0.016288908198475838, Accuracy: 1.0\n",
            "Step 20194/22500 - Loss: 0.4143466353416443, Accuracy: 0.875\n",
            "Step 20195/22500 - Loss: 0.09689914435148239, Accuracy: 1.0\n",
            "Step 20196/22500 - Loss: 0.0074281515553593636, Accuracy: 1.0\n",
            "Step 20197/22500 - Loss: 0.027847103774547577, Accuracy: 1.0\n",
            "Step 20198/22500 - Loss: 0.020704414695501328, Accuracy: 1.0\n",
            "Step 20199/22500 - Loss: 0.011507024988532066, Accuracy: 1.0\n",
            "Step 20200/22500 - Loss: 0.07770034670829773, Accuracy: 1.0\n",
            "Step 20201/22500 - Loss: 0.23328350484371185, Accuracy: 0.875\n",
            "Step 20202/22500 - Loss: 0.004835496190935373, Accuracy: 1.0\n",
            "Step 20203/22500 - Loss: 0.024639159440994263, Accuracy: 1.0\n",
            "Step 20204/22500 - Loss: 0.03869806230068207, Accuracy: 1.0\n",
            "Step 20205/22500 - Loss: 0.051569707691669464, Accuracy: 1.0\n",
            "Step 20206/22500 - Loss: 0.30036643147468567, Accuracy: 0.875\n",
            "Step 20207/22500 - Loss: 0.1642284244298935, Accuracy: 0.875\n",
            "Step 20208/22500 - Loss: 0.01149804424494505, Accuracy: 1.0\n",
            "Step 20209/22500 - Loss: 0.35314106941223145, Accuracy: 0.875\n",
            "Step 20210/22500 - Loss: 0.19054989516735077, Accuracy: 0.875\n",
            "Step 20211/22500 - Loss: 0.4440334439277649, Accuracy: 0.875\n",
            "Step 20212/22500 - Loss: 0.36874711513519287, Accuracy: 0.875\n",
            "Step 20213/22500 - Loss: 0.18190565705299377, Accuracy: 0.875\n",
            "Step 20214/22500 - Loss: 0.00952679943293333, Accuracy: 1.0\n",
            "Step 20215/22500 - Loss: 0.1378442794084549, Accuracy: 0.875\n",
            "Step 20216/22500 - Loss: 0.05827050656080246, Accuracy: 1.0\n",
            "Step 20217/22500 - Loss: 0.2182934731245041, Accuracy: 0.875\n",
            "Step 20218/22500 - Loss: 0.3670024573802948, Accuracy: 0.75\n",
            "Step 20219/22500 - Loss: 0.10327133536338806, Accuracy: 1.0\n",
            "Step 20220/22500 - Loss: 0.07463859766721725, Accuracy: 1.0\n",
            "Step 20221/22500 - Loss: 0.0814676582813263, Accuracy: 1.0\n",
            "Step 20222/22500 - Loss: 0.030719079077243805, Accuracy: 1.0\n",
            "Step 20223/22500 - Loss: 0.4426051080226898, Accuracy: 0.75\n",
            "Step 20224/22500 - Loss: 0.037189826369285583, Accuracy: 1.0\n",
            "Step 20225/22500 - Loss: 0.046191927045583725, Accuracy: 1.0\n",
            "Step 20226/22500 - Loss: 0.0541129894554615, Accuracy: 1.0\n",
            "Step 20227/22500 - Loss: 0.5312690734863281, Accuracy: 0.625\n",
            "Step 20228/22500 - Loss: 0.0818265825510025, Accuracy: 1.0\n",
            "Step 20229/22500 - Loss: 0.007829665206372738, Accuracy: 1.0\n",
            "Step 20230/22500 - Loss: 0.004894883371889591, Accuracy: 1.0\n",
            "Step 20231/22500 - Loss: 0.04308293014764786, Accuracy: 1.0\n",
            "Step 20232/22500 - Loss: 0.41852521896362305, Accuracy: 0.75\n",
            "Step 20233/22500 - Loss: 0.031178999692201614, Accuracy: 1.0\n",
            "Step 20234/22500 - Loss: 0.27023056149482727, Accuracy: 0.875\n",
            "Step 20235/22500 - Loss: 0.020984657108783722, Accuracy: 1.0\n",
            "Step 20236/22500 - Loss: 0.01871880330145359, Accuracy: 1.0\n",
            "Step 20237/22500 - Loss: 0.040699951350688934, Accuracy: 1.0\n",
            "Step 20238/22500 - Loss: 0.02473444864153862, Accuracy: 1.0\n",
            "Step 20239/22500 - Loss: 0.11306364834308624, Accuracy: 0.875\n",
            "Step 20240/22500 - Loss: 0.030656937509775162, Accuracy: 1.0\n",
            "Step 20241/22500 - Loss: 0.5102977752685547, Accuracy: 0.875\n",
            "Step 20242/22500 - Loss: 0.05187462270259857, Accuracy: 1.0\n",
            "Step 20243/22500 - Loss: 0.0037634316831827164, Accuracy: 1.0\n",
            "Step 20244/22500 - Loss: 0.05460917204618454, Accuracy: 1.0\n",
            "Step 20245/22500 - Loss: 0.711485743522644, Accuracy: 0.75\n",
            "Step 20246/22500 - Loss: 0.09571828693151474, Accuracy: 1.0\n",
            "Step 20247/22500 - Loss: 0.3538098931312561, Accuracy: 0.875\n",
            "Step 20248/22500 - Loss: 0.016141070052981377, Accuracy: 1.0\n",
            "Step 20249/22500 - Loss: 0.04141802340745926, Accuracy: 1.0\n",
            "Step 20250/22500 - Loss: 0.05014447867870331, Accuracy: 1.0\n",
            "Step 20251/22500 - Loss: 0.03496391698718071, Accuracy: 1.0\n",
            "Step 20252/22500 - Loss: 0.045753661543130875, Accuracy: 1.0\n",
            "Step 20253/22500 - Loss: 0.052399177104234695, Accuracy: 1.0\n",
            "Step 20254/22500 - Loss: 0.07724753022193909, Accuracy: 1.0\n",
            "Step 20255/22500 - Loss: 0.029827233403921127, Accuracy: 1.0\n",
            "Step 20256/22500 - Loss: 0.01925356686115265, Accuracy: 1.0\n",
            "Step 20257/22500 - Loss: 0.06772646307945251, Accuracy: 1.0\n",
            "Step 20258/22500 - Loss: 0.40959325432777405, Accuracy: 0.75\n",
            "Step 20259/22500 - Loss: 0.054465390741825104, Accuracy: 1.0\n",
            "Step 20260/22500 - Loss: 0.06446672976016998, Accuracy: 1.0\n",
            "Step 20261/22500 - Loss: 0.21478873491287231, Accuracy: 0.875\n",
            "Step 20262/22500 - Loss: 0.0950799211859703, Accuracy: 1.0\n",
            "Step 20263/22500 - Loss: 0.09076245129108429, Accuracy: 1.0\n",
            "Step 20264/22500 - Loss: 0.39832302927970886, Accuracy: 0.875\n",
            "Step 20265/22500 - Loss: 0.03706061840057373, Accuracy: 1.0\n",
            "Step 20266/22500 - Loss: 0.012431285344064236, Accuracy: 1.0\n",
            "Step 20267/22500 - Loss: 0.04967733845114708, Accuracy: 1.0\n",
            "Step 20268/22500 - Loss: 0.05850183591246605, Accuracy: 1.0\n",
            "Step 20269/22500 - Loss: 0.03595413267612457, Accuracy: 1.0\n",
            "Step 20270/22500 - Loss: 0.0587676465511322, Accuracy: 1.0\n",
            "Step 20271/22500 - Loss: 0.004885230213403702, Accuracy: 1.0\n",
            "Step 20272/22500 - Loss: 0.027342887595295906, Accuracy: 1.0\n",
            "Step 20273/22500 - Loss: 0.11837713420391083, Accuracy: 1.0\n",
            "Step 20274/22500 - Loss: 0.06568669527769089, Accuracy: 1.0\n",
            "Step 20275/22500 - Loss: 0.00938732735812664, Accuracy: 1.0\n",
            "Step 20276/22500 - Loss: 0.010197051800787449, Accuracy: 1.0\n",
            "Step 20277/22500 - Loss: 0.014574588276445866, Accuracy: 1.0\n",
            "Step 20278/22500 - Loss: 0.0069430433213710785, Accuracy: 1.0\n",
            "Step 20279/22500 - Loss: 0.37760627269744873, Accuracy: 0.875\n",
            "Step 20280/22500 - Loss: 0.25035360455513, Accuracy: 0.875\n",
            "Step 20281/22500 - Loss: 0.0766812413930893, Accuracy: 1.0\n",
            "Step 20282/22500 - Loss: 0.0582876093685627, Accuracy: 1.0\n",
            "Step 20283/22500 - Loss: 0.019889533519744873, Accuracy: 1.0\n",
            "Step 20284/22500 - Loss: 0.3461214303970337, Accuracy: 0.875\n",
            "Step 20285/22500 - Loss: 0.20371602475643158, Accuracy: 0.875\n",
            "Step 20286/22500 - Loss: 0.4654655158519745, Accuracy: 0.875\n",
            "Step 20287/22500 - Loss: 0.02534208819270134, Accuracy: 1.0\n",
            "Step 20288/22500 - Loss: 0.08485277742147446, Accuracy: 1.0\n",
            "Step 20289/22500 - Loss: 0.3243792653083801, Accuracy: 0.875\n",
            "Step 20290/22500 - Loss: 0.008529596030712128, Accuracy: 1.0\n",
            "Step 20291/22500 - Loss: 0.012032464146614075, Accuracy: 1.0\n",
            "Step 20292/22500 - Loss: 0.01517768669873476, Accuracy: 1.0\n",
            "Step 20293/22500 - Loss: 0.013542458415031433, Accuracy: 1.0\n",
            "Step 20294/22500 - Loss: 0.2007676362991333, Accuracy: 0.875\n",
            "Step 20295/22500 - Loss: 0.046029143035411835, Accuracy: 1.0\n",
            "Step 20296/22500 - Loss: 0.16286936402320862, Accuracy: 0.875\n",
            "Step 20297/22500 - Loss: 0.0894467681646347, Accuracy: 1.0\n",
            "Step 20298/22500 - Loss: 0.15766778588294983, Accuracy: 0.875\n",
            "Step 20299/22500 - Loss: 0.005795050412416458, Accuracy: 1.0\n",
            "Step 20300/22500 - Loss: 0.035919252783060074, Accuracy: 1.0\n",
            "Step 20301/22500 - Loss: 0.048373207449913025, Accuracy: 1.0\n",
            "Step 20302/22500 - Loss: 0.049128685146570206, Accuracy: 1.0\n",
            "Step 20303/22500 - Loss: 0.032443396747112274, Accuracy: 1.0\n",
            "Step 20304/22500 - Loss: 0.012855135835707188, Accuracy: 1.0\n",
            "Step 20305/22500 - Loss: 0.131546750664711, Accuracy: 0.875\n",
            "Step 20306/22500 - Loss: 0.013470001518726349, Accuracy: 1.0\n",
            "Step 20307/22500 - Loss: 0.03391260653734207, Accuracy: 1.0\n",
            "Step 20308/22500 - Loss: 0.051980044692754745, Accuracy: 1.0\n",
            "Step 20309/22500 - Loss: 0.023857222869992256, Accuracy: 1.0\n",
            "Step 20310/22500 - Loss: 0.027219485491514206, Accuracy: 1.0\n",
            "Step 20311/22500 - Loss: 0.24593406915664673, Accuracy: 0.875\n",
            "Step 20312/22500 - Loss: 0.3303128778934479, Accuracy: 0.875\n",
            "Step 20313/22500 - Loss: 0.4121820032596588, Accuracy: 0.875\n",
            "Step 20314/22500 - Loss: 0.06686978787183762, Accuracy: 1.0\n",
            "Step 20315/22500 - Loss: 0.08796501904726028, Accuracy: 1.0\n",
            "Step 20316/22500 - Loss: 0.23820646107196808, Accuracy: 0.875\n",
            "Step 20317/22500 - Loss: 0.03814328834414482, Accuracy: 1.0\n",
            "Step 20318/22500 - Loss: 0.2824723720550537, Accuracy: 0.875\n",
            "Step 20319/22500 - Loss: 0.03259623423218727, Accuracy: 1.0\n",
            "Step 20320/22500 - Loss: 0.08318953961133957, Accuracy: 1.0\n",
            "Step 20321/22500 - Loss: 0.22465650737285614, Accuracy: 0.875\n",
            "Step 20322/22500 - Loss: 0.012623708695173264, Accuracy: 1.0\n",
            "Step 20323/22500 - Loss: 0.017652003094553947, Accuracy: 1.0\n",
            "Step 20324/22500 - Loss: 0.11992979794740677, Accuracy: 0.875\n",
            "Step 20325/22500 - Loss: 0.10049092769622803, Accuracy: 0.875\n",
            "Step 20326/22500 - Loss: 0.5928252935409546, Accuracy: 0.875\n",
            "Step 20327/22500 - Loss: 0.09420998394489288, Accuracy: 1.0\n",
            "Step 20328/22500 - Loss: 0.006901304237544537, Accuracy: 1.0\n",
            "Step 20329/22500 - Loss: 0.052619557827711105, Accuracy: 1.0\n",
            "Step 20330/22500 - Loss: 0.12409673631191254, Accuracy: 0.875\n",
            "Step 20331/22500 - Loss: 0.08081208169460297, Accuracy: 1.0\n",
            "Step 20332/22500 - Loss: 0.017124010249972343, Accuracy: 1.0\n",
            "Step 20333/22500 - Loss: 0.6302877068519592, Accuracy: 0.875\n",
            "Step 20334/22500 - Loss: 0.09127532690763474, Accuracy: 1.0\n",
            "Step 20335/22500 - Loss: 0.011485490947961807, Accuracy: 1.0\n",
            "Step 20336/22500 - Loss: 0.03516266122460365, Accuracy: 1.0\n",
            "Step 20337/22500 - Loss: 0.3492397367954254, Accuracy: 0.875\n",
            "Step 20338/22500 - Loss: 0.10999959707260132, Accuracy: 1.0\n",
            "Step 20339/22500 - Loss: 0.017280200496315956, Accuracy: 1.0\n",
            "Step 20340/22500 - Loss: 0.036891672760248184, Accuracy: 1.0\n",
            "Step 20341/22500 - Loss: 0.5333276391029358, Accuracy: 0.75\n",
            "Step 20342/22500 - Loss: 0.0047602117992937565, Accuracy: 1.0\n",
            "Step 20343/22500 - Loss: 0.1000189557671547, Accuracy: 1.0\n",
            "Step 20344/22500 - Loss: 0.15750473737716675, Accuracy: 0.875\n",
            "Step 20345/22500 - Loss: 0.03903999179601669, Accuracy: 1.0\n",
            "Step 20346/22500 - Loss: 0.013345152139663696, Accuracy: 1.0\n",
            "Step 20347/22500 - Loss: 0.027108920738101006, Accuracy: 1.0\n",
            "Step 20348/22500 - Loss: 0.08845849335193634, Accuracy: 1.0\n",
            "Step 20349/22500 - Loss: 0.05564018338918686, Accuracy: 1.0\n",
            "Step 20350/22500 - Loss: 0.0960579514503479, Accuracy: 1.0\n",
            "Step 20351/22500 - Loss: 0.018913593143224716, Accuracy: 1.0\n",
            "Step 20352/22500 - Loss: 0.022753743454813957, Accuracy: 1.0\n",
            "Step 20353/22500 - Loss: 0.2519359290599823, Accuracy: 0.875\n",
            "Step 20354/22500 - Loss: 0.7402939796447754, Accuracy: 0.625\n",
            "Step 20355/22500 - Loss: 0.056425780057907104, Accuracy: 1.0\n",
            "Step 20356/22500 - Loss: 0.0878620445728302, Accuracy: 1.0\n",
            "Step 20357/22500 - Loss: 0.08051417022943497, Accuracy: 1.0\n",
            "Step 20358/22500 - Loss: 0.06088128685951233, Accuracy: 1.0\n",
            "Step 20359/22500 - Loss: 0.03095889650285244, Accuracy: 1.0\n",
            "Step 20360/22500 - Loss: 0.34780699014663696, Accuracy: 0.875\n",
            "Step 20361/22500 - Loss: 0.3728499412536621, Accuracy: 0.75\n",
            "Step 20362/22500 - Loss: 0.3071431517601013, Accuracy: 0.875\n",
            "Step 20363/22500 - Loss: 0.04392751306295395, Accuracy: 1.0\n",
            "Step 20364/22500 - Loss: 0.0098193334415555, Accuracy: 1.0\n",
            "Step 20365/22500 - Loss: 0.1448683887720108, Accuracy: 0.875\n",
            "Step 20366/22500 - Loss: 0.16670718789100647, Accuracy: 0.875\n",
            "Step 20367/22500 - Loss: 0.0059361765161156654, Accuracy: 1.0\n",
            "Step 20368/22500 - Loss: 0.22158518433570862, Accuracy: 0.875\n",
            "Step 20369/22500 - Loss: 0.14379242062568665, Accuracy: 1.0\n",
            "Step 20370/22500 - Loss: 0.017232388257980347, Accuracy: 1.0\n",
            "Step 20371/22500 - Loss: 0.73135906457901, Accuracy: 0.625\n",
            "Step 20372/22500 - Loss: 0.1662641018629074, Accuracy: 0.875\n",
            "Step 20373/22500 - Loss: 0.01765831746160984, Accuracy: 1.0\n",
            "Step 20374/22500 - Loss: 0.2706974446773529, Accuracy: 0.875\n",
            "Step 20375/22500 - Loss: 0.3994261622428894, Accuracy: 0.875\n",
            "Step 20376/22500 - Loss: 0.08662047237157822, Accuracy: 1.0\n",
            "Step 20377/22500 - Loss: 0.022533319890499115, Accuracy: 1.0\n",
            "Step 20378/22500 - Loss: 0.09172872453927994, Accuracy: 0.875\n",
            "Step 20379/22500 - Loss: 0.06275095045566559, Accuracy: 1.0\n",
            "Step 20380/22500 - Loss: 0.02058260887861252, Accuracy: 1.0\n",
            "Step 20381/22500 - Loss: 0.5730001330375671, Accuracy: 0.875\n",
            "Step 20382/22500 - Loss: 0.04534249007701874, Accuracy: 1.0\n",
            "Step 20383/22500 - Loss: 0.02119257114827633, Accuracy: 1.0\n",
            "Step 20384/22500 - Loss: 0.21725322306156158, Accuracy: 0.875\n",
            "Step 20385/22500 - Loss: 0.14832653105258942, Accuracy: 0.875\n",
            "Step 20386/22500 - Loss: 0.032913073897361755, Accuracy: 1.0\n",
            "Step 20387/22500 - Loss: 0.11652783304452896, Accuracy: 0.875\n",
            "Step 20388/22500 - Loss: 0.020741993561387062, Accuracy: 1.0\n",
            "Step 20389/22500 - Loss: 0.679020345211029, Accuracy: 0.625\n",
            "Step 20390/22500 - Loss: 0.019537484273314476, Accuracy: 1.0\n",
            "Step 20391/22500 - Loss: 0.30656173825263977, Accuracy: 0.875\n",
            "Step 20392/22500 - Loss: 0.06547485291957855, Accuracy: 1.0\n",
            "Step 20393/22500 - Loss: 0.03717928007245064, Accuracy: 1.0\n",
            "Step 20394/22500 - Loss: 0.19104138016700745, Accuracy: 1.0\n",
            "Step 20395/22500 - Loss: 0.1174841895699501, Accuracy: 1.0\n",
            "Step 20396/22500 - Loss: 0.019679594784975052, Accuracy: 1.0\n",
            "Step 20397/22500 - Loss: 0.07425278425216675, Accuracy: 1.0\n",
            "Step 20398/22500 - Loss: 0.04348449036478996, Accuracy: 1.0\n",
            "Step 20399/22500 - Loss: 0.01269554253667593, Accuracy: 1.0\n",
            "Step 20400/22500 - Loss: 0.04622650891542435, Accuracy: 1.0\n",
            "Step 20401/22500 - Loss: 0.12082166969776154, Accuracy: 1.0\n",
            "Step 20402/22500 - Loss: 0.01462005265057087, Accuracy: 1.0\n",
            "Step 20403/22500 - Loss: 0.44928881525993347, Accuracy: 0.875\n",
            "Step 20404/22500 - Loss: 0.05459905415773392, Accuracy: 1.0\n",
            "Step 20405/22500 - Loss: 0.015598367899656296, Accuracy: 1.0\n",
            "Step 20406/22500 - Loss: 0.07018258422613144, Accuracy: 1.0\n",
            "Step 20407/22500 - Loss: 0.0353207066655159, Accuracy: 1.0\n",
            "Step 20408/22500 - Loss: 0.01515739131718874, Accuracy: 1.0\n",
            "Step 20409/22500 - Loss: 0.23999547958374023, Accuracy: 0.75\n",
            "Step 20410/22500 - Loss: 0.03576822206377983, Accuracy: 1.0\n",
            "Step 20411/22500 - Loss: 0.07782196253538132, Accuracy: 1.0\n",
            "Step 20412/22500 - Loss: 0.007150127086788416, Accuracy: 1.0\n",
            "Step 20413/22500 - Loss: 0.011796796694397926, Accuracy: 1.0\n",
            "Step 20414/22500 - Loss: 0.0025930150877684355, Accuracy: 1.0\n",
            "Step 20415/22500 - Loss: 0.012935060076415539, Accuracy: 1.0\n",
            "Step 20416/22500 - Loss: 0.03739582747220993, Accuracy: 1.0\n",
            "Step 20417/22500 - Loss: 0.016368167474865913, Accuracy: 1.0\n",
            "Step 20418/22500 - Loss: 0.4705250859260559, Accuracy: 0.875\n",
            "Step 20419/22500 - Loss: 0.08314025402069092, Accuracy: 1.0\n",
            "Step 20420/22500 - Loss: 0.28820425271987915, Accuracy: 0.875\n",
            "Step 20421/22500 - Loss: 0.18813660740852356, Accuracy: 1.0\n",
            "Step 20422/22500 - Loss: 0.020483896136283875, Accuracy: 1.0\n",
            "Step 20423/22500 - Loss: 0.1824398785829544, Accuracy: 0.875\n",
            "Step 20424/22500 - Loss: 0.01620468869805336, Accuracy: 1.0\n",
            "Step 20425/22500 - Loss: 0.0052861180156469345, Accuracy: 1.0\n",
            "Step 20426/22500 - Loss: 0.004792267922312021, Accuracy: 1.0\n",
            "Step 20427/22500 - Loss: 0.052084144204854965, Accuracy: 1.0\n",
            "Step 20428/22500 - Loss: 0.023173682391643524, Accuracy: 1.0\n",
            "Step 20429/22500 - Loss: 0.08483342826366425, Accuracy: 1.0\n",
            "Step 20430/22500 - Loss: 0.04788699746131897, Accuracy: 1.0\n",
            "Step 20431/22500 - Loss: 0.20910868048667908, Accuracy: 0.875\n",
            "Step 20432/22500 - Loss: 0.28840017318725586, Accuracy: 0.875\n",
            "Step 20433/22500 - Loss: 0.38253358006477356, Accuracy: 0.875\n",
            "Step 20434/22500 - Loss: 0.07273693382740021, Accuracy: 1.0\n",
            "Step 20435/22500 - Loss: 0.09423188120126724, Accuracy: 0.875\n",
            "Step 20436/22500 - Loss: 0.09814182668924332, Accuracy: 1.0\n",
            "Step 20437/22500 - Loss: 0.1663345992565155, Accuracy: 0.875\n",
            "Step 20438/22500 - Loss: 0.19792185723781586, Accuracy: 0.875\n",
            "Step 20439/22500 - Loss: 0.06768840551376343, Accuracy: 1.0\n",
            "Step 20440/22500 - Loss: 0.3759407699108124, Accuracy: 0.75\n",
            "Step 20441/22500 - Loss: 0.029960190877318382, Accuracy: 1.0\n",
            "Step 20442/22500 - Loss: 0.08574342727661133, Accuracy: 1.0\n",
            "Step 20443/22500 - Loss: 0.04823698103427887, Accuracy: 1.0\n",
            "Step 20444/22500 - Loss: 0.06422226130962372, Accuracy: 1.0\n",
            "Step 20445/22500 - Loss: 0.3343356251716614, Accuracy: 0.75\n",
            "Step 20446/22500 - Loss: 0.5372270345687866, Accuracy: 0.875\n",
            "Step 20447/22500 - Loss: 0.0700223371386528, Accuracy: 1.0\n",
            "Step 20448/22500 - Loss: 0.16028304398059845, Accuracy: 1.0\n",
            "Step 20449/22500 - Loss: 0.20854529738426208, Accuracy: 0.875\n",
            "Step 20450/22500 - Loss: 0.02339886501431465, Accuracy: 1.0\n",
            "Step 20451/22500 - Loss: 0.09355124086141586, Accuracy: 1.0\n",
            "Step 20452/22500 - Loss: 0.2377844750881195, Accuracy: 0.875\n",
            "Step 20453/22500 - Loss: 0.11352851986885071, Accuracy: 0.875\n",
            "Step 20454/22500 - Loss: 0.0668630301952362, Accuracy: 1.0\n",
            "Step 20455/22500 - Loss: 0.2898995876312256, Accuracy: 0.875\n",
            "Step 20456/22500 - Loss: 0.05978826433420181, Accuracy: 1.0\n",
            "Step 20457/22500 - Loss: 0.13790389895439148, Accuracy: 0.875\n",
            "Step 20458/22500 - Loss: 0.16346056759357452, Accuracy: 0.875\n",
            "Step 20459/22500 - Loss: 0.10071711987257004, Accuracy: 0.875\n",
            "Step 20460/22500 - Loss: 0.01728207990527153, Accuracy: 1.0\n",
            "Step 20461/22500 - Loss: 0.01711927354335785, Accuracy: 1.0\n",
            "Step 20462/22500 - Loss: 0.0025212892796844244, Accuracy: 1.0\n",
            "Step 20463/22500 - Loss: 0.5184876918792725, Accuracy: 0.875\n",
            "Step 20464/22500 - Loss: 0.09570235759019852, Accuracy: 1.0\n",
            "Step 20465/22500 - Loss: 0.32116904854774475, Accuracy: 0.875\n",
            "Step 20466/22500 - Loss: 0.1086835116147995, Accuracy: 0.875\n",
            "Step 20467/22500 - Loss: 0.14732356369495392, Accuracy: 0.875\n",
            "Step 20468/22500 - Loss: 0.19444680213928223, Accuracy: 0.875\n",
            "Step 20469/22500 - Loss: 0.01894678920507431, Accuracy: 1.0\n",
            "Step 20470/22500 - Loss: 0.22502951323986053, Accuracy: 0.875\n",
            "Step 20471/22500 - Loss: 0.054469846189022064, Accuracy: 1.0\n",
            "Step 20472/22500 - Loss: 0.8716356754302979, Accuracy: 0.75\n",
            "Step 20473/22500 - Loss: 0.4605932831764221, Accuracy: 0.75\n",
            "Step 20474/22500 - Loss: 0.5644986629486084, Accuracy: 0.75\n",
            "Step 20475/22500 - Loss: 0.01824275217950344, Accuracy: 1.0\n",
            "Step 20476/22500 - Loss: 0.201233372092247, Accuracy: 0.875\n",
            "Step 20477/22500 - Loss: 0.005856522358953953, Accuracy: 1.0\n",
            "Step 20478/22500 - Loss: 0.0808895006775856, Accuracy: 1.0\n",
            "Step 20479/22500 - Loss: 0.013884326443076134, Accuracy: 1.0\n",
            "Step 20480/22500 - Loss: 0.07065712660551071, Accuracy: 1.0\n",
            "Step 20481/22500 - Loss: 0.7334495186805725, Accuracy: 0.75\n",
            "Step 20482/22500 - Loss: 0.05276041105389595, Accuracy: 1.0\n",
            "Step 20483/22500 - Loss: 0.03255539387464523, Accuracy: 1.0\n",
            "Step 20484/22500 - Loss: 0.05786487087607384, Accuracy: 1.0\n",
            "Step 20485/22500 - Loss: 0.10745473951101303, Accuracy: 1.0\n",
            "Step 20486/22500 - Loss: 0.09427012503147125, Accuracy: 1.0\n",
            "Step 20487/22500 - Loss: 0.1516326665878296, Accuracy: 0.875\n",
            "Step 20488/22500 - Loss: 0.01846863515675068, Accuracy: 1.0\n",
            "Step 20489/22500 - Loss: 0.041343558579683304, Accuracy: 1.0\n",
            "Step 20490/22500 - Loss: 0.2512822449207306, Accuracy: 0.875\n",
            "Step 20491/22500 - Loss: 0.07654917985200882, Accuracy: 1.0\n",
            "Step 20492/22500 - Loss: 0.10076025128364563, Accuracy: 0.875\n",
            "Step 20493/22500 - Loss: 0.44672176241874695, Accuracy: 0.875\n",
            "Step 20494/22500 - Loss: 0.17238661646842957, Accuracy: 0.875\n",
            "Step 20495/22500 - Loss: 0.058109100908041, Accuracy: 1.0\n",
            "Step 20496/22500 - Loss: 0.041711706668138504, Accuracy: 1.0\n",
            "Step 20497/22500 - Loss: 0.03662965074181557, Accuracy: 1.0\n",
            "Step 20498/22500 - Loss: 0.17072239518165588, Accuracy: 0.875\n",
            "Step 20499/22500 - Loss: 0.24105729162693024, Accuracy: 0.875\n",
            "Step 20500/22500 - Loss: 0.029008828103542328, Accuracy: 1.0\n",
            "Step 20501/22500 - Loss: 0.12788519263267517, Accuracy: 1.0\n",
            "Step 20502/22500 - Loss: 0.09558996558189392, Accuracy: 1.0\n",
            "Step 20503/22500 - Loss: 0.058386899530887604, Accuracy: 1.0\n",
            "Step 20504/22500 - Loss: 0.11749034374952316, Accuracy: 1.0\n",
            "Step 20505/22500 - Loss: 0.15133872628211975, Accuracy: 0.875\n",
            "Step 20506/22500 - Loss: 0.08207430690526962, Accuracy: 1.0\n",
            "Step 20507/22500 - Loss: 0.17975713312625885, Accuracy: 0.875\n",
            "Step 20508/22500 - Loss: 0.06753501296043396, Accuracy: 1.0\n",
            "Step 20509/22500 - Loss: 0.029452405869960785, Accuracy: 1.0\n",
            "Step 20510/22500 - Loss: 0.07372363656759262, Accuracy: 1.0\n",
            "Step 20511/22500 - Loss: 0.3273887634277344, Accuracy: 0.875\n",
            "Step 20512/22500 - Loss: 0.007213045842945576, Accuracy: 1.0\n",
            "Step 20513/22500 - Loss: 0.019588280469179153, Accuracy: 1.0\n",
            "Step 20514/22500 - Loss: 0.011403201147913933, Accuracy: 1.0\n",
            "Step 20515/22500 - Loss: 0.011591611430048943, Accuracy: 1.0\n",
            "Step 20516/22500 - Loss: 0.3057628571987152, Accuracy: 0.875\n",
            "Step 20517/22500 - Loss: 0.018905961886048317, Accuracy: 1.0\n",
            "Step 20518/22500 - Loss: 0.0017467859433963895, Accuracy: 1.0\n",
            "Step 20519/22500 - Loss: 0.04124440997838974, Accuracy: 1.0\n",
            "Step 20520/22500 - Loss: 0.026361210271716118, Accuracy: 1.0\n",
            "Step 20521/22500 - Loss: 0.3876688778400421, Accuracy: 0.875\n",
            "Step 20522/22500 - Loss: 0.04322672262787819, Accuracy: 1.0\n",
            "Step 20523/22500 - Loss: 0.20001362264156342, Accuracy: 0.875\n",
            "Step 20524/22500 - Loss: 0.14785417914390564, Accuracy: 0.875\n",
            "Step 20525/22500 - Loss: 0.03193233534693718, Accuracy: 1.0\n",
            "Step 20526/22500 - Loss: 0.007154060993343592, Accuracy: 1.0\n",
            "Step 20527/22500 - Loss: 0.008941082283854485, Accuracy: 1.0\n",
            "Step 20528/22500 - Loss: 0.009853711351752281, Accuracy: 1.0\n",
            "Step 20529/22500 - Loss: 0.04186457023024559, Accuracy: 1.0\n",
            "Step 20530/22500 - Loss: 0.05757889896631241, Accuracy: 1.0\n",
            "Step 20531/22500 - Loss: 0.43366456031799316, Accuracy: 0.875\n",
            "Step 20532/22500 - Loss: 0.27824535965919495, Accuracy: 0.875\n",
            "Step 20533/22500 - Loss: 0.04359830170869827, Accuracy: 1.0\n",
            "Step 20534/22500 - Loss: 0.22371788322925568, Accuracy: 0.875\n",
            "Step 20535/22500 - Loss: 0.09223363548517227, Accuracy: 1.0\n",
            "Step 20536/22500 - Loss: 0.013159295544028282, Accuracy: 1.0\n",
            "Step 20537/22500 - Loss: 0.10365897417068481, Accuracy: 1.0\n",
            "Step 20538/22500 - Loss: 0.4619206190109253, Accuracy: 0.75\n",
            "Step 20539/22500 - Loss: 0.2993508279323578, Accuracy: 0.875\n",
            "Step 20540/22500 - Loss: 0.22416354715824127, Accuracy: 0.875\n",
            "Step 20541/22500 - Loss: 0.03672027215361595, Accuracy: 1.0\n",
            "Step 20542/22500 - Loss: 0.03686225041747093, Accuracy: 1.0\n",
            "Step 20543/22500 - Loss: 0.13894760608673096, Accuracy: 1.0\n",
            "Step 20544/22500 - Loss: 0.017300797626376152, Accuracy: 1.0\n",
            "Step 20545/22500 - Loss: 0.021819956600666046, Accuracy: 1.0\n",
            "Step 20546/22500 - Loss: 0.030597064644098282, Accuracy: 1.0\n",
            "Step 20547/22500 - Loss: 0.0860338807106018, Accuracy: 1.0\n",
            "Step 20548/22500 - Loss: 0.05199584737420082, Accuracy: 1.0\n",
            "Step 20549/22500 - Loss: 0.007699687033891678, Accuracy: 1.0\n",
            "Step 20550/22500 - Loss: 0.013404350727796555, Accuracy: 1.0\n",
            "Step 20551/22500 - Loss: 0.21468397974967957, Accuracy: 0.875\n",
            "Step 20552/22500 - Loss: 0.106128990650177, Accuracy: 0.875\n",
            "Step 20553/22500 - Loss: 0.3208436071872711, Accuracy: 0.875\n",
            "Step 20554/22500 - Loss: 0.023731635883450508, Accuracy: 1.0\n",
            "Step 20555/22500 - Loss: 0.06489264965057373, Accuracy: 1.0\n",
            "Step 20556/22500 - Loss: 0.07631085067987442, Accuracy: 1.0\n",
            "Step 20557/22500 - Loss: 0.2149016410112381, Accuracy: 0.875\n",
            "Step 20558/22500 - Loss: 0.039506565779447556, Accuracy: 1.0\n",
            "Step 20559/22500 - Loss: 0.1810038983821869, Accuracy: 0.875\n",
            "Step 20560/22500 - Loss: 0.024913465604186058, Accuracy: 1.0\n",
            "Step 20561/22500 - Loss: 0.07252512872219086, Accuracy: 1.0\n",
            "Step 20562/22500 - Loss: 0.05400247126817703, Accuracy: 1.0\n",
            "Step 20563/22500 - Loss: 0.17172347009181976, Accuracy: 1.0\n",
            "Step 20564/22500 - Loss: 0.017591573297977448, Accuracy: 1.0\n",
            "Step 20565/22500 - Loss: 0.00844685360789299, Accuracy: 1.0\n",
            "Step 20566/22500 - Loss: 0.45150479674339294, Accuracy: 0.875\n",
            "Step 20567/22500 - Loss: 0.3179362118244171, Accuracy: 0.75\n",
            "Step 20568/22500 - Loss: 0.06034674495458603, Accuracy: 1.0\n",
            "Step 20569/22500 - Loss: 0.216557115316391, Accuracy: 0.875\n",
            "Step 20570/22500 - Loss: 0.02669578045606613, Accuracy: 1.0\n",
            "Step 20571/22500 - Loss: 0.064811110496521, Accuracy: 1.0\n",
            "Step 20572/22500 - Loss: 0.013479876331984997, Accuracy: 1.0\n",
            "Step 20573/22500 - Loss: 0.0456879623234272, Accuracy: 1.0\n",
            "Step 20574/22500 - Loss: 0.22034092247486115, Accuracy: 0.875\n",
            "Step 20575/22500 - Loss: 0.1003522053360939, Accuracy: 1.0\n",
            "Step 20576/22500 - Loss: 0.09157892316579819, Accuracy: 1.0\n",
            "Step 20577/22500 - Loss: 0.0038307560607790947, Accuracy: 1.0\n",
            "Step 20578/22500 - Loss: 0.06442946940660477, Accuracy: 1.0\n",
            "Step 20579/22500 - Loss: 0.036960650235414505, Accuracy: 1.0\n",
            "Step 20580/22500 - Loss: 0.5194172263145447, Accuracy: 0.875\n",
            "Step 20581/22500 - Loss: 0.11241267621517181, Accuracy: 1.0\n",
            "Step 20582/22500 - Loss: 0.030779432505369186, Accuracy: 1.0\n",
            "Step 20583/22500 - Loss: 0.004122747574001551, Accuracy: 1.0\n",
            "Step 20584/22500 - Loss: 0.02039398066699505, Accuracy: 1.0\n",
            "Step 20585/22500 - Loss: 0.14415012300014496, Accuracy: 0.875\n",
            "Step 20586/22500 - Loss: 0.24397152662277222, Accuracy: 0.875\n",
            "Step 20587/22500 - Loss: 0.012785825878381729, Accuracy: 1.0\n",
            "Step 20588/22500 - Loss: 0.045665837824344635, Accuracy: 1.0\n",
            "Step 20589/22500 - Loss: 0.026986347511410713, Accuracy: 1.0\n",
            "Step 20590/22500 - Loss: 0.355151891708374, Accuracy: 0.875\n",
            "Step 20591/22500 - Loss: 0.009725633077323437, Accuracy: 1.0\n",
            "Step 20592/22500 - Loss: 0.2140798717737198, Accuracy: 0.875\n",
            "Step 20593/22500 - Loss: 0.24675443768501282, Accuracy: 0.875\n",
            "Step 20594/22500 - Loss: 0.47977176308631897, Accuracy: 0.875\n",
            "Step 20595/22500 - Loss: 0.024302566424012184, Accuracy: 1.0\n",
            "Step 20596/22500 - Loss: 0.009655412286520004, Accuracy: 1.0\n",
            "Step 20597/22500 - Loss: 0.022481687366962433, Accuracy: 1.0\n",
            "Step 20598/22500 - Loss: 0.08906868100166321, Accuracy: 1.0\n",
            "Step 20599/22500 - Loss: 0.07782713323831558, Accuracy: 1.0\n",
            "Step 20600/22500 - Loss: 0.037763360887765884, Accuracy: 1.0\n",
            "Step 20601/22500 - Loss: 0.042966488748788834, Accuracy: 1.0\n",
            "Step 20602/22500 - Loss: 0.37920495867729187, Accuracy: 0.875\n",
            "Step 20603/22500 - Loss: 0.018381314352154732, Accuracy: 1.0\n",
            "Step 20604/22500 - Loss: 0.021692078560590744, Accuracy: 1.0\n",
            "Step 20605/22500 - Loss: 0.30977699160575867, Accuracy: 0.875\n",
            "Step 20606/22500 - Loss: 0.014944757334887981, Accuracy: 1.0\n",
            "Step 20607/22500 - Loss: 0.03235429897904396, Accuracy: 1.0\n",
            "Step 20608/22500 - Loss: 0.13300758600234985, Accuracy: 0.875\n",
            "Step 20609/22500 - Loss: 0.08963149040937424, Accuracy: 1.0\n",
            "Step 20610/22500 - Loss: 0.03251028060913086, Accuracy: 1.0\n",
            "Step 20611/22500 - Loss: 0.11062050610780716, Accuracy: 1.0\n",
            "Step 20612/22500 - Loss: 0.07601810246706009, Accuracy: 1.0\n",
            "Step 20613/22500 - Loss: 0.25687986612319946, Accuracy: 0.875\n",
            "Step 20614/22500 - Loss: 0.00879399012774229, Accuracy: 1.0\n",
            "Step 20615/22500 - Loss: 0.014979190193116665, Accuracy: 1.0\n",
            "Step 20616/22500 - Loss: 0.1949034184217453, Accuracy: 0.875\n",
            "Step 20617/22500 - Loss: 0.06992299854755402, Accuracy: 1.0\n",
            "Step 20618/22500 - Loss: 0.19285321235656738, Accuracy: 0.875\n",
            "Step 20619/22500 - Loss: 0.017539426684379578, Accuracy: 1.0\n",
            "Step 20620/22500 - Loss: 0.09756200760602951, Accuracy: 1.0\n",
            "Step 20621/22500 - Loss: 0.08777077496051788, Accuracy: 1.0\n",
            "Step 20622/22500 - Loss: 0.1114480048418045, Accuracy: 0.875\n",
            "Step 20623/22500 - Loss: 0.008243308402597904, Accuracy: 1.0\n",
            "Step 20624/22500 - Loss: 0.008129637688398361, Accuracy: 1.0\n",
            "Step 20625/22500 - Loss: 0.8526042699813843, Accuracy: 0.75\n",
            "Step 20626/22500 - Loss: 0.12259719520807266, Accuracy: 1.0\n",
            "Step 20627/22500 - Loss: 0.4331667125225067, Accuracy: 0.875\n",
            "Step 20628/22500 - Loss: 0.17132477462291718, Accuracy: 0.875\n",
            "Step 20629/22500 - Loss: 0.03351419046521187, Accuracy: 1.0\n",
            "Step 20630/22500 - Loss: 0.053069788962602615, Accuracy: 1.0\n",
            "Step 20631/22500 - Loss: 0.02523471787571907, Accuracy: 1.0\n",
            "Step 20632/22500 - Loss: 0.08956950902938843, Accuracy: 1.0\n",
            "Step 20633/22500 - Loss: 0.29180315136909485, Accuracy: 0.75\n",
            "Step 20634/22500 - Loss: 0.5650407075881958, Accuracy: 0.75\n",
            "Step 20635/22500 - Loss: 0.013625332154333591, Accuracy: 1.0\n",
            "Step 20636/22500 - Loss: 0.2302333265542984, Accuracy: 0.875\n",
            "Step 20637/22500 - Loss: 0.03386135771870613, Accuracy: 1.0\n",
            "Step 20638/22500 - Loss: 0.02929786406457424, Accuracy: 1.0\n",
            "Step 20639/22500 - Loss: 0.05524641275405884, Accuracy: 1.0\n",
            "Step 20640/22500 - Loss: 0.0457104854285717, Accuracy: 1.0\n",
            "Step 20641/22500 - Loss: 0.3168293535709381, Accuracy: 0.875\n",
            "Step 20642/22500 - Loss: 0.10881362855434418, Accuracy: 1.0\n",
            "Step 20643/22500 - Loss: 0.12900443375110626, Accuracy: 0.875\n",
            "Step 20644/22500 - Loss: 0.020722266286611557, Accuracy: 1.0\n",
            "Step 20645/22500 - Loss: 0.014298110269010067, Accuracy: 1.0\n",
            "Step 20646/22500 - Loss: 0.2979171574115753, Accuracy: 0.875\n",
            "Step 20647/22500 - Loss: 0.18184392154216766, Accuracy: 0.875\n",
            "Step 20648/22500 - Loss: 0.04436361789703369, Accuracy: 1.0\n",
            "Step 20649/22500 - Loss: 0.035216204822063446, Accuracy: 1.0\n",
            "Step 20650/22500 - Loss: 0.019618429243564606, Accuracy: 1.0\n",
            "Step 20651/22500 - Loss: 0.10648937523365021, Accuracy: 0.875\n",
            "Step 20652/22500 - Loss: 0.15207520127296448, Accuracy: 0.875\n",
            "Step 20653/22500 - Loss: 0.039737168699502945, Accuracy: 1.0\n",
            "Step 20654/22500 - Loss: 0.41906699538230896, Accuracy: 0.875\n",
            "Step 20655/22500 - Loss: 0.01809437945485115, Accuracy: 1.0\n",
            "Step 20656/22500 - Loss: 0.30185532569885254, Accuracy: 0.875\n",
            "Step 20657/22500 - Loss: 0.21206936240196228, Accuracy: 0.875\n",
            "Step 20658/22500 - Loss: 0.08223962783813477, Accuracy: 1.0\n",
            "Step 20659/22500 - Loss: 0.007906977087259293, Accuracy: 1.0\n",
            "Step 20660/22500 - Loss: 0.004847073927521706, Accuracy: 1.0\n",
            "Step 20661/22500 - Loss: 0.05161178112030029, Accuracy: 1.0\n",
            "Step 20662/22500 - Loss: 0.16554798185825348, Accuracy: 0.875\n",
            "Step 20663/22500 - Loss: 0.06310441344976425, Accuracy: 1.0\n",
            "Step 20664/22500 - Loss: 0.04519994929432869, Accuracy: 1.0\n",
            "Step 20665/22500 - Loss: 0.175348162651062, Accuracy: 0.875\n",
            "Step 20666/22500 - Loss: 0.09731095284223557, Accuracy: 1.0\n",
            "Step 20667/22500 - Loss: 0.1938815861940384, Accuracy: 0.875\n",
            "Step 20668/22500 - Loss: 0.4636055529117584, Accuracy: 0.875\n",
            "Step 20669/22500 - Loss: 0.08195795118808746, Accuracy: 1.0\n",
            "Step 20670/22500 - Loss: 0.08110961318016052, Accuracy: 1.0\n",
            "Step 20671/22500 - Loss: 0.03890369087457657, Accuracy: 1.0\n",
            "Step 20672/22500 - Loss: 0.004418156109750271, Accuracy: 1.0\n",
            "Step 20673/22500 - Loss: 0.1276402622461319, Accuracy: 0.875\n",
            "Step 20674/22500 - Loss: 0.09494524449110031, Accuracy: 1.0\n",
            "Step 20675/22500 - Loss: 0.1687103509902954, Accuracy: 0.875\n",
            "Step 20676/22500 - Loss: 0.08395994454622269, Accuracy: 1.0\n",
            "Step 20677/22500 - Loss: 0.08326876908540726, Accuracy: 1.0\n",
            "Step 20678/22500 - Loss: 0.09103935956954956, Accuracy: 1.0\n",
            "Step 20679/22500 - Loss: 0.5086119771003723, Accuracy: 0.75\n",
            "Step 20680/22500 - Loss: 0.15525969862937927, Accuracy: 0.875\n",
            "Step 20681/22500 - Loss: 0.13061903417110443, Accuracy: 1.0\n",
            "Step 20682/22500 - Loss: 0.5751325488090515, Accuracy: 0.75\n",
            "Step 20683/22500 - Loss: 0.12250079959630966, Accuracy: 1.0\n",
            "Step 20684/22500 - Loss: 0.01551570650190115, Accuracy: 1.0\n",
            "Step 20685/22500 - Loss: 0.01062927208840847, Accuracy: 1.0\n",
            "Step 20686/22500 - Loss: 0.10338448733091354, Accuracy: 0.875\n",
            "Step 20687/22500 - Loss: 0.04407353699207306, Accuracy: 1.0\n",
            "Step 20688/22500 - Loss: 0.11114382743835449, Accuracy: 1.0\n",
            "Step 20689/22500 - Loss: 0.03730582818388939, Accuracy: 1.0\n",
            "Step 20690/22500 - Loss: 0.08700050413608551, Accuracy: 1.0\n",
            "Step 20691/22500 - Loss: 0.1301119178533554, Accuracy: 1.0\n",
            "Step 20692/22500 - Loss: 0.007851192727684975, Accuracy: 1.0\n",
            "Step 20693/22500 - Loss: 0.142553448677063, Accuracy: 1.0\n",
            "Step 20694/22500 - Loss: 0.39081698656082153, Accuracy: 0.875\n",
            "Step 20695/22500 - Loss: 0.33168449997901917, Accuracy: 0.75\n",
            "Step 20696/22500 - Loss: 0.09749866276979446, Accuracy: 0.875\n",
            "Step 20697/22500 - Loss: 0.2861938774585724, Accuracy: 0.875\n",
            "Step 20698/22500 - Loss: 0.08440295606851578, Accuracy: 1.0\n",
            "Step 20699/22500 - Loss: 0.02015230804681778, Accuracy: 1.0\n",
            "Step 20700/22500 - Loss: 0.13301458954811096, Accuracy: 1.0\n",
            "Step 20701/22500 - Loss: 0.07257366180419922, Accuracy: 1.0\n",
            "Step 20702/22500 - Loss: 0.1912074238061905, Accuracy: 0.875\n",
            "Step 20703/22500 - Loss: 0.054354969412088394, Accuracy: 1.0\n",
            "Step 20704/22500 - Loss: 0.09986111521720886, Accuracy: 0.875\n",
            "Step 20705/22500 - Loss: 0.06796000897884369, Accuracy: 1.0\n",
            "Step 20706/22500 - Loss: 0.013102652505040169, Accuracy: 1.0\n",
            "Step 20707/22500 - Loss: 0.007340234704315662, Accuracy: 1.0\n",
            "Step 20708/22500 - Loss: 0.009694678708910942, Accuracy: 1.0\n",
            "Step 20709/22500 - Loss: 0.27817919850349426, Accuracy: 0.875\n",
            "Step 20710/22500 - Loss: 0.09154582023620605, Accuracy: 1.0\n",
            "Step 20711/22500 - Loss: 0.041211627423763275, Accuracy: 1.0\n",
            "Step 20712/22500 - Loss: 0.056022509932518005, Accuracy: 1.0\n",
            "Step 20713/22500 - Loss: 0.12380308657884598, Accuracy: 1.0\n",
            "Step 20714/22500 - Loss: 0.003960676956921816, Accuracy: 1.0\n",
            "Step 20715/22500 - Loss: 0.03325276076793671, Accuracy: 1.0\n",
            "Step 20716/22500 - Loss: 0.27816250920295715, Accuracy: 0.875\n",
            "Step 20717/22500 - Loss: 0.2700820565223694, Accuracy: 0.875\n",
            "Step 20718/22500 - Loss: 0.8955857753753662, Accuracy: 0.75\n",
            "Step 20719/22500 - Loss: 0.09726123511791229, Accuracy: 1.0\n",
            "Step 20720/22500 - Loss: 0.015841085463762283, Accuracy: 1.0\n",
            "Step 20721/22500 - Loss: 0.0459817610681057, Accuracy: 1.0\n",
            "Step 20722/22500 - Loss: 0.3392866253852844, Accuracy: 0.875\n",
            "Step 20723/22500 - Loss: 0.08564841747283936, Accuracy: 1.0\n",
            "Step 20724/22500 - Loss: 0.06707000732421875, Accuracy: 1.0\n",
            "Step 20725/22500 - Loss: 0.011471381410956383, Accuracy: 1.0\n",
            "Step 20726/22500 - Loss: 0.33566272258758545, Accuracy: 0.875\n",
            "Step 20727/22500 - Loss: 0.18923784792423248, Accuracy: 0.875\n",
            "Step 20728/22500 - Loss: 0.22349482774734497, Accuracy: 0.875\n",
            "Step 20729/22500 - Loss: 0.029987776651978493, Accuracy: 1.0\n",
            "Step 20730/22500 - Loss: 0.28708159923553467, Accuracy: 0.875\n",
            "Step 20731/22500 - Loss: 0.07284826040267944, Accuracy: 1.0\n",
            "Step 20732/22500 - Loss: 0.03519611805677414, Accuracy: 1.0\n",
            "Step 20733/22500 - Loss: 0.00943739153444767, Accuracy: 1.0\n",
            "Step 20734/22500 - Loss: 0.025259889662265778, Accuracy: 1.0\n",
            "Step 20735/22500 - Loss: 0.08590561151504517, Accuracy: 1.0\n",
            "Step 20736/22500 - Loss: 0.0987849161028862, Accuracy: 1.0\n",
            "Step 20737/22500 - Loss: 0.111338309943676, Accuracy: 1.0\n",
            "Step 20738/22500 - Loss: 0.003199913538992405, Accuracy: 1.0\n",
            "Step 20739/22500 - Loss: 0.131230890750885, Accuracy: 1.0\n",
            "Step 20740/22500 - Loss: 0.07339265942573547, Accuracy: 1.0\n",
            "Step 20741/22500 - Loss: 0.04106513410806656, Accuracy: 1.0\n",
            "Step 20742/22500 - Loss: 0.2932901382446289, Accuracy: 0.75\n",
            "Step 20743/22500 - Loss: 0.1132371798157692, Accuracy: 1.0\n",
            "Step 20744/22500 - Loss: 0.038470201194286346, Accuracy: 1.0\n",
            "Step 20745/22500 - Loss: 0.03133248910307884, Accuracy: 1.0\n",
            "Step 20746/22500 - Loss: 0.04550153389573097, Accuracy: 1.0\n",
            "Step 20747/22500 - Loss: 0.8486037850379944, Accuracy: 0.75\n",
            "Step 20748/22500 - Loss: 0.4782809913158417, Accuracy: 0.875\n",
            "Step 20749/22500 - Loss: 0.02971488982439041, Accuracy: 1.0\n",
            "Step 20750/22500 - Loss: 0.02925518900156021, Accuracy: 1.0\n",
            "Step 20751/22500 - Loss: 0.24118824303150177, Accuracy: 0.75\n",
            "Step 20752/22500 - Loss: 0.2375483363866806, Accuracy: 0.875\n",
            "Step 20753/22500 - Loss: 0.02295330911874771, Accuracy: 1.0\n",
            "Step 20754/22500 - Loss: 0.11322489380836487, Accuracy: 1.0\n",
            "Step 20755/22500 - Loss: 0.25505346059799194, Accuracy: 0.875\n",
            "Step 20756/22500 - Loss: 0.3315947651863098, Accuracy: 0.875\n",
            "Step 20757/22500 - Loss: 0.19772222638130188, Accuracy: 0.875\n",
            "Step 20758/22500 - Loss: 0.004542465787380934, Accuracy: 1.0\n",
            "Step 20759/22500 - Loss: 0.015309404581785202, Accuracy: 1.0\n",
            "Step 20760/22500 - Loss: 0.09145747870206833, Accuracy: 1.0\n",
            "Step 20761/22500 - Loss: 0.02911495417356491, Accuracy: 1.0\n",
            "Step 20762/22500 - Loss: 0.06733519583940506, Accuracy: 1.0\n",
            "Step 20763/22500 - Loss: 0.3519657254219055, Accuracy: 0.875\n",
            "Step 20764/22500 - Loss: 0.1440463364124298, Accuracy: 0.875\n",
            "Step 20765/22500 - Loss: 0.09226483106613159, Accuracy: 1.0\n",
            "Step 20766/22500 - Loss: 0.0572194866836071, Accuracy: 1.0\n",
            "Step 20767/22500 - Loss: 0.02775060385465622, Accuracy: 1.0\n",
            "Step 20768/22500 - Loss: 0.02023039199411869, Accuracy: 1.0\n",
            "Step 20769/22500 - Loss: 0.05558924749493599, Accuracy: 1.0\n",
            "Step 20770/22500 - Loss: 0.036471158266067505, Accuracy: 1.0\n",
            "Step 20771/22500 - Loss: 0.532735288143158, Accuracy: 0.75\n",
            "Step 20772/22500 - Loss: 0.006084193475544453, Accuracy: 1.0\n",
            "Step 20773/22500 - Loss: 0.02301749773323536, Accuracy: 1.0\n",
            "Step 20774/22500 - Loss: 0.018424246460199356, Accuracy: 1.0\n",
            "Step 20775/22500 - Loss: 0.04242613911628723, Accuracy: 1.0\n",
            "Step 20776/22500 - Loss: 0.00316068809479475, Accuracy: 1.0\n",
            "Step 20777/22500 - Loss: 0.0228525772690773, Accuracy: 1.0\n",
            "Step 20778/22500 - Loss: 0.028979022055864334, Accuracy: 1.0\n",
            "Step 20779/22500 - Loss: 0.016935309395194054, Accuracy: 1.0\n",
            "Step 20780/22500 - Loss: 0.0954664871096611, Accuracy: 1.0\n",
            "Step 20781/22500 - Loss: 0.053725071251392365, Accuracy: 1.0\n",
            "Step 20782/22500 - Loss: 0.07118720561265945, Accuracy: 1.0\n",
            "Step 20783/22500 - Loss: 0.22119146585464478, Accuracy: 0.875\n",
            "Step 20784/22500 - Loss: 0.015591337345540524, Accuracy: 1.0\n",
            "Step 20785/22500 - Loss: 0.09538666903972626, Accuracy: 1.0\n",
            "Step 20786/22500 - Loss: 0.010779937729239464, Accuracy: 1.0\n",
            "Step 20787/22500 - Loss: 0.04407022148370743, Accuracy: 1.0\n",
            "Step 20788/22500 - Loss: 0.6782535910606384, Accuracy: 0.875\n",
            "Step 20789/22500 - Loss: 0.25366735458374023, Accuracy: 0.875\n",
            "Step 20790/22500 - Loss: 0.09953822940587997, Accuracy: 1.0\n",
            "Step 20791/22500 - Loss: 0.5049322247505188, Accuracy: 0.75\n",
            "Step 20792/22500 - Loss: 0.3227294981479645, Accuracy: 0.875\n",
            "Step 20793/22500 - Loss: 0.07034514099359512, Accuracy: 1.0\n",
            "Step 20794/22500 - Loss: 0.5375228524208069, Accuracy: 0.875\n",
            "Step 20795/22500 - Loss: 0.1437191367149353, Accuracy: 0.875\n",
            "Step 20796/22500 - Loss: 0.41604384779930115, Accuracy: 0.75\n",
            "Step 20797/22500 - Loss: 0.03125563636422157, Accuracy: 1.0\n",
            "Step 20798/22500 - Loss: 0.010204077698290348, Accuracy: 1.0\n",
            "Step 20799/22500 - Loss: 0.008290594443678856, Accuracy: 1.0\n",
            "Step 20800/22500 - Loss: 0.10284892469644547, Accuracy: 0.875\n",
            "Step 20801/22500 - Loss: 0.05755939334630966, Accuracy: 1.0\n",
            "Step 20802/22500 - Loss: 0.08117041736841202, Accuracy: 1.0\n",
            "Step 20803/22500 - Loss: 0.008889762684702873, Accuracy: 1.0\n",
            "Step 20804/22500 - Loss: 0.12797363102436066, Accuracy: 1.0\n",
            "Step 20805/22500 - Loss: 0.3459321856498718, Accuracy: 0.875\n",
            "Step 20806/22500 - Loss: 0.5582167506217957, Accuracy: 0.75\n",
            "Step 20807/22500 - Loss: 0.1733495444059372, Accuracy: 0.875\n",
            "Step 20808/22500 - Loss: 0.006286123301833868, Accuracy: 1.0\n",
            "Step 20809/22500 - Loss: 0.09022209048271179, Accuracy: 1.0\n",
            "Step 20810/22500 - Loss: 0.0042193797416985035, Accuracy: 1.0\n",
            "Step 20811/22500 - Loss: 0.3891173005104065, Accuracy: 0.875\n",
            "Step 20812/22500 - Loss: 0.18732596933841705, Accuracy: 0.875\n",
            "Step 20813/22500 - Loss: 0.06501197069883347, Accuracy: 1.0\n",
            "Step 20814/22500 - Loss: 0.014031343162059784, Accuracy: 1.0\n",
            "Step 20815/22500 - Loss: 0.024347079917788506, Accuracy: 1.0\n",
            "Step 20816/22500 - Loss: 0.025925926864147186, Accuracy: 1.0\n",
            "Step 20817/22500 - Loss: 0.2985658645629883, Accuracy: 0.875\n",
            "Step 20818/22500 - Loss: 0.13986891508102417, Accuracy: 0.875\n",
            "Step 20819/22500 - Loss: 0.044706959277391434, Accuracy: 1.0\n",
            "Step 20820/22500 - Loss: 0.06097538024187088, Accuracy: 1.0\n",
            "Step 20821/22500 - Loss: 0.083000048995018, Accuracy: 1.0\n",
            "Step 20822/22500 - Loss: 0.06639797985553741, Accuracy: 1.0\n",
            "Step 20823/22500 - Loss: 0.3712209165096283, Accuracy: 0.75\n",
            "Step 20824/22500 - Loss: 0.023559583351016045, Accuracy: 1.0\n",
            "Step 20825/22500 - Loss: 0.20604506134986877, Accuracy: 0.875\n",
            "Step 20826/22500 - Loss: 0.27017536759376526, Accuracy: 0.875\n",
            "Step 20827/22500 - Loss: 0.047767072916030884, Accuracy: 1.0\n",
            "Step 20828/22500 - Loss: 0.021741356700658798, Accuracy: 1.0\n",
            "Step 20829/22500 - Loss: 0.15121135115623474, Accuracy: 0.875\n",
            "Step 20830/22500 - Loss: 0.002272930694743991, Accuracy: 1.0\n",
            "Step 20831/22500 - Loss: 0.22951799631118774, Accuracy: 0.875\n",
            "Step 20832/22500 - Loss: 0.06842371821403503, Accuracy: 1.0\n",
            "Step 20833/22500 - Loss: 0.15198054909706116, Accuracy: 0.875\n",
            "Step 20834/22500 - Loss: 0.4072410464286804, Accuracy: 0.75\n",
            "Step 20835/22500 - Loss: 0.04172462970018387, Accuracy: 1.0\n",
            "Step 20836/22500 - Loss: 0.03029795177280903, Accuracy: 1.0\n",
            "Step 20837/22500 - Loss: 0.06728778034448624, Accuracy: 1.0\n",
            "Step 20838/22500 - Loss: 0.22089119255542755, Accuracy: 0.875\n",
            "Step 20839/22500 - Loss: 0.5847510099411011, Accuracy: 0.75\n",
            "Step 20840/22500 - Loss: 0.011352104134857655, Accuracy: 1.0\n",
            "Step 20841/22500 - Loss: 0.45989713072776794, Accuracy: 0.75\n",
            "Step 20842/22500 - Loss: 0.02411184459924698, Accuracy: 1.0\n",
            "Step 20843/22500 - Loss: 0.002650634851306677, Accuracy: 1.0\n",
            "Step 20844/22500 - Loss: 0.11902394890785217, Accuracy: 0.875\n",
            "Step 20845/22500 - Loss: 0.005513234529644251, Accuracy: 1.0\n",
            "Step 20846/22500 - Loss: 0.10321269929409027, Accuracy: 1.0\n",
            "Step 20847/22500 - Loss: 0.07548601925373077, Accuracy: 1.0\n",
            "Step 20848/22500 - Loss: 0.18811500072479248, Accuracy: 0.875\n",
            "Step 20849/22500 - Loss: 0.26711028814315796, Accuracy: 0.875\n",
            "Step 20850/22500 - Loss: 0.03490489721298218, Accuracy: 1.0\n",
            "Step 20851/22500 - Loss: 0.0261999424546957, Accuracy: 1.0\n",
            "Step 20852/22500 - Loss: 0.16097822785377502, Accuracy: 1.0\n",
            "Step 20853/22500 - Loss: 0.33960261940956116, Accuracy: 0.875\n",
            "Step 20854/22500 - Loss: 0.36579933762550354, Accuracy: 0.75\n",
            "Step 20855/22500 - Loss: 0.05014538764953613, Accuracy: 1.0\n",
            "Step 20856/22500 - Loss: 0.03728599101305008, Accuracy: 1.0\n",
            "Step 20857/22500 - Loss: 0.11060469597578049, Accuracy: 1.0\n",
            "Step 20858/22500 - Loss: 0.38706669211387634, Accuracy: 0.875\n",
            "Step 20859/22500 - Loss: 0.08371998369693756, Accuracy: 1.0\n",
            "Step 20860/22500 - Loss: 0.05019785836338997, Accuracy: 1.0\n",
            "Step 20861/22500 - Loss: 0.23737221956253052, Accuracy: 0.875\n",
            "Step 20862/22500 - Loss: 0.09060549736022949, Accuracy: 1.0\n",
            "Step 20863/22500 - Loss: 0.7093797326087952, Accuracy: 0.875\n",
            "Step 20864/22500 - Loss: 0.03483043983578682, Accuracy: 1.0\n",
            "Step 20865/22500 - Loss: 0.006178257055580616, Accuracy: 1.0\n",
            "Step 20866/22500 - Loss: 0.01956561952829361, Accuracy: 1.0\n",
            "Step 20867/22500 - Loss: 0.01945163868367672, Accuracy: 1.0\n",
            "Step 20868/22500 - Loss: 0.004378051497042179, Accuracy: 1.0\n",
            "Step 20869/22500 - Loss: 0.005613244138658047, Accuracy: 1.0\n",
            "Step 20870/22500 - Loss: 0.2075556069612503, Accuracy: 0.875\n",
            "Step 20871/22500 - Loss: 0.014803443104028702, Accuracy: 1.0\n",
            "Step 20872/22500 - Loss: 0.019585618749260902, Accuracy: 1.0\n",
            "Step 20873/22500 - Loss: 0.016140855848789215, Accuracy: 1.0\n",
            "Step 20874/22500 - Loss: 0.04812905937433243, Accuracy: 1.0\n",
            "Step 20875/22500 - Loss: 0.30575963854789734, Accuracy: 0.875\n",
            "Step 20876/22500 - Loss: 0.6414900422096252, Accuracy: 0.75\n",
            "Step 20877/22500 - Loss: 0.029829569160938263, Accuracy: 1.0\n",
            "Step 20878/22500 - Loss: 0.01581658236682415, Accuracy: 1.0\n",
            "Step 20879/22500 - Loss: 0.008927150629460812, Accuracy: 1.0\n",
            "Step 20880/22500 - Loss: 0.14362962543964386, Accuracy: 0.875\n",
            "Step 20881/22500 - Loss: 0.2692820429801941, Accuracy: 0.875\n",
            "Step 20882/22500 - Loss: 0.030673813074827194, Accuracy: 1.0\n",
            "Step 20883/22500 - Loss: 0.12355538457632065, Accuracy: 1.0\n",
            "Step 20884/22500 - Loss: 0.054978903383016586, Accuracy: 1.0\n",
            "Step 20885/22500 - Loss: 0.08955828845500946, Accuracy: 1.0\n",
            "Step 20886/22500 - Loss: 0.0645005851984024, Accuracy: 1.0\n",
            "Step 20887/22500 - Loss: 0.2038881629705429, Accuracy: 0.875\n",
            "Step 20888/22500 - Loss: 0.06231072172522545, Accuracy: 1.0\n",
            "Step 20889/22500 - Loss: 0.04350414499640465, Accuracy: 1.0\n",
            "Step 20890/22500 - Loss: 0.11990279704332352, Accuracy: 1.0\n",
            "Step 20891/22500 - Loss: 0.06348031759262085, Accuracy: 1.0\n",
            "Step 20892/22500 - Loss: 0.10331090539693832, Accuracy: 1.0\n",
            "Step 20893/22500 - Loss: 0.6004056334495544, Accuracy: 0.625\n",
            "Step 20894/22500 - Loss: 0.1259307712316513, Accuracy: 1.0\n",
            "Step 20895/22500 - Loss: 0.04236616566777229, Accuracy: 1.0\n",
            "Step 20896/22500 - Loss: 0.058866195380687714, Accuracy: 1.0\n",
            "Step 20897/22500 - Loss: 0.005538615398108959, Accuracy: 1.0\n",
            "Step 20898/22500 - Loss: 0.3448037803173065, Accuracy: 0.875\n",
            "Step 20899/22500 - Loss: 0.03470608592033386, Accuracy: 1.0\n",
            "Step 20900/22500 - Loss: 0.2503149211406708, Accuracy: 0.875\n",
            "Step 20901/22500 - Loss: 0.07196641713380814, Accuracy: 1.0\n",
            "Step 20902/22500 - Loss: 0.3193676769733429, Accuracy: 0.75\n",
            "Step 20903/22500 - Loss: 0.060691192746162415, Accuracy: 1.0\n",
            "Step 20904/22500 - Loss: 0.027035806328058243, Accuracy: 1.0\n",
            "Step 20905/22500 - Loss: 0.12446975708007812, Accuracy: 0.875\n",
            "Step 20906/22500 - Loss: 0.0678253322839737, Accuracy: 1.0\n",
            "Step 20907/22500 - Loss: 0.37006813287734985, Accuracy: 0.875\n",
            "Step 20908/22500 - Loss: 0.03603673353791237, Accuracy: 1.0\n",
            "Step 20909/22500 - Loss: 0.0708090215921402, Accuracy: 1.0\n",
            "Step 20910/22500 - Loss: 0.03481264412403107, Accuracy: 1.0\n",
            "Step 20911/22500 - Loss: 0.011217179708182812, Accuracy: 1.0\n",
            "Step 20912/22500 - Loss: 0.08527737855911255, Accuracy: 1.0\n",
            "Step 20913/22500 - Loss: 0.03076544962823391, Accuracy: 1.0\n",
            "Step 20914/22500 - Loss: 0.03758884221315384, Accuracy: 1.0\n",
            "Step 20915/22500 - Loss: 0.02788710407912731, Accuracy: 1.0\n",
            "Step 20916/22500 - Loss: 0.0312043484300375, Accuracy: 1.0\n",
            "Step 20917/22500 - Loss: 0.02939048781991005, Accuracy: 1.0\n",
            "Step 20918/22500 - Loss: 0.3591253459453583, Accuracy: 0.875\n",
            "Step 20919/22500 - Loss: 0.12853865325450897, Accuracy: 0.875\n",
            "Step 20920/22500 - Loss: 0.055797092616558075, Accuracy: 1.0\n",
            "Step 20921/22500 - Loss: 0.23034049570560455, Accuracy: 0.875\n",
            "Step 20922/22500 - Loss: 0.25111591815948486, Accuracy: 0.875\n",
            "Step 20923/22500 - Loss: 0.00797615572810173, Accuracy: 1.0\n",
            "Step 20924/22500 - Loss: 0.18745194375514984, Accuracy: 0.875\n",
            "Step 20925/22500 - Loss: 0.01358387153595686, Accuracy: 1.0\n",
            "Step 20926/22500 - Loss: 0.0544501356780529, Accuracy: 1.0\n",
            "Step 20927/22500 - Loss: 0.06768064200878143, Accuracy: 1.0\n",
            "Step 20928/22500 - Loss: 0.489210844039917, Accuracy: 0.875\n",
            "Step 20929/22500 - Loss: 0.04410184547305107, Accuracy: 1.0\n",
            "Step 20930/22500 - Loss: 0.12489186227321625, Accuracy: 0.875\n",
            "Step 20931/22500 - Loss: 0.028396999463438988, Accuracy: 1.0\n",
            "Step 20932/22500 - Loss: 0.3714868128299713, Accuracy: 0.875\n",
            "Step 20933/22500 - Loss: 0.34411343932151794, Accuracy: 0.875\n",
            "Step 20934/22500 - Loss: 0.6681168079376221, Accuracy: 0.75\n",
            "Step 20935/22500 - Loss: 0.0443539097905159, Accuracy: 1.0\n",
            "Step 20936/22500 - Loss: 0.3520655930042267, Accuracy: 0.875\n",
            "Step 20937/22500 - Loss: 0.13757801055908203, Accuracy: 0.875\n",
            "Step 20938/22500 - Loss: 0.16776899993419647, Accuracy: 0.875\n",
            "Step 20939/22500 - Loss: 0.03333944082260132, Accuracy: 1.0\n",
            "Step 20940/22500 - Loss: 0.04118812084197998, Accuracy: 1.0\n",
            "Step 20941/22500 - Loss: 0.03104424476623535, Accuracy: 1.0\n",
            "Step 20942/22500 - Loss: 0.6255220174789429, Accuracy: 0.875\n",
            "Step 20943/22500 - Loss: 0.052869465202093124, Accuracy: 1.0\n",
            "Step 20944/22500 - Loss: 0.4735364019870758, Accuracy: 0.625\n",
            "Step 20945/22500 - Loss: 0.01036473736166954, Accuracy: 1.0\n",
            "Step 20946/22500 - Loss: 0.0672604963183403, Accuracy: 1.0\n",
            "Step 20947/22500 - Loss: 0.05846526473760605, Accuracy: 1.0\n",
            "Step 20948/22500 - Loss: 0.023463193327188492, Accuracy: 1.0\n",
            "Step 20949/22500 - Loss: 0.036596138030290604, Accuracy: 1.0\n",
            "Step 20950/22500 - Loss: 0.1388518065214157, Accuracy: 0.875\n",
            "Step 20951/22500 - Loss: 0.008276798762381077, Accuracy: 1.0\n",
            "Step 20952/22500 - Loss: 0.05566662177443504, Accuracy: 1.0\n",
            "Step 20953/22500 - Loss: 0.04163840785622597, Accuracy: 1.0\n",
            "Step 20954/22500 - Loss: 0.020106375217437744, Accuracy: 1.0\n",
            "Step 20955/22500 - Loss: 0.032844074070453644, Accuracy: 1.0\n",
            "Step 20956/22500 - Loss: 0.05876312032341957, Accuracy: 1.0\n",
            "Step 20957/22500 - Loss: 0.13590826094150543, Accuracy: 1.0\n",
            "Step 20958/22500 - Loss: 0.056360919028520584, Accuracy: 1.0\n",
            "Step 20959/22500 - Loss: 0.04794776439666748, Accuracy: 1.0\n",
            "Step 20960/22500 - Loss: 0.1661900281906128, Accuracy: 0.875\n",
            "Step 20961/22500 - Loss: 0.09222821891307831, Accuracy: 1.0\n",
            "Step 20962/22500 - Loss: 0.06447701901197433, Accuracy: 1.0\n",
            "Step 20963/22500 - Loss: 0.01873387023806572, Accuracy: 1.0\n",
            "Step 20964/22500 - Loss: 0.5238550901412964, Accuracy: 0.875\n",
            "Step 20965/22500 - Loss: 0.24344190955162048, Accuracy: 0.875\n",
            "Step 20966/22500 - Loss: 0.04406866803765297, Accuracy: 1.0\n",
            "Step 20967/22500 - Loss: 0.01906515471637249, Accuracy: 1.0\n",
            "Step 20968/22500 - Loss: 0.7071307897567749, Accuracy: 0.625\n",
            "Step 20969/22500 - Loss: 0.014338341541588306, Accuracy: 1.0\n",
            "Step 20970/22500 - Loss: 0.1853380799293518, Accuracy: 0.875\n",
            "Step 20971/22500 - Loss: 0.003950463607907295, Accuracy: 1.0\n",
            "Step 20972/22500 - Loss: 0.050546932965517044, Accuracy: 1.0\n",
            "Step 20973/22500 - Loss: 0.13421893119812012, Accuracy: 0.875\n",
            "Step 20974/22500 - Loss: 0.05411205068230629, Accuracy: 1.0\n",
            "Step 20975/22500 - Loss: 0.019075296819210052, Accuracy: 1.0\n",
            "Step 20976/22500 - Loss: 0.22921690344810486, Accuracy: 0.875\n",
            "Step 20977/22500 - Loss: 0.01863778755068779, Accuracy: 1.0\n",
            "Step 20978/22500 - Loss: 0.030836092308163643, Accuracy: 1.0\n",
            "Step 20979/22500 - Loss: 0.17490532994270325, Accuracy: 0.875\n",
            "Step 20980/22500 - Loss: 0.019940726459026337, Accuracy: 1.0\n",
            "Step 20981/22500 - Loss: 0.020242420956492424, Accuracy: 1.0\n",
            "Step 20982/22500 - Loss: 0.13042224943637848, Accuracy: 1.0\n",
            "Step 20983/22500 - Loss: 0.010332087054848671, Accuracy: 1.0\n",
            "Step 20984/22500 - Loss: 0.11523758620023727, Accuracy: 1.0\n",
            "Step 20985/22500 - Loss: 0.0965694710612297, Accuracy: 1.0\n",
            "Step 20986/22500 - Loss: 0.029355714097619057, Accuracy: 1.0\n",
            "Step 20987/22500 - Loss: 0.09761811792850494, Accuracy: 1.0\n",
            "Step 20988/22500 - Loss: 0.056831568479537964, Accuracy: 1.0\n",
            "Step 20989/22500 - Loss: 0.026147041469812393, Accuracy: 1.0\n",
            "Step 20990/22500 - Loss: 0.0410541296005249, Accuracy: 1.0\n",
            "Step 20991/22500 - Loss: 0.19233308732509613, Accuracy: 0.875\n",
            "Step 20992/22500 - Loss: 0.5357323884963989, Accuracy: 0.875\n",
            "Step 20993/22500 - Loss: 0.01573890447616577, Accuracy: 1.0\n",
            "Step 20994/22500 - Loss: 0.08137595653533936, Accuracy: 1.0\n",
            "Step 20995/22500 - Loss: 0.1910334676504135, Accuracy: 0.875\n",
            "Step 20996/22500 - Loss: 0.01135803759098053, Accuracy: 1.0\n",
            "Step 20997/22500 - Loss: 0.071891650557518, Accuracy: 1.0\n",
            "Step 20998/22500 - Loss: 0.028329556807875633, Accuracy: 1.0\n",
            "Step 20999/22500 - Loss: 0.022708136588335037, Accuracy: 1.0\n",
            "Step 21000/22500 - Loss: 0.050341732800006866, Accuracy: 1.0\n",
            "Step 21001/22500 - Loss: 0.0017559512052685022, Accuracy: 1.0\n",
            "Step 21002/22500 - Loss: 0.018328821286559105, Accuracy: 1.0\n",
            "Step 21003/22500 - Loss: 0.3715086877346039, Accuracy: 0.875\n",
            "Step 21004/22500 - Loss: 0.29262620210647583, Accuracy: 0.875\n",
            "Step 21005/22500 - Loss: 0.6326128244400024, Accuracy: 0.75\n",
            "Step 21006/22500 - Loss: 0.017343442887067795, Accuracy: 1.0\n",
            "Step 21007/22500 - Loss: 0.007641575299203396, Accuracy: 1.0\n",
            "Step 21008/22500 - Loss: 0.1077052652835846, Accuracy: 1.0\n",
            "Step 21009/22500 - Loss: 0.05665304884314537, Accuracy: 1.0\n",
            "Step 21010/22500 - Loss: 0.12769271433353424, Accuracy: 1.0\n",
            "Step 21011/22500 - Loss: 0.03731055185198784, Accuracy: 1.0\n",
            "Step 21012/22500 - Loss: 0.08448290079832077, Accuracy: 1.0\n",
            "Step 21013/22500 - Loss: 0.0311039499938488, Accuracy: 1.0\n",
            "Step 21014/22500 - Loss: 0.015783201903104782, Accuracy: 1.0\n",
            "Step 21015/22500 - Loss: 0.03688995912671089, Accuracy: 1.0\n",
            "Step 21016/22500 - Loss: 0.12623202800750732, Accuracy: 0.875\n",
            "Step 21017/22500 - Loss: 0.04590779170393944, Accuracy: 1.0\n",
            "Step 21018/22500 - Loss: 0.025464709848165512, Accuracy: 1.0\n",
            "Step 21019/22500 - Loss: 0.16815528273582458, Accuracy: 0.875\n",
            "Step 21020/22500 - Loss: 0.04726722463965416, Accuracy: 1.0\n",
            "Step 21021/22500 - Loss: 0.015241364017128944, Accuracy: 1.0\n",
            "Step 21022/22500 - Loss: 0.15769055485725403, Accuracy: 1.0\n",
            "Step 21023/22500 - Loss: 0.033904142677783966, Accuracy: 1.0\n",
            "Step 21024/22500 - Loss: 0.12966564297676086, Accuracy: 0.875\n",
            "Step 21025/22500 - Loss: 0.07909661531448364, Accuracy: 1.0\n",
            "Step 21026/22500 - Loss: 0.09068392217159271, Accuracy: 0.875\n",
            "Step 21027/22500 - Loss: 0.04443874582648277, Accuracy: 1.0\n",
            "Step 21028/22500 - Loss: 0.0029715155251324177, Accuracy: 1.0\n",
            "Step 21029/22500 - Loss: 0.08497226238250732, Accuracy: 1.0\n",
            "Step 21030/22500 - Loss: 0.1776830106973648, Accuracy: 0.875\n",
            "Step 21031/22500 - Loss: 0.4130890667438507, Accuracy: 0.875\n",
            "Step 21032/22500 - Loss: 0.09071923047304153, Accuracy: 1.0\n",
            "Step 21033/22500 - Loss: 0.12743553519248962, Accuracy: 0.875\n",
            "Step 21034/22500 - Loss: 0.02800842374563217, Accuracy: 1.0\n",
            "Step 21035/22500 - Loss: 0.19056005775928497, Accuracy: 0.875\n",
            "Step 21036/22500 - Loss: 0.3216700851917267, Accuracy: 0.875\n",
            "Step 21037/22500 - Loss: 0.029492061585187912, Accuracy: 1.0\n",
            "Step 21038/22500 - Loss: 0.01367124356329441, Accuracy: 1.0\n",
            "Step 21039/22500 - Loss: 0.3170631229877472, Accuracy: 0.875\n",
            "Step 21040/22500 - Loss: 0.05848326534032822, Accuracy: 1.0\n",
            "Step 21041/22500 - Loss: 0.27445968985557556, Accuracy: 0.875\n",
            "Step 21042/22500 - Loss: 0.18110638856887817, Accuracy: 0.875\n",
            "Step 21043/22500 - Loss: 0.12092062830924988, Accuracy: 1.0\n",
            "Step 21044/22500 - Loss: 0.026591798290610313, Accuracy: 1.0\n",
            "Step 21045/22500 - Loss: 0.012123391032218933, Accuracy: 1.0\n",
            "Step 21046/22500 - Loss: 0.07960708439350128, Accuracy: 1.0\n",
            "Step 21047/22500 - Loss: 0.28475672006607056, Accuracy: 0.875\n",
            "Step 21048/22500 - Loss: 0.5092974901199341, Accuracy: 0.875\n",
            "Step 21049/22500 - Loss: 0.3272024989128113, Accuracy: 0.875\n",
            "Step 21050/22500 - Loss: 0.018756451085209846, Accuracy: 1.0\n",
            "Step 21051/22500 - Loss: 0.008739077486097813, Accuracy: 1.0\n",
            "Step 21052/22500 - Loss: 0.1412789523601532, Accuracy: 1.0\n",
            "Step 21053/22500 - Loss: 0.05226420983672142, Accuracy: 1.0\n",
            "Step 21054/22500 - Loss: 0.009526273235678673, Accuracy: 1.0\n",
            "Step 21055/22500 - Loss: 0.01668066717684269, Accuracy: 1.0\n",
            "Step 21056/22500 - Loss: 0.006280938629060984, Accuracy: 1.0\n",
            "Step 21057/22500 - Loss: 0.10142384469509125, Accuracy: 0.875\n",
            "Step 21058/22500 - Loss: 0.03150726109743118, Accuracy: 1.0\n",
            "Step 21059/22500 - Loss: 0.046408720314502716, Accuracy: 1.0\n",
            "Step 21060/22500 - Loss: 0.0055748834274709225, Accuracy: 1.0\n",
            "Step 21061/22500 - Loss: 0.15168926119804382, Accuracy: 1.0\n",
            "Step 21062/22500 - Loss: 0.2669471204280853, Accuracy: 0.875\n",
            "Step 21063/22500 - Loss: 0.0149852205067873, Accuracy: 1.0\n",
            "Step 21064/22500 - Loss: 0.05250834673643112, Accuracy: 1.0\n",
            "Step 21065/22500 - Loss: 0.025113636627793312, Accuracy: 1.0\n",
            "Step 21066/22500 - Loss: 0.0224507637321949, Accuracy: 1.0\n",
            "Step 21067/22500 - Loss: 0.01941615343093872, Accuracy: 1.0\n",
            "Step 21068/22500 - Loss: 0.022593356668949127, Accuracy: 1.0\n",
            "Step 21069/22500 - Loss: 0.022448722273111343, Accuracy: 1.0\n",
            "Step 21070/22500 - Loss: 0.047304484993219376, Accuracy: 1.0\n",
            "Step 21071/22500 - Loss: 0.04469699040055275, Accuracy: 1.0\n",
            "Step 21072/22500 - Loss: 0.0025504841469228268, Accuracy: 1.0\n",
            "Step 21073/22500 - Loss: 0.15343934297561646, Accuracy: 0.875\n",
            "Step 21074/22500 - Loss: 0.008748956955969334, Accuracy: 1.0\n",
            "Step 21075/22500 - Loss: 0.3006734549999237, Accuracy: 0.875\n",
            "Step 21076/22500 - Loss: 0.003617533715441823, Accuracy: 1.0\n",
            "Step 21077/22500 - Loss: 0.12160855531692505, Accuracy: 1.0\n",
            "Step 21078/22500 - Loss: 0.5707988142967224, Accuracy: 0.75\n",
            "Step 21079/22500 - Loss: 0.04100674390792847, Accuracy: 1.0\n",
            "Step 21080/22500 - Loss: 0.09577128291130066, Accuracy: 1.0\n",
            "Step 21081/22500 - Loss: 0.03115466795861721, Accuracy: 1.0\n",
            "Step 21082/22500 - Loss: 0.01025941502302885, Accuracy: 1.0\n",
            "Step 21083/22500 - Loss: 0.5456641912460327, Accuracy: 0.875\n",
            "Step 21084/22500 - Loss: 0.0041209738701581955, Accuracy: 1.0\n",
            "Step 21085/22500 - Loss: 0.023865103721618652, Accuracy: 1.0\n",
            "Step 21086/22500 - Loss: 0.08926887065172195, Accuracy: 1.0\n",
            "Step 21087/22500 - Loss: 0.16113168001174927, Accuracy: 0.875\n",
            "Step 21088/22500 - Loss: 0.028664877638220787, Accuracy: 1.0\n",
            "Step 21089/22500 - Loss: 0.2442786991596222, Accuracy: 0.875\n",
            "Step 21090/22500 - Loss: 0.06117013841867447, Accuracy: 1.0\n",
            "Step 21091/22500 - Loss: 0.039504557847976685, Accuracy: 1.0\n",
            "Step 21092/22500 - Loss: 0.0475851409137249, Accuracy: 1.0\n",
            "Step 21093/22500 - Loss: 0.36824995279312134, Accuracy: 0.875\n",
            "Step 21094/22500 - Loss: 0.32140153646469116, Accuracy: 0.875\n",
            "Step 21095/22500 - Loss: 0.16416482627391815, Accuracy: 1.0\n",
            "Step 21096/22500 - Loss: 0.13180992007255554, Accuracy: 0.875\n",
            "Step 21097/22500 - Loss: 0.06121860072016716, Accuracy: 1.0\n",
            "Step 21098/22500 - Loss: 0.05920480564236641, Accuracy: 1.0\n",
            "Step 21099/22500 - Loss: 0.009215264581143856, Accuracy: 1.0\n",
            "Step 21100/22500 - Loss: 0.3365649878978729, Accuracy: 0.875\n",
            "Step 21101/22500 - Loss: 0.027502896264195442, Accuracy: 1.0\n",
            "Step 21102/22500 - Loss: 0.029843105003237724, Accuracy: 1.0\n",
            "Step 21103/22500 - Loss: 0.153621643781662, Accuracy: 0.875\n",
            "Step 21104/22500 - Loss: 0.14746323227882385, Accuracy: 1.0\n",
            "Step 21105/22500 - Loss: 0.0686037614941597, Accuracy: 1.0\n",
            "Step 21106/22500 - Loss: 0.20895297825336456, Accuracy: 0.875\n",
            "Step 21107/22500 - Loss: 0.16983094811439514, Accuracy: 0.875\n",
            "Step 21108/22500 - Loss: 0.2889317572116852, Accuracy: 0.875\n",
            "Step 21109/22500 - Loss: 0.019330373033881187, Accuracy: 1.0\n",
            "Step 21110/22500 - Loss: 0.2565978467464447, Accuracy: 0.875\n",
            "Step 21111/22500 - Loss: 0.14031729102134705, Accuracy: 0.875\n",
            "Step 21112/22500 - Loss: 0.07000986486673355, Accuracy: 1.0\n",
            "Step 21113/22500 - Loss: 0.15607644617557526, Accuracy: 0.875\n",
            "Step 21114/22500 - Loss: 0.059509050101041794, Accuracy: 1.0\n",
            "Step 21115/22500 - Loss: 0.03976287692785263, Accuracy: 1.0\n",
            "Step 21116/22500 - Loss: 0.0130863506346941, Accuracy: 1.0\n",
            "Step 21117/22500 - Loss: 0.24653169512748718, Accuracy: 0.875\n",
            "Step 21118/22500 - Loss: 0.046547066420316696, Accuracy: 1.0\n",
            "Step 21119/22500 - Loss: 0.04626024141907692, Accuracy: 1.0\n",
            "Step 21120/22500 - Loss: 0.04937282204627991, Accuracy: 1.0\n",
            "Step 21121/22500 - Loss: 0.021043814718723297, Accuracy: 1.0\n",
            "Step 21122/22500 - Loss: 0.10195349156856537, Accuracy: 0.875\n",
            "Step 21123/22500 - Loss: 0.04797505959868431, Accuracy: 1.0\n",
            "Step 21124/22500 - Loss: 0.1297004073858261, Accuracy: 0.875\n",
            "Step 21125/22500 - Loss: 0.30265185236930847, Accuracy: 0.875\n",
            "Step 21126/22500 - Loss: 0.011524545028805733, Accuracy: 1.0\n",
            "Step 21127/22500 - Loss: 0.10491348057985306, Accuracy: 1.0\n",
            "Step 21128/22500 - Loss: 0.02391696535050869, Accuracy: 1.0\n",
            "Step 21129/22500 - Loss: 0.10268579423427582, Accuracy: 1.0\n",
            "Step 21130/22500 - Loss: 0.01716776192188263, Accuracy: 1.0\n",
            "Step 21131/22500 - Loss: 0.00858987309038639, Accuracy: 1.0\n",
            "Step 21132/22500 - Loss: 0.01497727818787098, Accuracy: 1.0\n",
            "Step 21133/22500 - Loss: 0.11423256993293762, Accuracy: 0.875\n",
            "Step 21134/22500 - Loss: 0.025359859690070152, Accuracy: 1.0\n",
            "Step 21135/22500 - Loss: 0.01463608630001545, Accuracy: 1.0\n",
            "Step 21136/22500 - Loss: 0.0018581331241875887, Accuracy: 1.0\n",
            "Step 21137/22500 - Loss: 0.03747593238949776, Accuracy: 1.0\n",
            "Step 21138/22500 - Loss: 0.2533281445503235, Accuracy: 0.875\n",
            "Step 21139/22500 - Loss: 0.011980445124208927, Accuracy: 1.0\n",
            "Step 21140/22500 - Loss: 0.10231926292181015, Accuracy: 1.0\n",
            "Step 21141/22500 - Loss: 0.0020671032834798098, Accuracy: 1.0\n",
            "Step 21142/22500 - Loss: 0.19734619557857513, Accuracy: 0.875\n",
            "Step 21143/22500 - Loss: 0.0721796378493309, Accuracy: 1.0\n",
            "Step 21144/22500 - Loss: 0.0026001171208918095, Accuracy: 1.0\n",
            "Step 21145/22500 - Loss: 0.19832497835159302, Accuracy: 0.75\n",
            "Step 21146/22500 - Loss: 0.14144828915596008, Accuracy: 0.875\n",
            "Step 21147/22500 - Loss: 0.0983084887266159, Accuracy: 1.0\n",
            "Step 21148/22500 - Loss: 0.08149179816246033, Accuracy: 1.0\n",
            "Step 21149/22500 - Loss: 0.013193854130804539, Accuracy: 1.0\n",
            "Step 21150/22500 - Loss: 0.03948880732059479, Accuracy: 1.0\n",
            "Step 21151/22500 - Loss: 0.061976321041584015, Accuracy: 1.0\n",
            "Step 21152/22500 - Loss: 0.009770628064870834, Accuracy: 1.0\n",
            "Step 21153/22500 - Loss: 0.005104789510369301, Accuracy: 1.0\n",
            "Step 21154/22500 - Loss: 0.3854108452796936, Accuracy: 0.875\n",
            "Step 21155/22500 - Loss: 0.003840475110337138, Accuracy: 1.0\n",
            "Step 21156/22500 - Loss: 0.019080452620983124, Accuracy: 1.0\n",
            "Step 21157/22500 - Loss: 0.024565204977989197, Accuracy: 1.0\n",
            "Step 21158/22500 - Loss: 0.013373161666095257, Accuracy: 1.0\n",
            "Step 21159/22500 - Loss: 0.24855439364910126, Accuracy: 0.875\n",
            "Step 21160/22500 - Loss: 0.0754552036523819, Accuracy: 1.0\n",
            "Step 21161/22500 - Loss: 0.01976032741367817, Accuracy: 1.0\n",
            "Step 21162/22500 - Loss: 0.017602114006876945, Accuracy: 1.0\n",
            "Step 21163/22500 - Loss: 0.055738095194101334, Accuracy: 1.0\n",
            "Step 21164/22500 - Loss: 0.022238846868276596, Accuracy: 1.0\n",
            "Step 21165/22500 - Loss: 0.006235763896256685, Accuracy: 1.0\n",
            "Step 21166/22500 - Loss: 0.05852299928665161, Accuracy: 1.0\n",
            "Step 21167/22500 - Loss: 0.043957315385341644, Accuracy: 1.0\n",
            "Step 21168/22500 - Loss: 0.5010019540786743, Accuracy: 0.75\n",
            "Step 21169/22500 - Loss: 0.010174217633903027, Accuracy: 1.0\n",
            "Step 21170/22500 - Loss: 0.0471884161233902, Accuracy: 1.0\n",
            "Step 21171/22500 - Loss: 0.07619716227054596, Accuracy: 1.0\n",
            "Step 21172/22500 - Loss: 0.33792465925216675, Accuracy: 0.875\n",
            "Step 21173/22500 - Loss: 0.6775228381156921, Accuracy: 0.75\n",
            "Step 21174/22500 - Loss: 0.024717088788747787, Accuracy: 1.0\n",
            "Step 21175/22500 - Loss: 0.03144093230366707, Accuracy: 1.0\n",
            "Step 21176/22500 - Loss: 0.06767279654741287, Accuracy: 1.0\n",
            "Step 21177/22500 - Loss: 0.12036129087209702, Accuracy: 0.875\n",
            "Step 21178/22500 - Loss: 0.15323969721794128, Accuracy: 0.875\n",
            "Step 21179/22500 - Loss: 0.12515127658843994, Accuracy: 0.875\n",
            "Step 21180/22500 - Loss: 0.003407333744689822, Accuracy: 1.0\n",
            "Step 21181/22500 - Loss: 0.033104293048381805, Accuracy: 1.0\n",
            "Step 21182/22500 - Loss: 0.17644654214382172, Accuracy: 0.875\n",
            "Step 21183/22500 - Loss: 0.22291256487369537, Accuracy: 0.75\n",
            "Step 21184/22500 - Loss: 0.02778194658458233, Accuracy: 1.0\n",
            "Step 21185/22500 - Loss: 0.14195099472999573, Accuracy: 0.875\n",
            "Step 21186/22500 - Loss: 0.11138810962438583, Accuracy: 0.875\n",
            "Step 21187/22500 - Loss: 0.008843415416777134, Accuracy: 1.0\n",
            "Step 21188/22500 - Loss: 0.18564634025096893, Accuracy: 0.875\n",
            "Step 21189/22500 - Loss: 0.014778224751353264, Accuracy: 1.0\n",
            "Step 21190/22500 - Loss: 0.011325519531965256, Accuracy: 1.0\n",
            "Step 21191/22500 - Loss: 0.05623141676187515, Accuracy: 1.0\n",
            "Step 21192/22500 - Loss: 0.08143343031406403, Accuracy: 1.0\n",
            "Step 21193/22500 - Loss: 0.2600345313549042, Accuracy: 0.75\n",
            "Step 21194/22500 - Loss: 0.1449841558933258, Accuracy: 0.875\n",
            "Step 21195/22500 - Loss: 0.1582966446876526, Accuracy: 1.0\n",
            "Step 21196/22500 - Loss: 0.012813928537070751, Accuracy: 1.0\n",
            "Step 21197/22500 - Loss: 0.0031829860527068377, Accuracy: 1.0\n",
            "Step 21198/22500 - Loss: 0.017602693289518356, Accuracy: 1.0\n",
            "Step 21199/22500 - Loss: 0.01993511989712715, Accuracy: 1.0\n",
            "Step 21200/22500 - Loss: 0.022350717335939407, Accuracy: 1.0\n",
            "Step 21201/22500 - Loss: 0.2111455798149109, Accuracy: 0.875\n",
            "Step 21202/22500 - Loss: 0.4689749777317047, Accuracy: 0.75\n",
            "Step 21203/22500 - Loss: 0.174452543258667, Accuracy: 0.875\n",
            "Step 21204/22500 - Loss: 0.0385943204164505, Accuracy: 1.0\n",
            "Step 21205/22500 - Loss: 0.055128663778305054, Accuracy: 1.0\n",
            "Step 21206/22500 - Loss: 0.04477035254240036, Accuracy: 1.0\n",
            "Step 21207/22500 - Loss: 0.1705635040998459, Accuracy: 0.875\n",
            "Step 21208/22500 - Loss: 0.2276810109615326, Accuracy: 0.875\n",
            "Step 21209/22500 - Loss: 0.03374012932181358, Accuracy: 1.0\n",
            "Step 21210/22500 - Loss: 0.035074569284915924, Accuracy: 1.0\n",
            "Step 21211/22500 - Loss: 0.040090162307024, Accuracy: 1.0\n",
            "Step 21212/22500 - Loss: 0.06274985522031784, Accuracy: 1.0\n",
            "Step 21213/22500 - Loss: 0.005661963950842619, Accuracy: 1.0\n",
            "Step 21214/22500 - Loss: 0.27574506402015686, Accuracy: 0.875\n",
            "Step 21215/22500 - Loss: 0.030833585187792778, Accuracy: 1.0\n",
            "Step 21216/22500 - Loss: 0.3302195966243744, Accuracy: 0.875\n",
            "Step 21217/22500 - Loss: 0.0064476728439331055, Accuracy: 1.0\n",
            "Step 21218/22500 - Loss: 0.11197884380817413, Accuracy: 1.0\n",
            "Step 21219/22500 - Loss: 0.2554360628128052, Accuracy: 0.875\n",
            "Step 21220/22500 - Loss: 0.014953752979636192, Accuracy: 1.0\n",
            "Step 21221/22500 - Loss: 0.03630482405424118, Accuracy: 1.0\n",
            "Step 21222/22500 - Loss: 0.38512179255485535, Accuracy: 0.875\n",
            "Step 21223/22500 - Loss: 0.2564028799533844, Accuracy: 0.75\n",
            "Step 21224/22500 - Loss: 0.352772057056427, Accuracy: 0.875\n",
            "Step 21225/22500 - Loss: 0.035802606493234634, Accuracy: 1.0\n",
            "Step 21226/22500 - Loss: 0.18447235226631165, Accuracy: 1.0\n",
            "Step 21227/22500 - Loss: 0.17244760692119598, Accuracy: 0.875\n",
            "Step 21228/22500 - Loss: 0.3214813470840454, Accuracy: 0.875\n",
            "Step 21229/22500 - Loss: 0.08828698098659515, Accuracy: 1.0\n",
            "Step 21230/22500 - Loss: 0.38661691546440125, Accuracy: 0.75\n",
            "Step 21231/22500 - Loss: 0.0397665873169899, Accuracy: 1.0\n",
            "Step 21232/22500 - Loss: 0.24708926677703857, Accuracy: 0.875\n",
            "Step 21233/22500 - Loss: 0.05820087343454361, Accuracy: 1.0\n",
            "Step 21234/22500 - Loss: 0.0981127917766571, Accuracy: 1.0\n",
            "Step 21235/22500 - Loss: 0.008794555440545082, Accuracy: 1.0\n",
            "Step 21236/22500 - Loss: 0.04970288276672363, Accuracy: 1.0\n",
            "Step 21237/22500 - Loss: 0.3823460042476654, Accuracy: 0.875\n",
            "Step 21238/22500 - Loss: 0.09254056960344315, Accuracy: 0.875\n",
            "Step 21239/22500 - Loss: 0.08620952069759369, Accuracy: 1.0\n",
            "Step 21240/22500 - Loss: 0.07804026454687119, Accuracy: 1.0\n",
            "Step 21241/22500 - Loss: 0.3823670744895935, Accuracy: 0.875\n",
            "Step 21242/22500 - Loss: 0.009714418090879917, Accuracy: 1.0\n",
            "Step 21243/22500 - Loss: 0.19723016023635864, Accuracy: 0.875\n",
            "Step 21244/22500 - Loss: 0.22495608031749725, Accuracy: 0.875\n",
            "Step 21245/22500 - Loss: 0.08045117557048798, Accuracy: 1.0\n",
            "Step 21246/22500 - Loss: 0.06572623550891876, Accuracy: 1.0\n",
            "Step 21247/22500 - Loss: 0.4174171984195709, Accuracy: 0.875\n",
            "Step 21248/22500 - Loss: 0.025774968788027763, Accuracy: 1.0\n",
            "Step 21249/22500 - Loss: 0.10843348503112793, Accuracy: 0.875\n",
            "Step 21250/22500 - Loss: 0.029541032388806343, Accuracy: 1.0\n",
            "Step 21251/22500 - Loss: 0.016180919483304024, Accuracy: 1.0\n",
            "Step 21252/22500 - Loss: 0.016396010294556618, Accuracy: 1.0\n",
            "Step 21253/22500 - Loss: 0.014941630885004997, Accuracy: 1.0\n",
            "Step 21254/22500 - Loss: 0.3930615186691284, Accuracy: 0.875\n",
            "Step 21255/22500 - Loss: 0.07026385515928268, Accuracy: 1.0\n",
            "Step 21256/22500 - Loss: 0.024427326396107674, Accuracy: 1.0\n",
            "Step 21257/22500 - Loss: 0.05916554480791092, Accuracy: 1.0\n",
            "Step 21258/22500 - Loss: 0.016333600506186485, Accuracy: 1.0\n",
            "Step 21259/22500 - Loss: 0.11557691544294357, Accuracy: 0.875\n",
            "Step 21260/22500 - Loss: 0.38910841941833496, Accuracy: 0.875\n",
            "Step 21261/22500 - Loss: 0.004126095212996006, Accuracy: 1.0\n",
            "Step 21262/22500 - Loss: 0.29049578309059143, Accuracy: 0.875\n",
            "Step 21263/22500 - Loss: 0.04721022769808769, Accuracy: 1.0\n",
            "Step 21264/22500 - Loss: 0.11122160404920578, Accuracy: 1.0\n",
            "Step 21265/22500 - Loss: 0.0280144102871418, Accuracy: 1.0\n",
            "Step 21266/22500 - Loss: 0.01650410331785679, Accuracy: 1.0\n",
            "Step 21267/22500 - Loss: 0.029429320245981216, Accuracy: 1.0\n",
            "Step 21268/22500 - Loss: 0.051722630858421326, Accuracy: 1.0\n",
            "Step 21269/22500 - Loss: 0.021974582225084305, Accuracy: 1.0\n",
            "Step 21270/22500 - Loss: 0.39117759466171265, Accuracy: 0.875\n",
            "Step 21271/22500 - Loss: 0.024173572659492493, Accuracy: 1.0\n",
            "Step 21272/22500 - Loss: 0.03300035372376442, Accuracy: 1.0\n",
            "Step 21273/22500 - Loss: 0.015637144446372986, Accuracy: 1.0\n",
            "Step 21274/22500 - Loss: 0.03570673614740372, Accuracy: 1.0\n",
            "Step 21275/22500 - Loss: 0.007391829043626785, Accuracy: 1.0\n",
            "Step 21276/22500 - Loss: 0.02132461965084076, Accuracy: 1.0\n",
            "Step 21277/22500 - Loss: 0.0023119766265153885, Accuracy: 1.0\n",
            "Step 21278/22500 - Loss: 0.5523027777671814, Accuracy: 0.75\n",
            "Step 21279/22500 - Loss: 0.06536611169576645, Accuracy: 1.0\n",
            "Step 21280/22500 - Loss: 0.023713072761893272, Accuracy: 1.0\n",
            "Step 21281/22500 - Loss: 0.0363023616373539, Accuracy: 1.0\n",
            "Step 21282/22500 - Loss: 0.019596202298998833, Accuracy: 1.0\n",
            "Step 21283/22500 - Loss: 0.1648128181695938, Accuracy: 1.0\n",
            "Step 21284/22500 - Loss: 0.7024886608123779, Accuracy: 0.75\n",
            "Step 21285/22500 - Loss: 0.062291909009218216, Accuracy: 1.0\n",
            "Step 21286/22500 - Loss: 0.11775819212198257, Accuracy: 1.0\n",
            "Step 21287/22500 - Loss: 0.023040203377604485, Accuracy: 1.0\n",
            "Step 21288/22500 - Loss: 0.06931405514478683, Accuracy: 1.0\n",
            "Step 21289/22500 - Loss: 0.07640452682971954, Accuracy: 1.0\n",
            "Step 21290/22500 - Loss: 0.13437889516353607, Accuracy: 0.875\n",
            "Step 21291/22500 - Loss: 0.003146338276565075, Accuracy: 1.0\n",
            "Step 21292/22500 - Loss: 0.03485984727740288, Accuracy: 1.0\n",
            "Step 21293/22500 - Loss: 0.08768313378095627, Accuracy: 1.0\n",
            "Step 21294/22500 - Loss: 0.0469110831618309, Accuracy: 1.0\n",
            "Step 21295/22500 - Loss: 0.6370673775672913, Accuracy: 0.875\n",
            "Step 21296/22500 - Loss: 0.14071819186210632, Accuracy: 1.0\n",
            "Step 21297/22500 - Loss: 0.02702169120311737, Accuracy: 1.0\n",
            "Step 21298/22500 - Loss: 0.012736370787024498, Accuracy: 1.0\n",
            "Step 21299/22500 - Loss: 0.1600496768951416, Accuracy: 1.0\n",
            "Step 21300/22500 - Loss: 0.032712172716856, Accuracy: 1.0\n",
            "Step 21301/22500 - Loss: 0.11938243359327316, Accuracy: 0.875\n",
            "Step 21302/22500 - Loss: 0.05210684612393379, Accuracy: 1.0\n",
            "Step 21303/22500 - Loss: 0.011704281903803349, Accuracy: 1.0\n",
            "Step 21304/22500 - Loss: 0.22889211773872375, Accuracy: 0.875\n",
            "Step 21305/22500 - Loss: 0.02150527946650982, Accuracy: 1.0\n",
            "Step 21306/22500 - Loss: 0.08306606113910675, Accuracy: 1.0\n",
            "Step 21307/22500 - Loss: 0.0926065444946289, Accuracy: 1.0\n",
            "Step 21308/22500 - Loss: 0.32416605949401855, Accuracy: 0.875\n",
            "Step 21309/22500 - Loss: 0.004835772328078747, Accuracy: 1.0\n",
            "Step 21310/22500 - Loss: 0.19326740503311157, Accuracy: 0.875\n",
            "Step 21311/22500 - Loss: 0.020419126376509666, Accuracy: 1.0\n",
            "Step 21312/22500 - Loss: 0.22232040762901306, Accuracy: 0.875\n",
            "Step 21313/22500 - Loss: 0.14655306935310364, Accuracy: 0.875\n",
            "Step 21314/22500 - Loss: 0.010371771641075611, Accuracy: 1.0\n",
            "Step 21315/22500 - Loss: 0.024297885596752167, Accuracy: 1.0\n",
            "Step 21316/22500 - Loss: 0.18862682580947876, Accuracy: 0.875\n",
            "Step 21317/22500 - Loss: 0.1989567130804062, Accuracy: 0.875\n",
            "Step 21318/22500 - Loss: 0.06183459609746933, Accuracy: 1.0\n",
            "Step 21319/22500 - Loss: 0.34652459621429443, Accuracy: 0.875\n",
            "Step 21320/22500 - Loss: 0.0408649705350399, Accuracy: 1.0\n",
            "Step 21321/22500 - Loss: 0.08937808871269226, Accuracy: 1.0\n",
            "Step 21322/22500 - Loss: 0.15839746594429016, Accuracy: 0.875\n",
            "Step 21323/22500 - Loss: 0.057426199316978455, Accuracy: 1.0\n",
            "Step 21324/22500 - Loss: 0.025051066651940346, Accuracy: 1.0\n",
            "Step 21325/22500 - Loss: 0.16426043212413788, Accuracy: 0.875\n",
            "Step 21326/22500 - Loss: 0.09387774765491486, Accuracy: 1.0\n",
            "Step 21327/22500 - Loss: 0.10545112192630768, Accuracy: 1.0\n",
            "Step 21328/22500 - Loss: 0.10965154320001602, Accuracy: 1.0\n",
            "Step 21329/22500 - Loss: 0.22609277069568634, Accuracy: 0.875\n",
            "Step 21330/22500 - Loss: 0.06851749122142792, Accuracy: 1.0\n",
            "Step 21331/22500 - Loss: 0.2386472374200821, Accuracy: 0.875\n",
            "Step 21332/22500 - Loss: 0.029897453263401985, Accuracy: 1.0\n",
            "Step 21333/22500 - Loss: 0.12980268895626068, Accuracy: 0.875\n",
            "Step 21334/22500 - Loss: 0.25271376967430115, Accuracy: 0.75\n",
            "Step 21335/22500 - Loss: 0.05910530686378479, Accuracy: 1.0\n",
            "Step 21336/22500 - Loss: 0.020815547555685043, Accuracy: 1.0\n",
            "Step 21337/22500 - Loss: 0.006304256618022919, Accuracy: 1.0\n",
            "Step 21338/22500 - Loss: 0.024735117331147194, Accuracy: 1.0\n",
            "Step 21339/22500 - Loss: 0.009318385273218155, Accuracy: 1.0\n",
            "Step 21340/22500 - Loss: 0.1915387660264969, Accuracy: 0.875\n",
            "Step 21341/22500 - Loss: 0.037425100803375244, Accuracy: 1.0\n",
            "Step 21342/22500 - Loss: 0.18039318919181824, Accuracy: 0.875\n",
            "Step 21343/22500 - Loss: 0.004707887303084135, Accuracy: 1.0\n",
            "Step 21344/22500 - Loss: 0.3705624043941498, Accuracy: 0.875\n",
            "Step 21345/22500 - Loss: 0.1821366548538208, Accuracy: 0.875\n",
            "Step 21346/22500 - Loss: 0.007040747441351414, Accuracy: 1.0\n",
            "Step 21347/22500 - Loss: 0.022655101493000984, Accuracy: 1.0\n",
            "Step 21348/22500 - Loss: 0.036389436572790146, Accuracy: 1.0\n",
            "Step 21349/22500 - Loss: 0.011703073047101498, Accuracy: 1.0\n",
            "Step 21350/22500 - Loss: 0.11370775103569031, Accuracy: 1.0\n",
            "Step 21351/22500 - Loss: 0.056717399507761, Accuracy: 1.0\n",
            "Step 21352/22500 - Loss: 0.024980230256915092, Accuracy: 1.0\n",
            "Step 21353/22500 - Loss: 0.10507837682962418, Accuracy: 0.875\n",
            "Step 21354/22500 - Loss: 0.09194859117269516, Accuracy: 1.0\n",
            "Step 21355/22500 - Loss: 0.014880177564918995, Accuracy: 1.0\n",
            "Step 21356/22500 - Loss: 0.2673211395740509, Accuracy: 0.875\n",
            "Step 21357/22500 - Loss: 0.0664866715669632, Accuracy: 1.0\n",
            "Step 21358/22500 - Loss: 0.01553548313677311, Accuracy: 1.0\n",
            "Step 21359/22500 - Loss: 0.06370935589075089, Accuracy: 1.0\n",
            "Step 21360/22500 - Loss: 0.018887963145971298, Accuracy: 1.0\n",
            "Step 21361/22500 - Loss: 0.011275487020611763, Accuracy: 1.0\n",
            "Step 21362/22500 - Loss: 0.2180117815732956, Accuracy: 0.875\n",
            "Step 21363/22500 - Loss: 0.031416453421115875, Accuracy: 1.0\n",
            "Step 21364/22500 - Loss: 0.6855449676513672, Accuracy: 0.875\n",
            "Step 21365/22500 - Loss: 0.00527243223041296, Accuracy: 1.0\n",
            "Step 21366/22500 - Loss: 0.011949661187827587, Accuracy: 1.0\n",
            "Step 21367/22500 - Loss: 0.021102076396346092, Accuracy: 1.0\n",
            "Step 21368/22500 - Loss: 0.15181013941764832, Accuracy: 0.875\n",
            "Step 21369/22500 - Loss: 0.10509217530488968, Accuracy: 1.0\n",
            "Step 21370/22500 - Loss: 0.061264149844646454, Accuracy: 1.0\n",
            "Step 21371/22500 - Loss: 0.019716225564479828, Accuracy: 1.0\n",
            "Step 21372/22500 - Loss: 0.12849724292755127, Accuracy: 1.0\n",
            "Step 21373/22500 - Loss: 0.04624048247933388, Accuracy: 1.0\n",
            "Step 21374/22500 - Loss: 0.17129720747470856, Accuracy: 1.0\n",
            "Step 21375/22500 - Loss: 0.02165442891418934, Accuracy: 1.0\n",
            "Step 21376/22500 - Loss: 0.07676499336957932, Accuracy: 1.0\n",
            "Step 21377/22500 - Loss: 0.07308913767337799, Accuracy: 1.0\n",
            "Step 21378/22500 - Loss: 0.037859685719013214, Accuracy: 1.0\n",
            "Step 21379/22500 - Loss: 0.004700811114162207, Accuracy: 1.0\n",
            "Step 21380/22500 - Loss: 0.006476438604295254, Accuracy: 1.0\n",
            "Step 21381/22500 - Loss: 0.2683679461479187, Accuracy: 0.875\n",
            "Step 21382/22500 - Loss: 0.06631496548652649, Accuracy: 1.0\n",
            "Step 21383/22500 - Loss: 0.042878810316324234, Accuracy: 1.0\n",
            "Step 21384/22500 - Loss: 0.27730312943458557, Accuracy: 0.875\n",
            "Step 21385/22500 - Loss: 0.060683779418468475, Accuracy: 1.0\n",
            "Step 21386/22500 - Loss: 0.026358818635344505, Accuracy: 1.0\n",
            "Step 21387/22500 - Loss: 0.16722701489925385, Accuracy: 0.875\n",
            "Step 21388/22500 - Loss: 0.3086930513381958, Accuracy: 0.875\n",
            "Step 21389/22500 - Loss: 0.03105551190674305, Accuracy: 1.0\n",
            "Step 21390/22500 - Loss: 0.03219369053840637, Accuracy: 1.0\n",
            "Step 21391/22500 - Loss: 0.015278303995728493, Accuracy: 1.0\n",
            "Step 21392/22500 - Loss: 0.005108097102493048, Accuracy: 1.0\n",
            "Step 21393/22500 - Loss: 0.05307319387793541, Accuracy: 1.0\n",
            "Step 21394/22500 - Loss: 0.18801167607307434, Accuracy: 0.875\n",
            "Step 21395/22500 - Loss: 0.010823643766343594, Accuracy: 1.0\n",
            "Step 21396/22500 - Loss: 0.010376960039138794, Accuracy: 1.0\n",
            "Step 21397/22500 - Loss: 0.27227768301963806, Accuracy: 0.875\n",
            "Step 21398/22500 - Loss: 0.021868539974093437, Accuracy: 1.0\n",
            "Step 21399/22500 - Loss: 0.009519456885755062, Accuracy: 1.0\n",
            "Step 21400/22500 - Loss: 0.06504498422145844, Accuracy: 1.0\n",
            "Step 21401/22500 - Loss: 0.10455702990293503, Accuracy: 1.0\n",
            "Step 21402/22500 - Loss: 0.380908340215683, Accuracy: 0.75\n",
            "Step 21403/22500 - Loss: 0.21067765355110168, Accuracy: 0.875\n",
            "Step 21404/22500 - Loss: 0.22573791444301605, Accuracy: 0.875\n",
            "Step 21405/22500 - Loss: 0.035000793635845184, Accuracy: 1.0\n",
            "Step 21406/22500 - Loss: 0.1299133598804474, Accuracy: 0.875\n",
            "Step 21407/22500 - Loss: 0.055966202169656754, Accuracy: 1.0\n",
            "Step 21408/22500 - Loss: 0.02026762254536152, Accuracy: 1.0\n",
            "Step 21409/22500 - Loss: 0.5185675024986267, Accuracy: 0.75\n",
            "Step 21410/22500 - Loss: 0.14523041248321533, Accuracy: 1.0\n",
            "Step 21411/22500 - Loss: 0.011031508445739746, Accuracy: 1.0\n",
            "Step 21412/22500 - Loss: 0.09736847132444382, Accuracy: 1.0\n",
            "Step 21413/22500 - Loss: 0.025165094062685966, Accuracy: 1.0\n",
            "Step 21414/22500 - Loss: 0.009836897253990173, Accuracy: 1.0\n",
            "Step 21415/22500 - Loss: 0.04279068857431412, Accuracy: 1.0\n",
            "Step 21416/22500 - Loss: 0.004833567887544632, Accuracy: 1.0\n",
            "Step 21417/22500 - Loss: 0.047003552317619324, Accuracy: 1.0\n",
            "Step 21418/22500 - Loss: 0.018503574654459953, Accuracy: 1.0\n",
            "Step 21419/22500 - Loss: 0.02011498063802719, Accuracy: 1.0\n",
            "Step 21420/22500 - Loss: 0.2593172788619995, Accuracy: 0.875\n",
            "Step 21421/22500 - Loss: 0.011633865535259247, Accuracy: 1.0\n",
            "Step 21422/22500 - Loss: 0.042791396379470825, Accuracy: 1.0\n",
            "Step 21423/22500 - Loss: 0.22523954510688782, Accuracy: 0.875\n",
            "Step 21424/22500 - Loss: 0.14281068742275238, Accuracy: 0.875\n",
            "Step 21425/22500 - Loss: 0.08209406584501266, Accuracy: 1.0\n",
            "Step 21426/22500 - Loss: 0.006724259350448847, Accuracy: 1.0\n",
            "Step 21427/22500 - Loss: 0.016519293189048767, Accuracy: 1.0\n",
            "Step 21428/22500 - Loss: 0.12698708474636078, Accuracy: 1.0\n",
            "Step 21429/22500 - Loss: 0.007674943655729294, Accuracy: 1.0\n",
            "Step 21430/22500 - Loss: 0.12289769947528839, Accuracy: 1.0\n",
            "Step 21431/22500 - Loss: 0.21498312056064606, Accuracy: 0.875\n",
            "Step 21432/22500 - Loss: 0.009037043899297714, Accuracy: 1.0\n",
            "Step 21433/22500 - Loss: 0.28041014075279236, Accuracy: 0.875\n",
            "Step 21434/22500 - Loss: 0.08318236470222473, Accuracy: 1.0\n",
            "Step 21435/22500 - Loss: 0.0078562768176198, Accuracy: 1.0\n",
            "Step 21436/22500 - Loss: 0.029243573546409607, Accuracy: 1.0\n",
            "Step 21437/22500 - Loss: 0.010053913109004498, Accuracy: 1.0\n",
            "Step 21438/22500 - Loss: 0.1966797560453415, Accuracy: 0.875\n",
            "Step 21439/22500 - Loss: 0.005592750385403633, Accuracy: 1.0\n",
            "Step 21440/22500 - Loss: 0.13849911093711853, Accuracy: 0.875\n",
            "Step 21441/22500 - Loss: 0.04028429090976715, Accuracy: 1.0\n",
            "Step 21442/22500 - Loss: 0.07538864761590958, Accuracy: 1.0\n",
            "Step 21443/22500 - Loss: 0.05464787408709526, Accuracy: 1.0\n",
            "Step 21444/22500 - Loss: 0.02354125678539276, Accuracy: 1.0\n",
            "Step 21445/22500 - Loss: 0.03621510788798332, Accuracy: 1.0\n",
            "Step 21446/22500 - Loss: 0.013211377896368504, Accuracy: 1.0\n",
            "Step 21447/22500 - Loss: 0.20139789581298828, Accuracy: 0.875\n",
            "Step 21448/22500 - Loss: 0.08944008499383926, Accuracy: 1.0\n",
            "Step 21449/22500 - Loss: 0.10981755703687668, Accuracy: 1.0\n",
            "Step 21450/22500 - Loss: 0.05355655774474144, Accuracy: 1.0\n",
            "Step 21451/22500 - Loss: 0.13367922604084015, Accuracy: 1.0\n",
            "Step 21452/22500 - Loss: 0.06798653304576874, Accuracy: 1.0\n",
            "Step 21453/22500 - Loss: 0.1115230917930603, Accuracy: 1.0\n",
            "Step 21454/22500 - Loss: 0.05449243262410164, Accuracy: 1.0\n",
            "Step 21455/22500 - Loss: 0.007112708408385515, Accuracy: 1.0\n",
            "Step 21456/22500 - Loss: 0.022760048508644104, Accuracy: 1.0\n",
            "Step 21457/22500 - Loss: 0.0037497628945857286, Accuracy: 1.0\n",
            "Step 21458/22500 - Loss: 0.10077524930238724, Accuracy: 1.0\n",
            "Step 21459/22500 - Loss: 0.014399992302060127, Accuracy: 1.0\n",
            "Step 21460/22500 - Loss: 0.34830141067504883, Accuracy: 0.875\n",
            "Step 21461/22500 - Loss: 0.0380188450217247, Accuracy: 1.0\n",
            "Step 21462/22500 - Loss: 0.01660739630460739, Accuracy: 1.0\n",
            "Step 21463/22500 - Loss: 0.2600230574607849, Accuracy: 0.875\n",
            "Step 21464/22500 - Loss: 0.030049597844481468, Accuracy: 1.0\n",
            "Step 21465/22500 - Loss: 0.1240244209766388, Accuracy: 1.0\n",
            "Step 21466/22500 - Loss: 0.05362363159656525, Accuracy: 1.0\n",
            "Step 21467/22500 - Loss: 0.13915203511714935, Accuracy: 0.875\n",
            "Step 21468/22500 - Loss: 0.08755869418382645, Accuracy: 1.0\n",
            "Step 21469/22500 - Loss: 0.008373276330530643, Accuracy: 1.0\n",
            "Step 21470/22500 - Loss: 0.08942639827728271, Accuracy: 1.0\n",
            "Step 21471/22500 - Loss: 0.5519044399261475, Accuracy: 0.875\n",
            "Step 21472/22500 - Loss: 0.21709303557872772, Accuracy: 1.0\n",
            "Step 21473/22500 - Loss: 0.09375346451997757, Accuracy: 1.0\n",
            "Step 21474/22500 - Loss: 0.0877770408987999, Accuracy: 1.0\n",
            "Step 21475/22500 - Loss: 0.005255718715488911, Accuracy: 1.0\n",
            "Step 21476/22500 - Loss: 0.010377364233136177, Accuracy: 1.0\n",
            "Step 21477/22500 - Loss: 0.014611685648560524, Accuracy: 1.0\n",
            "Step 21478/22500 - Loss: 0.049061160534620285, Accuracy: 1.0\n",
            "Step 21479/22500 - Loss: 0.0023770646657794714, Accuracy: 1.0\n",
            "Step 21480/22500 - Loss: 0.11706221103668213, Accuracy: 0.875\n",
            "Step 21481/22500 - Loss: 0.0777662843465805, Accuracy: 1.0\n",
            "Step 21482/22500 - Loss: 0.1835063099861145, Accuracy: 0.875\n",
            "Step 21483/22500 - Loss: 0.01505438331514597, Accuracy: 1.0\n",
            "Step 21484/22500 - Loss: 0.014933709055185318, Accuracy: 1.0\n",
            "Step 21485/22500 - Loss: 0.03105325438082218, Accuracy: 1.0\n",
            "Step 21486/22500 - Loss: 0.07878861576318741, Accuracy: 1.0\n",
            "Step 21487/22500 - Loss: 0.014598476700484753, Accuracy: 1.0\n",
            "Step 21488/22500 - Loss: 0.06330987811088562, Accuracy: 1.0\n",
            "Step 21489/22500 - Loss: 0.007570501416921616, Accuracy: 1.0\n",
            "Step 21490/22500 - Loss: 0.4911872148513794, Accuracy: 0.875\n",
            "Step 21491/22500 - Loss: 0.05127055197954178, Accuracy: 1.0\n",
            "Step 21492/22500 - Loss: 0.023489931598305702, Accuracy: 1.0\n",
            "Step 21493/22500 - Loss: 0.4452487528324127, Accuracy: 0.875\n",
            "Step 21494/22500 - Loss: 0.7944439649581909, Accuracy: 0.75\n",
            "Step 21495/22500 - Loss: 0.029645895585417747, Accuracy: 1.0\n",
            "Step 21496/22500 - Loss: 0.07575379312038422, Accuracy: 1.0\n",
            "Step 21497/22500 - Loss: 0.0836697444319725, Accuracy: 1.0\n",
            "Step 21498/22500 - Loss: 0.05546104535460472, Accuracy: 1.0\n",
            "Step 21499/22500 - Loss: 0.025804847478866577, Accuracy: 1.0\n",
            "Step 21500/22500 - Loss: 0.08603265881538391, Accuracy: 1.0\n",
            "Step 21501/22500 - Loss: 0.015164774842560291, Accuracy: 1.0\n",
            "Step 21502/22500 - Loss: 0.04288697987794876, Accuracy: 1.0\n",
            "Step 21503/22500 - Loss: 0.04195638746023178, Accuracy: 1.0\n",
            "Step 21504/22500 - Loss: 0.00817620474845171, Accuracy: 1.0\n",
            "Step 21505/22500 - Loss: 0.3691813349723816, Accuracy: 0.75\n",
            "Step 21506/22500 - Loss: 0.003271430032327771, Accuracy: 1.0\n",
            "Step 21507/22500 - Loss: 0.0501779280602932, Accuracy: 1.0\n",
            "Step 21508/22500 - Loss: 0.02145472541451454, Accuracy: 1.0\n",
            "Step 21509/22500 - Loss: 0.8869795799255371, Accuracy: 0.875\n",
            "Step 21510/22500 - Loss: 0.029600193724036217, Accuracy: 1.0\n",
            "Step 21511/22500 - Loss: 0.00786062702536583, Accuracy: 1.0\n",
            "Step 21512/22500 - Loss: 0.030999677255749702, Accuracy: 1.0\n",
            "Step 21513/22500 - Loss: 0.025637449696660042, Accuracy: 1.0\n",
            "Step 21514/22500 - Loss: 0.06848137080669403, Accuracy: 1.0\n",
            "Step 21515/22500 - Loss: 0.19338777661323547, Accuracy: 0.875\n",
            "Step 21516/22500 - Loss: 0.05747012794017792, Accuracy: 1.0\n",
            "Step 21517/22500 - Loss: 0.026835836470127106, Accuracy: 1.0\n",
            "Step 21518/22500 - Loss: 0.022804543375968933, Accuracy: 1.0\n",
            "Step 21519/22500 - Loss: 0.296699196100235, Accuracy: 0.875\n",
            "Step 21520/22500 - Loss: 0.37660402059555054, Accuracy: 0.75\n",
            "Step 21521/22500 - Loss: 0.19150181114673615, Accuracy: 0.875\n",
            "Step 21522/22500 - Loss: 0.11212588846683502, Accuracy: 0.875\n",
            "Step 21523/22500 - Loss: 0.19617415964603424, Accuracy: 0.875\n",
            "Step 21524/22500 - Loss: 0.1619923859834671, Accuracy: 0.875\n",
            "Step 21525/22500 - Loss: 0.5211312770843506, Accuracy: 0.875\n",
            "Step 21526/22500 - Loss: 0.039803966879844666, Accuracy: 1.0\n",
            "Step 21527/22500 - Loss: 0.16511087119579315, Accuracy: 0.875\n",
            "Step 21528/22500 - Loss: 0.06676048785448074, Accuracy: 1.0\n",
            "Step 21529/22500 - Loss: 0.5635635852813721, Accuracy: 0.875\n",
            "Step 21530/22500 - Loss: 0.30760395526885986, Accuracy: 0.75\n",
            "Step 21531/22500 - Loss: 0.05189047381281853, Accuracy: 1.0\n",
            "Step 21532/22500 - Loss: 0.09181533753871918, Accuracy: 1.0\n",
            "Step 21533/22500 - Loss: 0.015676280483603477, Accuracy: 1.0\n",
            "Step 21534/22500 - Loss: 0.46969884634017944, Accuracy: 0.875\n",
            "Step 21535/22500 - Loss: 0.09346646070480347, Accuracy: 1.0\n",
            "Step 21536/22500 - Loss: 0.04634397476911545, Accuracy: 1.0\n",
            "Step 21537/22500 - Loss: 0.01402558945119381, Accuracy: 1.0\n",
            "Step 21538/22500 - Loss: 0.4514482617378235, Accuracy: 0.75\n",
            "Step 21539/22500 - Loss: 0.732855498790741, Accuracy: 0.75\n",
            "Step 21540/22500 - Loss: 0.01616647280752659, Accuracy: 1.0\n",
            "Step 21541/22500 - Loss: 0.11751941591501236, Accuracy: 0.875\n",
            "Step 21542/22500 - Loss: 0.015522505156695843, Accuracy: 1.0\n",
            "Step 21543/22500 - Loss: 0.03276379033923149, Accuracy: 1.0\n",
            "Step 21544/22500 - Loss: 0.00864760484546423, Accuracy: 1.0\n",
            "Step 21545/22500 - Loss: 0.01789209432899952, Accuracy: 1.0\n",
            "Step 21546/22500 - Loss: 0.05083785206079483, Accuracy: 1.0\n",
            "Step 21547/22500 - Loss: 0.07160324603319168, Accuracy: 1.0\n",
            "Step 21548/22500 - Loss: 0.057742051780223846, Accuracy: 1.0\n",
            "Step 21549/22500 - Loss: 0.056221477687358856, Accuracy: 1.0\n",
            "Step 21550/22500 - Loss: 0.01716095767915249, Accuracy: 1.0\n",
            "Step 21551/22500 - Loss: 0.3632563352584839, Accuracy: 0.75\n",
            "Step 21552/22500 - Loss: 0.0037547461688518524, Accuracy: 1.0\n",
            "Step 21553/22500 - Loss: 0.061587005853652954, Accuracy: 1.0\n",
            "Step 21554/22500 - Loss: 0.10661663115024567, Accuracy: 1.0\n",
            "Step 21555/22500 - Loss: 0.05467512086033821, Accuracy: 1.0\n",
            "Step 21556/22500 - Loss: 0.075191929936409, Accuracy: 1.0\n",
            "Step 21557/22500 - Loss: 0.010470406152307987, Accuracy: 1.0\n",
            "Step 21558/22500 - Loss: 0.05791997164487839, Accuracy: 1.0\n",
            "Step 21559/22500 - Loss: 0.028096575289964676, Accuracy: 1.0\n",
            "Step 21560/22500 - Loss: 0.12387792766094208, Accuracy: 0.875\n",
            "Step 21561/22500 - Loss: 0.07912279665470123, Accuracy: 1.0\n",
            "Step 21562/22500 - Loss: 0.07246245443820953, Accuracy: 1.0\n",
            "Step 21563/22500 - Loss: 0.21196304261684418, Accuracy: 0.875\n",
            "Step 21564/22500 - Loss: 0.4461526572704315, Accuracy: 0.875\n",
            "Step 21565/22500 - Loss: 0.3747607171535492, Accuracy: 0.875\n",
            "Step 21566/22500 - Loss: 0.010723893530666828, Accuracy: 1.0\n",
            "Step 21567/22500 - Loss: 0.118809774518013, Accuracy: 1.0\n",
            "Step 21568/22500 - Loss: 0.0979006215929985, Accuracy: 1.0\n",
            "Step 21569/22500 - Loss: 0.048217952251434326, Accuracy: 1.0\n",
            "Step 21570/22500 - Loss: 0.12097738683223724, Accuracy: 1.0\n",
            "Step 21571/22500 - Loss: 0.020652201026678085, Accuracy: 1.0\n",
            "Step 21572/22500 - Loss: 0.6426039934158325, Accuracy: 0.875\n",
            "Step 21573/22500 - Loss: 0.5798670649528503, Accuracy: 0.75\n",
            "Step 21574/22500 - Loss: 0.18219085037708282, Accuracy: 0.875\n",
            "Step 21575/22500 - Loss: 0.05599703639745712, Accuracy: 1.0\n",
            "Step 21576/22500 - Loss: 0.010046513751149178, Accuracy: 1.0\n",
            "Step 21577/22500 - Loss: 0.03575129806995392, Accuracy: 1.0\n",
            "Step 21578/22500 - Loss: 0.31346651911735535, Accuracy: 0.875\n",
            "Step 21579/22500 - Loss: 0.0037252353504300117, Accuracy: 1.0\n",
            "Step 21580/22500 - Loss: 0.3657100200653076, Accuracy: 0.875\n",
            "Step 21581/22500 - Loss: 0.009661417454481125, Accuracy: 1.0\n",
            "Step 21582/22500 - Loss: 0.13648349046707153, Accuracy: 0.875\n",
            "Step 21583/22500 - Loss: 0.0023325816728174686, Accuracy: 1.0\n",
            "Step 21584/22500 - Loss: 0.03307124972343445, Accuracy: 1.0\n",
            "Step 21585/22500 - Loss: 0.025390375405550003, Accuracy: 1.0\n",
            "Step 21586/22500 - Loss: 0.07711474597454071, Accuracy: 1.0\n",
            "Step 21587/22500 - Loss: 0.3537213206291199, Accuracy: 0.875\n",
            "Step 21588/22500 - Loss: 0.030025584623217583, Accuracy: 1.0\n",
            "Step 21589/22500 - Loss: 0.13982734084129333, Accuracy: 0.875\n",
            "Step 21590/22500 - Loss: 0.019362248480319977, Accuracy: 1.0\n",
            "Step 21591/22500 - Loss: 0.15087449550628662, Accuracy: 1.0\n",
            "Step 21592/22500 - Loss: 0.05779729411005974, Accuracy: 1.0\n",
            "Step 21593/22500 - Loss: 0.017303375527262688, Accuracy: 1.0\n",
            "Step 21594/22500 - Loss: 0.6059620380401611, Accuracy: 0.875\n",
            "Step 21595/22500 - Loss: 0.4272293150424957, Accuracy: 0.875\n",
            "Step 21596/22500 - Loss: 0.046627309173345566, Accuracy: 1.0\n",
            "Step 21597/22500 - Loss: 0.13574139773845673, Accuracy: 0.875\n",
            "Step 21598/22500 - Loss: 0.08555826544761658, Accuracy: 1.0\n",
            "Step 21599/22500 - Loss: 0.01551100891083479, Accuracy: 1.0\n",
            "Step 21600/22500 - Loss: 0.048900261521339417, Accuracy: 1.0\n",
            "Step 21601/22500 - Loss: 0.15701913833618164, Accuracy: 0.875\n",
            "Step 21602/22500 - Loss: 0.09244648367166519, Accuracy: 1.0\n",
            "Step 21603/22500 - Loss: 0.04498739168047905, Accuracy: 1.0\n",
            "Step 21604/22500 - Loss: 0.017361104488372803, Accuracy: 1.0\n",
            "Step 21605/22500 - Loss: 0.18694184720516205, Accuracy: 0.875\n",
            "Step 21606/22500 - Loss: 0.07726878672838211, Accuracy: 1.0\n",
            "Step 21607/22500 - Loss: 0.33522701263427734, Accuracy: 0.75\n",
            "Step 21608/22500 - Loss: 0.5793337821960449, Accuracy: 0.875\n",
            "Step 21609/22500 - Loss: 0.19711336493492126, Accuracy: 0.875\n",
            "Step 21610/22500 - Loss: 0.01648000255227089, Accuracy: 1.0\n",
            "Step 21611/22500 - Loss: 0.2815050482749939, Accuracy: 0.875\n",
            "Step 21612/22500 - Loss: 0.03344913199543953, Accuracy: 1.0\n",
            "Step 21613/22500 - Loss: 0.0034290505573153496, Accuracy: 1.0\n",
            "Step 21614/22500 - Loss: 0.05366965010762215, Accuracy: 1.0\n",
            "Step 21615/22500 - Loss: 0.020589515566825867, Accuracy: 1.0\n",
            "Step 21616/22500 - Loss: 0.06952530890703201, Accuracy: 1.0\n",
            "Step 21617/22500 - Loss: 0.023241324350237846, Accuracy: 1.0\n",
            "Step 21618/22500 - Loss: 0.02899916097521782, Accuracy: 1.0\n",
            "Step 21619/22500 - Loss: 0.054211631417274475, Accuracy: 1.0\n",
            "Step 21620/22500 - Loss: 0.2231343388557434, Accuracy: 0.875\n",
            "Step 21621/22500 - Loss: 0.07211115956306458, Accuracy: 1.0\n",
            "Step 21622/22500 - Loss: 0.2730652391910553, Accuracy: 0.75\n",
            "Step 21623/22500 - Loss: 0.8125805854797363, Accuracy: 0.875\n",
            "Step 21624/22500 - Loss: 0.5322175025939941, Accuracy: 0.875\n",
            "Step 21625/22500 - Loss: 0.1685989648103714, Accuracy: 1.0\n",
            "Step 21626/22500 - Loss: 0.005706549622118473, Accuracy: 1.0\n",
            "Step 21627/22500 - Loss: 0.005762127228081226, Accuracy: 1.0\n",
            "Step 21628/22500 - Loss: 0.03314638510346413, Accuracy: 1.0\n",
            "Step 21629/22500 - Loss: 0.01406569592654705, Accuracy: 1.0\n",
            "Step 21630/22500 - Loss: 0.0024458253756165504, Accuracy: 1.0\n",
            "Step 21631/22500 - Loss: 0.01558844093233347, Accuracy: 1.0\n",
            "Step 21632/22500 - Loss: 0.002998518059030175, Accuracy: 1.0\n",
            "Step 21633/22500 - Loss: 0.06019536778330803, Accuracy: 1.0\n",
            "Step 21634/22500 - Loss: 0.0280089620500803, Accuracy: 1.0\n",
            "Step 21635/22500 - Loss: 0.04118126630783081, Accuracy: 1.0\n",
            "Step 21636/22500 - Loss: 0.2743210196495056, Accuracy: 0.75\n",
            "Step 21637/22500 - Loss: 0.09551495313644409, Accuracy: 1.0\n",
            "Step 21638/22500 - Loss: 0.21311168372631073, Accuracy: 0.875\n",
            "Step 21639/22500 - Loss: 0.00999888963997364, Accuracy: 1.0\n",
            "Step 21640/22500 - Loss: 0.007908416911959648, Accuracy: 1.0\n",
            "Step 21641/22500 - Loss: 0.024620098993182182, Accuracy: 1.0\n",
            "Step 21642/22500 - Loss: 0.019714124500751495, Accuracy: 1.0\n",
            "Step 21643/22500 - Loss: 0.038212988525629044, Accuracy: 1.0\n",
            "Step 21644/22500 - Loss: 0.06827104091644287, Accuracy: 1.0\n",
            "Step 21645/22500 - Loss: 1.2381608486175537, Accuracy: 0.75\n",
            "Step 21646/22500 - Loss: 0.0499018058180809, Accuracy: 1.0\n",
            "Step 21647/22500 - Loss: 0.01280166395008564, Accuracy: 1.0\n",
            "Step 21648/22500 - Loss: 0.050599563866853714, Accuracy: 1.0\n",
            "Step 21649/22500 - Loss: 0.03760251775383949, Accuracy: 1.0\n",
            "Step 21650/22500 - Loss: 0.0951543003320694, Accuracy: 0.875\n",
            "Step 21651/22500 - Loss: 0.11371076852083206, Accuracy: 0.875\n",
            "Step 21652/22500 - Loss: 0.13228008151054382, Accuracy: 0.875\n",
            "Step 21653/22500 - Loss: 0.04752985015511513, Accuracy: 1.0\n",
            "Step 21654/22500 - Loss: 0.3737122714519501, Accuracy: 0.875\n",
            "Step 21655/22500 - Loss: 0.039092812687158585, Accuracy: 1.0\n",
            "Step 21656/22500 - Loss: 0.14304202795028687, Accuracy: 0.875\n",
            "Step 21657/22500 - Loss: 0.0026070207823067904, Accuracy: 1.0\n",
            "Step 21658/22500 - Loss: 0.20959646999835968, Accuracy: 0.875\n",
            "Step 21659/22500 - Loss: 0.23193243145942688, Accuracy: 0.875\n",
            "Step 21660/22500 - Loss: 0.06965924799442291, Accuracy: 1.0\n",
            "Step 21661/22500 - Loss: 0.17638477683067322, Accuracy: 0.875\n",
            "Step 21662/22500 - Loss: 0.16565096378326416, Accuracy: 1.0\n",
            "Step 21663/22500 - Loss: 0.15664808452129364, Accuracy: 0.875\n",
            "Step 21664/22500 - Loss: 0.06939570605754852, Accuracy: 1.0\n",
            "Step 21665/22500 - Loss: 0.012558918446302414, Accuracy: 1.0\n",
            "Step 21666/22500 - Loss: 0.014038234949111938, Accuracy: 1.0\n",
            "Step 21667/22500 - Loss: 0.1764029562473297, Accuracy: 0.875\n",
            "Step 21668/22500 - Loss: 0.1423867642879486, Accuracy: 0.875\n",
            "Step 21669/22500 - Loss: 0.1462218165397644, Accuracy: 0.875\n",
            "Step 21670/22500 - Loss: 0.1161278709769249, Accuracy: 1.0\n",
            "Step 21671/22500 - Loss: 0.07685196399688721, Accuracy: 1.0\n",
            "Step 21672/22500 - Loss: 0.07893455773591995, Accuracy: 1.0\n",
            "Step 21673/22500 - Loss: 0.010751230642199516, Accuracy: 1.0\n",
            "Step 21674/22500 - Loss: 0.014035787433385849, Accuracy: 1.0\n",
            "Step 21675/22500 - Loss: 0.26885098218917847, Accuracy: 0.875\n",
            "Step 21676/22500 - Loss: 0.35716602206230164, Accuracy: 0.875\n",
            "Step 21677/22500 - Loss: 0.20685939490795135, Accuracy: 0.875\n",
            "Step 21678/22500 - Loss: 0.13849100470542908, Accuracy: 0.875\n",
            "Step 21679/22500 - Loss: 0.5451798439025879, Accuracy: 0.75\n",
            "Step 21680/22500 - Loss: 0.12712110579013824, Accuracy: 0.875\n",
            "Step 21681/22500 - Loss: 0.040931232273578644, Accuracy: 1.0\n",
            "Step 21682/22500 - Loss: 0.06810207664966583, Accuracy: 1.0\n",
            "Step 21683/22500 - Loss: 0.006569590885192156, Accuracy: 1.0\n",
            "Step 21684/22500 - Loss: 0.32205840945243835, Accuracy: 0.875\n",
            "Step 21685/22500 - Loss: 0.04064604640007019, Accuracy: 1.0\n",
            "Step 21686/22500 - Loss: 0.033515337854623795, Accuracy: 1.0\n",
            "Step 21687/22500 - Loss: 0.03184974193572998, Accuracy: 1.0\n",
            "Step 21688/22500 - Loss: 0.053294382989406586, Accuracy: 1.0\n",
            "Step 21689/22500 - Loss: 0.054967597126960754, Accuracy: 1.0\n",
            "Step 21690/22500 - Loss: 0.07965759187936783, Accuracy: 1.0\n",
            "Step 21691/22500 - Loss: 0.06590013951063156, Accuracy: 1.0\n",
            "Step 21692/22500 - Loss: 0.10009979456663132, Accuracy: 1.0\n",
            "Step 21693/22500 - Loss: 0.297995388507843, Accuracy: 0.75\n",
            "Step 21694/22500 - Loss: 0.016862129792571068, Accuracy: 1.0\n",
            "Step 21695/22500 - Loss: 0.10229186713695526, Accuracy: 1.0\n",
            "Step 21696/22500 - Loss: 0.02425341308116913, Accuracy: 1.0\n",
            "Step 21697/22500 - Loss: 0.08850158751010895, Accuracy: 1.0\n",
            "Step 21698/22500 - Loss: 0.05083797872066498, Accuracy: 1.0\n",
            "Step 21699/22500 - Loss: 0.12667429447174072, Accuracy: 0.875\n",
            "Step 21700/22500 - Loss: 0.059252623468637466, Accuracy: 1.0\n",
            "Step 21701/22500 - Loss: 0.26495712995529175, Accuracy: 0.875\n",
            "Step 21702/22500 - Loss: 0.016097988933324814, Accuracy: 1.0\n",
            "Step 21703/22500 - Loss: 0.460446834564209, Accuracy: 0.875\n",
            "Step 21704/22500 - Loss: 0.07926416397094727, Accuracy: 1.0\n",
            "Step 21705/22500 - Loss: 0.3212398588657379, Accuracy: 0.75\n",
            "Step 21706/22500 - Loss: 0.3323929011821747, Accuracy: 0.875\n",
            "Step 21707/22500 - Loss: 0.05423466116189957, Accuracy: 1.0\n",
            "Step 21708/22500 - Loss: 0.028558742254972458, Accuracy: 1.0\n",
            "Step 21709/22500 - Loss: 0.055782292038202286, Accuracy: 1.0\n",
            "Step 21710/22500 - Loss: 0.017002137377858162, Accuracy: 1.0\n",
            "Step 21711/22500 - Loss: 0.004749604966491461, Accuracy: 1.0\n",
            "Step 21712/22500 - Loss: 0.01763988845050335, Accuracy: 1.0\n",
            "Step 21713/22500 - Loss: 0.10933960229158401, Accuracy: 0.875\n",
            "Step 21714/22500 - Loss: 0.08091319352388382, Accuracy: 1.0\n",
            "Step 21715/22500 - Loss: 0.06157029792666435, Accuracy: 1.0\n",
            "Step 21716/22500 - Loss: 0.18104565143585205, Accuracy: 0.875\n",
            "Step 21717/22500 - Loss: 0.03710613772273064, Accuracy: 1.0\n",
            "Step 21718/22500 - Loss: 0.008410794660449028, Accuracy: 1.0\n",
            "Step 21719/22500 - Loss: 0.04060934856534004, Accuracy: 1.0\n",
            "Step 21720/22500 - Loss: 0.15244005620479584, Accuracy: 1.0\n",
            "Step 21721/22500 - Loss: 0.016219280660152435, Accuracy: 1.0\n",
            "Step 21722/22500 - Loss: 0.1589093655347824, Accuracy: 0.875\n",
            "Step 21723/22500 - Loss: 0.06656398624181747, Accuracy: 1.0\n",
            "Step 21724/22500 - Loss: 0.07069840282201767, Accuracy: 1.0\n",
            "Step 21725/22500 - Loss: 0.016650360077619553, Accuracy: 1.0\n",
            "Step 21726/22500 - Loss: 0.00972227193415165, Accuracy: 1.0\n",
            "Step 21727/22500 - Loss: 0.3353983461856842, Accuracy: 0.875\n",
            "Step 21728/22500 - Loss: 0.012412182986736298, Accuracy: 1.0\n",
            "Step 21729/22500 - Loss: 0.032656434923410416, Accuracy: 1.0\n",
            "Step 21730/22500 - Loss: 0.32531043887138367, Accuracy: 0.875\n",
            "Step 21731/22500 - Loss: 0.21715228259563446, Accuracy: 0.875\n",
            "Step 21732/22500 - Loss: 0.02061382867395878, Accuracy: 1.0\n",
            "Step 21733/22500 - Loss: 0.4238418638706207, Accuracy: 0.875\n",
            "Step 21734/22500 - Loss: 0.02745905891060829, Accuracy: 1.0\n",
            "Step 21735/22500 - Loss: 0.026974117383360863, Accuracy: 1.0\n",
            "Step 21736/22500 - Loss: 0.17487415671348572, Accuracy: 0.875\n",
            "Step 21737/22500 - Loss: 0.21984978020191193, Accuracy: 0.875\n",
            "Step 21738/22500 - Loss: 0.0036056216340512037, Accuracy: 1.0\n",
            "Step 21739/22500 - Loss: 0.07458039373159409, Accuracy: 1.0\n",
            "Step 21740/22500 - Loss: 0.028144976124167442, Accuracy: 1.0\n",
            "Step 21741/22500 - Loss: 0.05175421014428139, Accuracy: 1.0\n",
            "Step 21742/22500 - Loss: 0.03164311498403549, Accuracy: 1.0\n",
            "Step 21743/22500 - Loss: 0.03782443329691887, Accuracy: 1.0\n",
            "Step 21744/22500 - Loss: 0.15694285929203033, Accuracy: 0.875\n",
            "Step 21745/22500 - Loss: 0.014643345028162003, Accuracy: 1.0\n",
            "Step 21746/22500 - Loss: 0.054567813873291016, Accuracy: 1.0\n",
            "Step 21747/22500 - Loss: 0.3074631690979004, Accuracy: 0.875\n",
            "Step 21748/22500 - Loss: 0.006943278480321169, Accuracy: 1.0\n",
            "Step 21749/22500 - Loss: 0.04812599718570709, Accuracy: 1.0\n",
            "Step 21750/22500 - Loss: 0.03043001890182495, Accuracy: 1.0\n",
            "Step 21751/22500 - Loss: 0.03633071854710579, Accuracy: 1.0\n",
            "Step 21752/22500 - Loss: 0.016682367771863937, Accuracy: 1.0\n",
            "Step 21753/22500 - Loss: 0.00909794308245182, Accuracy: 1.0\n",
            "Step 21754/22500 - Loss: 0.08183892071247101, Accuracy: 1.0\n",
            "Step 21755/22500 - Loss: 0.021586501970887184, Accuracy: 1.0\n",
            "Step 21756/22500 - Loss: 0.07609216868877411, Accuracy: 1.0\n",
            "Step 21757/22500 - Loss: 0.010007170960307121, Accuracy: 1.0\n",
            "Step 21758/22500 - Loss: 0.021948833018541336, Accuracy: 1.0\n",
            "Step 21759/22500 - Loss: 0.013100329786539078, Accuracy: 1.0\n",
            "Step 21760/22500 - Loss: 0.6243261694908142, Accuracy: 0.875\n",
            "Step 21761/22500 - Loss: 0.025954609736800194, Accuracy: 1.0\n",
            "Step 21762/22500 - Loss: 0.08023694902658463, Accuracy: 1.0\n",
            "Step 21763/22500 - Loss: 0.1335674524307251, Accuracy: 0.875\n",
            "Step 21764/22500 - Loss: 0.015208982862532139, Accuracy: 1.0\n",
            "Step 21765/22500 - Loss: 0.008382716216146946, Accuracy: 1.0\n",
            "Step 21766/22500 - Loss: 0.06085937097668648, Accuracy: 1.0\n",
            "Step 21767/22500 - Loss: 0.007983513176441193, Accuracy: 1.0\n",
            "Step 21768/22500 - Loss: 0.2745301425457001, Accuracy: 0.875\n",
            "Step 21769/22500 - Loss: 0.07633046805858612, Accuracy: 1.0\n",
            "Step 21770/22500 - Loss: 0.014375783503055573, Accuracy: 1.0\n",
            "Step 21771/22500 - Loss: 0.47967687249183655, Accuracy: 0.875\n",
            "Step 21772/22500 - Loss: 0.5137019753456116, Accuracy: 0.75\n",
            "Step 21773/22500 - Loss: 0.008327099494636059, Accuracy: 1.0\n",
            "Step 21774/22500 - Loss: 0.30033594369888306, Accuracy: 0.875\n",
            "Step 21775/22500 - Loss: 0.012856918387115002, Accuracy: 1.0\n",
            "Step 21776/22500 - Loss: 0.0055246190167963505, Accuracy: 1.0\n",
            "Step 21777/22500 - Loss: 0.03522017225623131, Accuracy: 1.0\n",
            "Step 21778/22500 - Loss: 0.024422109127044678, Accuracy: 1.0\n",
            "Step 21779/22500 - Loss: 0.04271438717842102, Accuracy: 1.0\n",
            "Step 21780/22500 - Loss: 0.14361999928951263, Accuracy: 1.0\n",
            "Step 21781/22500 - Loss: 0.04362405836582184, Accuracy: 1.0\n",
            "Step 21782/22500 - Loss: 0.29825854301452637, Accuracy: 0.875\n",
            "Step 21783/22500 - Loss: 0.05867897719144821, Accuracy: 1.0\n",
            "Step 21784/22500 - Loss: 0.027670549228787422, Accuracy: 1.0\n",
            "Step 21785/22500 - Loss: 0.019873030483722687, Accuracy: 1.0\n",
            "Step 21786/22500 - Loss: 0.17491260170936584, Accuracy: 0.875\n",
            "Step 21787/22500 - Loss: 0.24760112166404724, Accuracy: 0.875\n",
            "Step 21788/22500 - Loss: 0.08608756959438324, Accuracy: 1.0\n",
            "Step 21789/22500 - Loss: 0.07036054134368896, Accuracy: 1.0\n",
            "Step 21790/22500 - Loss: 0.009618408046662807, Accuracy: 1.0\n",
            "Step 21791/22500 - Loss: 0.08390150219202042, Accuracy: 1.0\n",
            "Step 21792/22500 - Loss: 0.19572485983371735, Accuracy: 1.0\n",
            "Step 21793/22500 - Loss: 0.06201600283384323, Accuracy: 1.0\n",
            "Step 21794/22500 - Loss: 0.04888349026441574, Accuracy: 1.0\n",
            "Step 21795/22500 - Loss: 0.3247179687023163, Accuracy: 0.875\n",
            "Step 21796/22500 - Loss: 0.027521567419171333, Accuracy: 1.0\n",
            "Step 21797/22500 - Loss: 0.030299104750156403, Accuracy: 1.0\n",
            "Step 21798/22500 - Loss: 0.2821653485298157, Accuracy: 0.875\n",
            "Step 21799/22500 - Loss: 0.10584341734647751, Accuracy: 0.875\n",
            "Step 21800/22500 - Loss: 0.02076982893049717, Accuracy: 1.0\n",
            "Step 21801/22500 - Loss: 0.16755744814872742, Accuracy: 0.875\n",
            "Step 21802/22500 - Loss: 0.057690639048814774, Accuracy: 1.0\n",
            "Step 21803/22500 - Loss: 0.007479995489120483, Accuracy: 1.0\n",
            "Step 21804/22500 - Loss: 0.01054628286510706, Accuracy: 1.0\n",
            "Step 21805/22500 - Loss: 0.16951796412467957, Accuracy: 0.875\n",
            "Step 21806/22500 - Loss: 0.08251044154167175, Accuracy: 1.0\n",
            "Step 21807/22500 - Loss: 0.02871536649763584, Accuracy: 1.0\n",
            "Step 21808/22500 - Loss: 0.04866599664092064, Accuracy: 1.0\n",
            "Step 21809/22500 - Loss: 0.016889534890651703, Accuracy: 1.0\n",
            "Step 21810/22500 - Loss: 0.05640241876244545, Accuracy: 1.0\n",
            "Step 21811/22500 - Loss: 0.004303295630961657, Accuracy: 1.0\n",
            "Step 21812/22500 - Loss: 0.05150003358721733, Accuracy: 1.0\n",
            "Step 21813/22500 - Loss: 0.2854291498661041, Accuracy: 0.875\n",
            "Step 21814/22500 - Loss: 0.05088350921869278, Accuracy: 1.0\n",
            "Step 21815/22500 - Loss: 0.017212070524692535, Accuracy: 1.0\n",
            "Step 21816/22500 - Loss: 0.08026611804962158, Accuracy: 1.0\n",
            "Step 21817/22500 - Loss: 0.04790492728352547, Accuracy: 1.0\n",
            "Step 21818/22500 - Loss: 0.09674418717622757, Accuracy: 1.0\n",
            "Step 21819/22500 - Loss: 0.12742292881011963, Accuracy: 0.875\n",
            "Step 21820/22500 - Loss: 0.0419713519513607, Accuracy: 1.0\n",
            "Step 21821/22500 - Loss: 0.03554098308086395, Accuracy: 1.0\n",
            "Step 21822/22500 - Loss: 0.026715222746133804, Accuracy: 1.0\n",
            "Step 21823/22500 - Loss: 0.059009671211242676, Accuracy: 1.0\n",
            "Step 21824/22500 - Loss: 0.013698293827474117, Accuracy: 1.0\n",
            "Step 21825/22500 - Loss: 0.27810555696487427, Accuracy: 0.875\n",
            "Step 21826/22500 - Loss: 0.020812099799513817, Accuracy: 1.0\n",
            "Step 21827/22500 - Loss: 0.03027494065463543, Accuracy: 1.0\n",
            "Step 21828/22500 - Loss: 0.3859213590621948, Accuracy: 0.875\n",
            "Step 21829/22500 - Loss: 0.0049706087447702885, Accuracy: 1.0\n",
            "Step 21830/22500 - Loss: 0.021581178531050682, Accuracy: 1.0\n",
            "Step 21831/22500 - Loss: 0.043689142912626266, Accuracy: 1.0\n",
            "Step 21832/22500 - Loss: 0.3087020814418793, Accuracy: 0.875\n",
            "Step 21833/22500 - Loss: 0.40980908274650574, Accuracy: 0.875\n",
            "Step 21834/22500 - Loss: 0.04696514457464218, Accuracy: 1.0\n",
            "Step 21835/22500 - Loss: 0.04064606875181198, Accuracy: 1.0\n",
            "Step 21836/22500 - Loss: 0.020946070551872253, Accuracy: 1.0\n",
            "Step 21837/22500 - Loss: 0.389804482460022, Accuracy: 0.875\n",
            "Step 21838/22500 - Loss: 0.03886721655726433, Accuracy: 1.0\n",
            "Step 21839/22500 - Loss: 0.2517746388912201, Accuracy: 0.875\n",
            "Step 21840/22500 - Loss: 0.013088698498904705, Accuracy: 1.0\n",
            "Step 21841/22500 - Loss: 0.013669737614691257, Accuracy: 1.0\n",
            "Step 21842/22500 - Loss: 0.07465285807847977, Accuracy: 1.0\n",
            "Step 21843/22500 - Loss: 0.017082389444112778, Accuracy: 1.0\n",
            "Step 21844/22500 - Loss: 0.4322924017906189, Accuracy: 0.75\n",
            "Step 21845/22500 - Loss: 0.020360467955470085, Accuracy: 1.0\n",
            "Step 21846/22500 - Loss: 0.2528636157512665, Accuracy: 0.875\n",
            "Step 21847/22500 - Loss: 0.0767747089266777, Accuracy: 1.0\n",
            "Step 21848/22500 - Loss: 0.054181091487407684, Accuracy: 1.0\n",
            "Step 21849/22500 - Loss: 0.32539838552474976, Accuracy: 0.75\n",
            "Step 21850/22500 - Loss: 0.13100013136863708, Accuracy: 1.0\n",
            "Step 21851/22500 - Loss: 0.009365525096654892, Accuracy: 1.0\n",
            "Step 21852/22500 - Loss: 0.007890054024755955, Accuracy: 1.0\n",
            "Step 21853/22500 - Loss: 0.034656327217817307, Accuracy: 1.0\n",
            "Step 21854/22500 - Loss: 0.0695018470287323, Accuracy: 1.0\n",
            "Step 21855/22500 - Loss: 0.024025024846196175, Accuracy: 1.0\n",
            "Step 21856/22500 - Loss: 0.13309058547019958, Accuracy: 0.875\n",
            "Step 21857/22500 - Loss: 0.029453421011567116, Accuracy: 1.0\n",
            "Step 21858/22500 - Loss: 0.0461902879178524, Accuracy: 1.0\n",
            "Step 21859/22500 - Loss: 0.02030397765338421, Accuracy: 1.0\n",
            "Step 21860/22500 - Loss: 0.09846699982881546, Accuracy: 1.0\n",
            "Step 21861/22500 - Loss: 0.16513517498970032, Accuracy: 0.875\n",
            "Step 21862/22500 - Loss: 0.015088394284248352, Accuracy: 1.0\n",
            "Step 21863/22500 - Loss: 0.44225022196769714, Accuracy: 0.875\n",
            "Step 21864/22500 - Loss: 0.020220626145601273, Accuracy: 1.0\n",
            "Step 21865/22500 - Loss: 0.04755561426281929, Accuracy: 1.0\n",
            "Step 21866/22500 - Loss: 0.12065831571817398, Accuracy: 1.0\n",
            "Step 21867/22500 - Loss: 0.413436621427536, Accuracy: 0.875\n",
            "Step 21868/22500 - Loss: 0.41553446650505066, Accuracy: 0.75\n",
            "Step 21869/22500 - Loss: 0.030620958656072617, Accuracy: 1.0\n",
            "Step 21870/22500 - Loss: 0.017402149736881256, Accuracy: 1.0\n",
            "Step 21871/22500 - Loss: 0.23165524005889893, Accuracy: 0.875\n",
            "Step 21872/22500 - Loss: 0.03860951587557793, Accuracy: 1.0\n",
            "Step 21873/22500 - Loss: 0.06576330214738846, Accuracy: 1.0\n",
            "Step 21874/22500 - Loss: 0.003637762973085046, Accuracy: 1.0\n",
            "Step 21875/22500 - Loss: 0.06994661688804626, Accuracy: 1.0\n",
            "Step 21876/22500 - Loss: 0.06414981186389923, Accuracy: 1.0\n",
            "Step 21877/22500 - Loss: 0.03433317691087723, Accuracy: 1.0\n",
            "Step 21878/22500 - Loss: 0.18570032715797424, Accuracy: 0.875\n",
            "Step 21879/22500 - Loss: 0.034080520272254944, Accuracy: 1.0\n",
            "Step 21880/22500 - Loss: 0.0017370266141369939, Accuracy: 1.0\n",
            "Step 21881/22500 - Loss: 0.03449656441807747, Accuracy: 1.0\n",
            "Step 21882/22500 - Loss: 0.07571778446435928, Accuracy: 1.0\n",
            "Step 21883/22500 - Loss: 0.14108631014823914, Accuracy: 0.875\n",
            "Step 21884/22500 - Loss: 0.39533957839012146, Accuracy: 0.875\n",
            "Step 21885/22500 - Loss: 0.09267859905958176, Accuracy: 1.0\n",
            "Step 21886/22500 - Loss: 0.19876688718795776, Accuracy: 0.875\n",
            "Step 21887/22500 - Loss: 0.08905910700559616, Accuracy: 1.0\n",
            "Step 21888/22500 - Loss: 0.3354651927947998, Accuracy: 0.75\n",
            "Step 21889/22500 - Loss: 0.020518530160188675, Accuracy: 1.0\n",
            "Step 21890/22500 - Loss: 0.01860913820564747, Accuracy: 1.0\n",
            "Step 21891/22500 - Loss: 0.17173460125923157, Accuracy: 0.875\n",
            "Step 21892/22500 - Loss: 0.01906253583729267, Accuracy: 1.0\n",
            "Step 21893/22500 - Loss: 0.18056657910346985, Accuracy: 0.875\n",
            "Step 21894/22500 - Loss: 0.007589478045701981, Accuracy: 1.0\n",
            "Step 21895/22500 - Loss: 0.034477349370718, Accuracy: 1.0\n",
            "Step 21896/22500 - Loss: 0.06828587502241135, Accuracy: 1.0\n",
            "Step 21897/22500 - Loss: 0.2709578573703766, Accuracy: 0.875\n",
            "Step 21898/22500 - Loss: 0.015238629654049873, Accuracy: 1.0\n",
            "Step 21899/22500 - Loss: 0.18986178934574127, Accuracy: 0.875\n",
            "Step 21900/22500 - Loss: 0.03881732001900673, Accuracy: 1.0\n",
            "Step 21901/22500 - Loss: 0.187069371342659, Accuracy: 0.875\n",
            "Step 21902/22500 - Loss: 0.1742018163204193, Accuracy: 0.875\n",
            "Step 21903/22500 - Loss: 0.04272162914276123, Accuracy: 1.0\n",
            "Step 21904/22500 - Loss: 0.19048134982585907, Accuracy: 0.875\n",
            "Step 21905/22500 - Loss: 0.0737389549612999, Accuracy: 1.0\n",
            "Step 21906/22500 - Loss: 0.17569342255592346, Accuracy: 0.875\n",
            "Step 21907/22500 - Loss: 0.028025077655911446, Accuracy: 1.0\n",
            "Step 21908/22500 - Loss: 0.03344353660941124, Accuracy: 1.0\n",
            "Step 21909/22500 - Loss: 0.013058006763458252, Accuracy: 1.0\n",
            "Step 21910/22500 - Loss: 0.04049753025174141, Accuracy: 1.0\n",
            "Step 21911/22500 - Loss: 0.03294166550040245, Accuracy: 1.0\n",
            "Step 21912/22500 - Loss: 0.11118258535861969, Accuracy: 1.0\n",
            "Step 21913/22500 - Loss: 0.5113259553909302, Accuracy: 0.875\n",
            "Step 21914/22500 - Loss: 0.06964690238237381, Accuracy: 1.0\n",
            "Step 21915/22500 - Loss: 0.01681872457265854, Accuracy: 1.0\n",
            "Step 21916/22500 - Loss: 0.1264028698205948, Accuracy: 0.875\n",
            "Step 21917/22500 - Loss: 0.06251883506774902, Accuracy: 1.0\n",
            "Step 21918/22500 - Loss: 0.1810552477836609, Accuracy: 0.875\n",
            "Step 21919/22500 - Loss: 0.10198096930980682, Accuracy: 1.0\n",
            "Step 21920/22500 - Loss: 0.019286544993519783, Accuracy: 1.0\n",
            "Step 21921/22500 - Loss: 0.009504409506917, Accuracy: 1.0\n",
            "Step 21922/22500 - Loss: 0.1618395745754242, Accuracy: 0.875\n",
            "Step 21923/22500 - Loss: 0.04453791305422783, Accuracy: 1.0\n",
            "Step 21924/22500 - Loss: 0.676981508731842, Accuracy: 0.75\n",
            "Step 21925/22500 - Loss: 0.04531072825193405, Accuracy: 1.0\n",
            "Step 21926/22500 - Loss: 0.028664765879511833, Accuracy: 1.0\n",
            "Step 21927/22500 - Loss: 0.10197704285383224, Accuracy: 1.0\n",
            "Step 21928/22500 - Loss: 0.06035304069519043, Accuracy: 1.0\n",
            "Step 21929/22500 - Loss: 0.2201945185661316, Accuracy: 0.875\n",
            "Step 21930/22500 - Loss: 0.00544746732339263, Accuracy: 1.0\n",
            "Step 21931/22500 - Loss: 0.0566546767950058, Accuracy: 1.0\n",
            "Step 21932/22500 - Loss: 0.08475210517644882, Accuracy: 1.0\n",
            "Step 21933/22500 - Loss: 0.013523361645638943, Accuracy: 1.0\n",
            "Step 21934/22500 - Loss: 0.04036516323685646, Accuracy: 1.0\n",
            "Step 21935/22500 - Loss: 0.06517958641052246, Accuracy: 1.0\n",
            "Step 21936/22500 - Loss: 0.12470373511314392, Accuracy: 1.0\n",
            "Step 21937/22500 - Loss: 0.1360217183828354, Accuracy: 1.0\n",
            "Step 21938/22500 - Loss: 0.006298122461885214, Accuracy: 1.0\n",
            "Step 21939/22500 - Loss: 0.03176267817616463, Accuracy: 1.0\n",
            "Step 21940/22500 - Loss: 0.053788330405950546, Accuracy: 1.0\n",
            "Step 21941/22500 - Loss: 0.27987951040267944, Accuracy: 0.875\n",
            "Step 21942/22500 - Loss: 0.007545038126409054, Accuracy: 1.0\n",
            "Step 21943/22500 - Loss: 0.03960738331079483, Accuracy: 1.0\n",
            "Step 21944/22500 - Loss: 0.15175361931324005, Accuracy: 0.875\n",
            "Step 21945/22500 - Loss: 0.02972964197397232, Accuracy: 1.0\n",
            "Step 21946/22500 - Loss: 0.31229862570762634, Accuracy: 0.875\n",
            "Step 21947/22500 - Loss: 0.15111710131168365, Accuracy: 0.875\n",
            "Step 21948/22500 - Loss: 0.03291800618171692, Accuracy: 1.0\n",
            "Step 21949/22500 - Loss: 0.2134108692407608, Accuracy: 0.875\n",
            "Step 21950/22500 - Loss: 0.35145124793052673, Accuracy: 0.875\n",
            "Step 21951/22500 - Loss: 0.2536884546279907, Accuracy: 0.875\n",
            "Step 21952/22500 - Loss: 0.23360957205295563, Accuracy: 0.875\n",
            "Step 21953/22500 - Loss: 0.09981261193752289, Accuracy: 1.0\n",
            "Step 21954/22500 - Loss: 0.058382801711559296, Accuracy: 1.0\n",
            "Step 21955/22500 - Loss: 0.06701762229204178, Accuracy: 1.0\n",
            "Step 21956/22500 - Loss: 0.07453363388776779, Accuracy: 1.0\n",
            "Step 21957/22500 - Loss: 0.007034203037619591, Accuracy: 1.0\n",
            "Step 21958/22500 - Loss: 0.02066844142973423, Accuracy: 1.0\n",
            "Step 21959/22500 - Loss: 0.030140826478600502, Accuracy: 1.0\n",
            "Step 21960/22500 - Loss: 0.20599760115146637, Accuracy: 0.875\n",
            "Step 21961/22500 - Loss: 0.0684693306684494, Accuracy: 1.0\n",
            "Step 21962/22500 - Loss: 0.023247187957167625, Accuracy: 1.0\n",
            "Step 21963/22500 - Loss: 0.1353069543838501, Accuracy: 0.875\n",
            "Step 21964/22500 - Loss: 0.5103461742401123, Accuracy: 0.875\n",
            "Step 21965/22500 - Loss: 0.02557780221104622, Accuracy: 1.0\n",
            "Step 21966/22500 - Loss: 0.02403375320136547, Accuracy: 1.0\n",
            "Step 21967/22500 - Loss: 0.01226445659995079, Accuracy: 1.0\n",
            "Step 21968/22500 - Loss: 0.024088945239782333, Accuracy: 1.0\n",
            "Step 21969/22500 - Loss: 0.01264095026999712, Accuracy: 1.0\n",
            "Step 21970/22500 - Loss: 0.010026243515312672, Accuracy: 1.0\n",
            "Step 21971/22500 - Loss: 0.28509512543678284, Accuracy: 0.875\n",
            "Step 21972/22500 - Loss: 0.006486641708761454, Accuracy: 1.0\n",
            "Step 21973/22500 - Loss: 0.019888930022716522, Accuracy: 1.0\n",
            "Step 21974/22500 - Loss: 0.029608052223920822, Accuracy: 1.0\n",
            "Step 21975/22500 - Loss: 0.008479288779199123, Accuracy: 1.0\n",
            "Step 21976/22500 - Loss: 0.29827627539634705, Accuracy: 0.875\n",
            "Step 21977/22500 - Loss: 0.027031883597373962, Accuracy: 1.0\n",
            "Step 21978/22500 - Loss: 0.20068340003490448, Accuracy: 0.875\n",
            "Step 21979/22500 - Loss: 0.019323129206895828, Accuracy: 1.0\n",
            "Step 21980/22500 - Loss: 0.004306480288505554, Accuracy: 1.0\n",
            "Step 21981/22500 - Loss: 0.13084661960601807, Accuracy: 0.875\n",
            "Step 21982/22500 - Loss: 0.03523669019341469, Accuracy: 1.0\n",
            "Step 21983/22500 - Loss: 0.04169733077287674, Accuracy: 1.0\n",
            "Step 21984/22500 - Loss: 0.048681773245334625, Accuracy: 1.0\n",
            "Step 21985/22500 - Loss: 0.019408047199249268, Accuracy: 1.0\n",
            "Step 21986/22500 - Loss: 0.040832698345184326, Accuracy: 1.0\n",
            "Step 21987/22500 - Loss: 0.018427301198244095, Accuracy: 1.0\n",
            "Step 21988/22500 - Loss: 0.02585790678858757, Accuracy: 1.0\n",
            "Step 21989/22500 - Loss: 0.21361589431762695, Accuracy: 0.875\n",
            "Step 21990/22500 - Loss: 0.03892705217003822, Accuracy: 1.0\n",
            "Step 21991/22500 - Loss: 0.13309530913829803, Accuracy: 0.875\n",
            "Step 21992/22500 - Loss: 0.1029915139079094, Accuracy: 1.0\n",
            "Step 21993/22500 - Loss: 0.00521526113152504, Accuracy: 1.0\n",
            "Step 21994/22500 - Loss: 0.26651591062545776, Accuracy: 0.875\n",
            "Step 21995/22500 - Loss: 0.20474116504192352, Accuracy: 0.875\n",
            "Step 21996/22500 - Loss: 0.11970344930887222, Accuracy: 1.0\n",
            "Step 21997/22500 - Loss: 0.0384761281311512, Accuracy: 1.0\n",
            "Step 21998/22500 - Loss: 0.023275144398212433, Accuracy: 1.0\n",
            "Step 21999/22500 - Loss: 0.011393122375011444, Accuracy: 1.0\n",
            "Step 22000/22500 - Loss: 0.05777154862880707, Accuracy: 1.0\n",
            "Step 22001/22500 - Loss: 0.2174438089132309, Accuracy: 0.875\n",
            "Step 22002/22500 - Loss: 0.02524429000914097, Accuracy: 1.0\n",
            "Step 22003/22500 - Loss: 0.02916320227086544, Accuracy: 1.0\n",
            "Step 22004/22500 - Loss: 0.03893499821424484, Accuracy: 1.0\n",
            "Step 22005/22500 - Loss: 0.04753555729985237, Accuracy: 1.0\n",
            "Step 22006/22500 - Loss: 0.09696604311466217, Accuracy: 1.0\n",
            "Step 22007/22500 - Loss: 0.21783015131950378, Accuracy: 0.875\n",
            "Step 22008/22500 - Loss: 0.900776743888855, Accuracy: 0.75\n",
            "Step 22009/22500 - Loss: 0.6491977572441101, Accuracy: 0.875\n",
            "Step 22010/22500 - Loss: 0.010163385421037674, Accuracy: 1.0\n",
            "Step 22011/22500 - Loss: 0.025851016864180565, Accuracy: 1.0\n",
            "Step 22012/22500 - Loss: 0.050353821367025375, Accuracy: 1.0\n",
            "Step 22013/22500 - Loss: 0.27025264501571655, Accuracy: 0.875\n",
            "Step 22014/22500 - Loss: 0.1611049771308899, Accuracy: 0.875\n",
            "Step 22015/22500 - Loss: 0.006348843686282635, Accuracy: 1.0\n",
            "Step 22016/22500 - Loss: 0.06372642517089844, Accuracy: 1.0\n",
            "Step 22017/22500 - Loss: 0.007943679578602314, Accuracy: 1.0\n",
            "Step 22018/22500 - Loss: 0.07460729777812958, Accuracy: 1.0\n",
            "Step 22019/22500 - Loss: 0.0028312280774116516, Accuracy: 1.0\n",
            "Step 22020/22500 - Loss: 0.03405849263072014, Accuracy: 1.0\n",
            "Step 22021/22500 - Loss: 0.03413690999150276, Accuracy: 1.0\n",
            "Step 22022/22500 - Loss: 0.21514514088630676, Accuracy: 0.875\n",
            "Step 22023/22500 - Loss: 0.1180366799235344, Accuracy: 1.0\n",
            "Step 22024/22500 - Loss: 0.06797744333744049, Accuracy: 1.0\n",
            "Step 22025/22500 - Loss: 0.13133543729782104, Accuracy: 0.875\n",
            "Step 22026/22500 - Loss: 0.026819827035069466, Accuracy: 1.0\n",
            "Step 22027/22500 - Loss: 0.029606780037283897, Accuracy: 1.0\n",
            "Step 22028/22500 - Loss: 0.048093218356370926, Accuracy: 1.0\n",
            "Step 22029/22500 - Loss: 0.004077646415680647, Accuracy: 1.0\n",
            "Step 22030/22500 - Loss: 0.021072201430797577, Accuracy: 1.0\n",
            "Step 22031/22500 - Loss: 0.06062097102403641, Accuracy: 1.0\n",
            "Step 22032/22500 - Loss: 0.25221824645996094, Accuracy: 0.875\n",
            "Step 22033/22500 - Loss: 0.2568652033805847, Accuracy: 0.875\n",
            "Step 22034/22500 - Loss: 0.3583241403102875, Accuracy: 0.875\n",
            "Step 22035/22500 - Loss: 0.01441210601478815, Accuracy: 1.0\n",
            "Step 22036/22500 - Loss: 0.11687268316745758, Accuracy: 1.0\n",
            "Step 22037/22500 - Loss: 0.12161349505186081, Accuracy: 0.875\n",
            "Step 22038/22500 - Loss: 0.04445664584636688, Accuracy: 1.0\n",
            "Step 22039/22500 - Loss: 0.2708060145378113, Accuracy: 0.875\n",
            "Step 22040/22500 - Loss: 0.0043912469409406185, Accuracy: 1.0\n",
            "Step 22041/22500 - Loss: 0.09160448610782623, Accuracy: 1.0\n",
            "Step 22042/22500 - Loss: 0.009642515331506729, Accuracy: 1.0\n",
            "Step 22043/22500 - Loss: 0.3019345998764038, Accuracy: 0.875\n",
            "Step 22044/22500 - Loss: 0.03458767384290695, Accuracy: 1.0\n",
            "Step 22045/22500 - Loss: 0.059431519359350204, Accuracy: 1.0\n",
            "Step 22046/22500 - Loss: 0.020366616547107697, Accuracy: 1.0\n",
            "Step 22047/22500 - Loss: 0.4440487325191498, Accuracy: 0.625\n",
            "Step 22048/22500 - Loss: 0.42282330989837646, Accuracy: 0.875\n",
            "Step 22049/22500 - Loss: 0.20981092751026154, Accuracy: 0.875\n",
            "Step 22050/22500 - Loss: 0.3396869897842407, Accuracy: 0.875\n",
            "Step 22051/22500 - Loss: 0.2667945921421051, Accuracy: 0.875\n",
            "Step 22052/22500 - Loss: 0.0028091773856431246, Accuracy: 1.0\n",
            "Step 22053/22500 - Loss: 0.3723890781402588, Accuracy: 0.875\n",
            "Step 22054/22500 - Loss: 0.4154040217399597, Accuracy: 0.875\n",
            "Step 22055/22500 - Loss: 0.3464081287384033, Accuracy: 0.875\n",
            "Step 22056/22500 - Loss: 0.10236383229494095, Accuracy: 1.0\n",
            "Step 22057/22500 - Loss: 0.024606484919786453, Accuracy: 1.0\n",
            "Step 22058/22500 - Loss: 0.2001527100801468, Accuracy: 0.875\n",
            "Step 22059/22500 - Loss: 0.11361755430698395, Accuracy: 0.875\n",
            "Step 22060/22500 - Loss: 0.07961880415678024, Accuracy: 1.0\n",
            "Step 22061/22500 - Loss: 0.23261019587516785, Accuracy: 0.875\n",
            "Step 22062/22500 - Loss: 0.02927987277507782, Accuracy: 1.0\n",
            "Step 22063/22500 - Loss: 0.022642001509666443, Accuracy: 1.0\n",
            "Step 22064/22500 - Loss: 0.0031182996463030577, Accuracy: 1.0\n",
            "Step 22065/22500 - Loss: 0.4915389120578766, Accuracy: 0.875\n",
            "Step 22066/22500 - Loss: 0.2654253840446472, Accuracy: 0.875\n",
            "Step 22067/22500 - Loss: 0.05913747102022171, Accuracy: 1.0\n",
            "Step 22068/22500 - Loss: 0.13047364354133606, Accuracy: 0.875\n",
            "Step 22069/22500 - Loss: 0.004085002467036247, Accuracy: 1.0\n",
            "Step 22070/22500 - Loss: 0.019289270043373108, Accuracy: 1.0\n",
            "Step 22071/22500 - Loss: 0.006317062769085169, Accuracy: 1.0\n",
            "Step 22072/22500 - Loss: 0.10080209374427795, Accuracy: 0.875\n",
            "Step 22073/22500 - Loss: 0.08247692883014679, Accuracy: 1.0\n",
            "Step 22074/22500 - Loss: 0.0606050118803978, Accuracy: 1.0\n",
            "Step 22075/22500 - Loss: 0.11111798882484436, Accuracy: 0.875\n",
            "Step 22076/22500 - Loss: 0.09304361045360565, Accuracy: 1.0\n",
            "Step 22077/22500 - Loss: 0.04228300601243973, Accuracy: 1.0\n",
            "Step 22078/22500 - Loss: 0.1966102570295334, Accuracy: 0.875\n",
            "Step 22079/22500 - Loss: 0.2534574270248413, Accuracy: 0.875\n",
            "Step 22080/22500 - Loss: 0.12146322429180145, Accuracy: 1.0\n",
            "Step 22081/22500 - Loss: 0.061205144971609116, Accuracy: 1.0\n",
            "Step 22082/22500 - Loss: 0.5247960686683655, Accuracy: 0.875\n",
            "Step 22083/22500 - Loss: 0.04700703173875809, Accuracy: 1.0\n",
            "Step 22084/22500 - Loss: 0.021105119958519936, Accuracy: 1.0\n",
            "Step 22085/22500 - Loss: 0.1962209790945053, Accuracy: 0.875\n",
            "Step 22086/22500 - Loss: 0.020434223115444183, Accuracy: 1.0\n",
            "Step 22087/22500 - Loss: 0.06115599721670151, Accuracy: 1.0\n",
            "Step 22088/22500 - Loss: 0.03564661741256714, Accuracy: 1.0\n",
            "Step 22089/22500 - Loss: 0.008038242347538471, Accuracy: 1.0\n",
            "Step 22090/22500 - Loss: 0.0873071476817131, Accuracy: 1.0\n",
            "Step 22091/22500 - Loss: 0.23475216329097748, Accuracy: 0.875\n",
            "Step 22092/22500 - Loss: 0.022610971704125404, Accuracy: 1.0\n",
            "Step 22093/22500 - Loss: 0.15237092971801758, Accuracy: 0.875\n",
            "Step 22094/22500 - Loss: 0.005997456610202789, Accuracy: 1.0\n",
            "Step 22095/22500 - Loss: 0.11699430644512177, Accuracy: 0.875\n",
            "Step 22096/22500 - Loss: 0.01571839302778244, Accuracy: 1.0\n",
            "Step 22097/22500 - Loss: 0.1554851233959198, Accuracy: 0.875\n",
            "Step 22098/22500 - Loss: 0.006446732208132744, Accuracy: 1.0\n",
            "Step 22099/22500 - Loss: 0.036185212433338165, Accuracy: 1.0\n",
            "Step 22100/22500 - Loss: 0.025984739884734154, Accuracy: 1.0\n",
            "Step 22101/22500 - Loss: 0.03847318887710571, Accuracy: 1.0\n",
            "Step 22102/22500 - Loss: 0.0031450907699763775, Accuracy: 1.0\n",
            "Step 22103/22500 - Loss: 0.22837863862514496, Accuracy: 0.875\n",
            "Step 22104/22500 - Loss: 0.4619077444076538, Accuracy: 0.75\n",
            "Step 22105/22500 - Loss: 0.42451027035713196, Accuracy: 0.75\n",
            "Step 22106/22500 - Loss: 0.03208887204527855, Accuracy: 1.0\n",
            "Step 22107/22500 - Loss: 0.09899383038282394, Accuracy: 1.0\n",
            "Step 22108/22500 - Loss: 0.030920805409550667, Accuracy: 1.0\n",
            "Step 22109/22500 - Loss: 0.14328628778457642, Accuracy: 1.0\n",
            "Step 22110/22500 - Loss: 0.32953694462776184, Accuracy: 0.875\n",
            "Step 22111/22500 - Loss: 0.1734509915113449, Accuracy: 0.875\n",
            "Step 22112/22500 - Loss: 0.02747233770787716, Accuracy: 1.0\n",
            "Step 22113/22500 - Loss: 0.04656921327114105, Accuracy: 1.0\n",
            "Step 22114/22500 - Loss: 0.01201601605862379, Accuracy: 1.0\n",
            "Step 22115/22500 - Loss: 0.021263862028717995, Accuracy: 1.0\n",
            "Step 22116/22500 - Loss: 0.8479198813438416, Accuracy: 0.75\n",
            "Step 22117/22500 - Loss: 0.015451912768185139, Accuracy: 1.0\n",
            "Step 22118/22500 - Loss: 0.04557174816727638, Accuracy: 1.0\n",
            "Step 22119/22500 - Loss: 0.42782390117645264, Accuracy: 0.75\n",
            "Step 22120/22500 - Loss: 0.16440555453300476, Accuracy: 0.875\n",
            "Step 22121/22500 - Loss: 0.03029083088040352, Accuracy: 1.0\n",
            "Step 22122/22500 - Loss: 0.008097765035927296, Accuracy: 1.0\n",
            "Step 22123/22500 - Loss: 0.08280456066131592, Accuracy: 1.0\n",
            "Step 22124/22500 - Loss: 0.2762225270271301, Accuracy: 0.875\n",
            "Step 22125/22500 - Loss: 0.019177591428160667, Accuracy: 1.0\n",
            "Step 22126/22500 - Loss: 0.14506900310516357, Accuracy: 1.0\n",
            "Step 22127/22500 - Loss: 0.5570213794708252, Accuracy: 0.875\n",
            "Step 22128/22500 - Loss: 0.03820627182722092, Accuracy: 1.0\n",
            "Step 22129/22500 - Loss: 0.19191820919513702, Accuracy: 0.875\n",
            "Step 22130/22500 - Loss: 0.03542148321866989, Accuracy: 1.0\n",
            "Step 22131/22500 - Loss: 0.024184148758649826, Accuracy: 1.0\n",
            "Step 22132/22500 - Loss: 0.5626857280731201, Accuracy: 0.75\n",
            "Step 22133/22500 - Loss: 0.38276562094688416, Accuracy: 0.875\n",
            "Step 22134/22500 - Loss: 0.32920822501182556, Accuracy: 0.875\n",
            "Step 22135/22500 - Loss: 0.0395633764564991, Accuracy: 1.0\n",
            "Step 22136/22500 - Loss: 0.043947555124759674, Accuracy: 1.0\n",
            "Step 22137/22500 - Loss: 0.3598096966743469, Accuracy: 0.875\n",
            "Step 22138/22500 - Loss: 0.0029320288449525833, Accuracy: 1.0\n",
            "Step 22139/22500 - Loss: 0.02816721796989441, Accuracy: 1.0\n",
            "Step 22140/22500 - Loss: 0.5396579504013062, Accuracy: 0.75\n",
            "Step 22141/22500 - Loss: 0.044240180402994156, Accuracy: 1.0\n",
            "Step 22142/22500 - Loss: 0.020027704536914825, Accuracy: 1.0\n",
            "Step 22143/22500 - Loss: 0.09154009073972702, Accuracy: 1.0\n",
            "Step 22144/22500 - Loss: 0.04395584017038345, Accuracy: 1.0\n",
            "Step 22145/22500 - Loss: 0.15481719374656677, Accuracy: 0.875\n",
            "Step 22146/22500 - Loss: 0.04581625014543533, Accuracy: 1.0\n",
            "Step 22147/22500 - Loss: 0.006421895232051611, Accuracy: 1.0\n",
            "Step 22148/22500 - Loss: 0.029375486075878143, Accuracy: 1.0\n",
            "Step 22149/22500 - Loss: 0.015450552105903625, Accuracy: 1.0\n",
            "Step 22150/22500 - Loss: 0.5469198226928711, Accuracy: 0.875\n",
            "Step 22151/22500 - Loss: 0.017269235104322433, Accuracy: 1.0\n",
            "Step 22152/22500 - Loss: 0.05309677869081497, Accuracy: 1.0\n",
            "Step 22153/22500 - Loss: 0.13809794187545776, Accuracy: 1.0\n",
            "Step 22154/22500 - Loss: 0.036930520087480545, Accuracy: 1.0\n",
            "Step 22155/22500 - Loss: 0.17459118366241455, Accuracy: 1.0\n",
            "Step 22156/22500 - Loss: 0.06526792794466019, Accuracy: 1.0\n",
            "Step 22157/22500 - Loss: 0.058339111506938934, Accuracy: 1.0\n",
            "Step 22158/22500 - Loss: 0.2895984351634979, Accuracy: 0.875\n",
            "Step 22159/22500 - Loss: 0.024470217525959015, Accuracy: 1.0\n",
            "Step 22160/22500 - Loss: 0.2370324432849884, Accuracy: 0.875\n",
            "Step 22161/22500 - Loss: 0.053875114768743515, Accuracy: 1.0\n",
            "Step 22162/22500 - Loss: 0.027170347049832344, Accuracy: 1.0\n",
            "Step 22163/22500 - Loss: 0.016750670969486237, Accuracy: 1.0\n",
            "Step 22164/22500 - Loss: 0.1859360784292221, Accuracy: 0.875\n",
            "Step 22165/22500 - Loss: 0.06785399466753006, Accuracy: 1.0\n",
            "Step 22166/22500 - Loss: 0.03681560233235359, Accuracy: 1.0\n",
            "Step 22167/22500 - Loss: 0.021678727120161057, Accuracy: 1.0\n",
            "Step 22168/22500 - Loss: 0.022176677361130714, Accuracy: 1.0\n",
            "Step 22169/22500 - Loss: 0.054045431315898895, Accuracy: 1.0\n",
            "Step 22170/22500 - Loss: 0.025061583146452904, Accuracy: 1.0\n",
            "Step 22171/22500 - Loss: 0.01909826509654522, Accuracy: 1.0\n",
            "Step 22172/22500 - Loss: 0.017153797671198845, Accuracy: 1.0\n",
            "Step 22173/22500 - Loss: 0.20692139863967896, Accuracy: 0.875\n",
            "Step 22174/22500 - Loss: 0.07072111964225769, Accuracy: 1.0\n",
            "Step 22175/22500 - Loss: 0.038965869694948196, Accuracy: 1.0\n",
            "Step 22176/22500 - Loss: 0.6434955596923828, Accuracy: 0.625\n",
            "Step 22177/22500 - Loss: 0.006190749816596508, Accuracy: 1.0\n",
            "Step 22178/22500 - Loss: 0.27563509345054626, Accuracy: 0.75\n",
            "Step 22179/22500 - Loss: 0.05949592590332031, Accuracy: 1.0\n",
            "Step 22180/22500 - Loss: 0.01004549115896225, Accuracy: 1.0\n",
            "Step 22181/22500 - Loss: 0.062471531331539154, Accuracy: 1.0\n",
            "Step 22182/22500 - Loss: 0.09384061396121979, Accuracy: 1.0\n",
            "Step 22183/22500 - Loss: 0.05060343071818352, Accuracy: 1.0\n",
            "Step 22184/22500 - Loss: 0.051399532705545425, Accuracy: 1.0\n",
            "Step 22185/22500 - Loss: 0.0172031968832016, Accuracy: 1.0\n",
            "Step 22186/22500 - Loss: 0.015343721956014633, Accuracy: 1.0\n",
            "Step 22187/22500 - Loss: 0.020254457369446754, Accuracy: 1.0\n",
            "Step 22188/22500 - Loss: 0.1323329210281372, Accuracy: 1.0\n",
            "Step 22189/22500 - Loss: 0.29578205943107605, Accuracy: 0.875\n",
            "Step 22190/22500 - Loss: 0.00983407162129879, Accuracy: 1.0\n",
            "Step 22191/22500 - Loss: 0.12077037990093231, Accuracy: 1.0\n",
            "Step 22192/22500 - Loss: 0.07263781130313873, Accuracy: 1.0\n",
            "Step 22193/22500 - Loss: 0.07518162578344345, Accuracy: 1.0\n",
            "Step 22194/22500 - Loss: 0.07491322606801987, Accuracy: 1.0\n",
            "Step 22195/22500 - Loss: 0.014028975740075111, Accuracy: 1.0\n",
            "Step 22196/22500 - Loss: 0.01903468556702137, Accuracy: 1.0\n",
            "Step 22197/22500 - Loss: 0.19153307378292084, Accuracy: 0.875\n",
            "Step 22198/22500 - Loss: 0.4581869840621948, Accuracy: 0.875\n",
            "Step 22199/22500 - Loss: 0.060323067009449005, Accuracy: 1.0\n",
            "Step 22200/22500 - Loss: 0.4118357300758362, Accuracy: 0.875\n",
            "Step 22201/22500 - Loss: 0.0020762314088642597, Accuracy: 1.0\n",
            "Step 22202/22500 - Loss: 0.45601335167884827, Accuracy: 0.875\n",
            "Step 22203/22500 - Loss: 0.0671682208776474, Accuracy: 1.0\n",
            "Step 22204/22500 - Loss: 0.3617323338985443, Accuracy: 0.875\n",
            "Step 22205/22500 - Loss: 0.32057714462280273, Accuracy: 0.875\n",
            "Step 22206/22500 - Loss: 0.008439630270004272, Accuracy: 1.0\n",
            "Step 22207/22500 - Loss: 0.3654465973377228, Accuracy: 0.875\n",
            "Step 22208/22500 - Loss: 0.05771121010184288, Accuracy: 1.0\n",
            "Step 22209/22500 - Loss: 0.09120691567659378, Accuracy: 1.0\n",
            "Step 22210/22500 - Loss: 0.048535823822021484, Accuracy: 1.0\n",
            "Step 22211/22500 - Loss: 0.018588609993457794, Accuracy: 1.0\n",
            "Step 22212/22500 - Loss: 0.032202333211898804, Accuracy: 1.0\n",
            "Step 22213/22500 - Loss: 0.15296341478824615, Accuracy: 0.875\n",
            "Step 22214/22500 - Loss: 0.248880997300148, Accuracy: 0.875\n",
            "Step 22215/22500 - Loss: 0.036543842405080795, Accuracy: 1.0\n",
            "Step 22216/22500 - Loss: 0.004260992631316185, Accuracy: 1.0\n",
            "Step 22217/22500 - Loss: 0.0036349932197481394, Accuracy: 1.0\n",
            "Step 22218/22500 - Loss: 0.2821652591228485, Accuracy: 0.875\n",
            "Step 22219/22500 - Loss: 0.08319780975580215, Accuracy: 1.0\n",
            "Step 22220/22500 - Loss: 0.31327685713768005, Accuracy: 0.875\n",
            "Step 22221/22500 - Loss: 0.1674184799194336, Accuracy: 0.875\n",
            "Step 22222/22500 - Loss: 0.060792576521635056, Accuracy: 1.0\n",
            "Step 22223/22500 - Loss: 0.034959860146045685, Accuracy: 1.0\n",
            "Step 22224/22500 - Loss: 0.41457656025886536, Accuracy: 0.75\n",
            "Step 22225/22500 - Loss: 0.029186584055423737, Accuracy: 1.0\n",
            "Step 22226/22500 - Loss: 0.39339473843574524, Accuracy: 0.75\n",
            "Step 22227/22500 - Loss: 0.029399646446108818, Accuracy: 1.0\n",
            "Step 22228/22500 - Loss: 0.017611803486943245, Accuracy: 1.0\n",
            "Step 22229/22500 - Loss: 0.031405575573444366, Accuracy: 1.0\n",
            "Step 22230/22500 - Loss: 0.013835448771715164, Accuracy: 1.0\n",
            "Step 22231/22500 - Loss: 0.03547387197613716, Accuracy: 1.0\n",
            "Step 22232/22500 - Loss: 0.5084783434867859, Accuracy: 0.75\n",
            "Step 22233/22500 - Loss: 0.1700904667377472, Accuracy: 0.875\n",
            "Step 22234/22500 - Loss: 0.09696736186742783, Accuracy: 0.875\n",
            "Step 22235/22500 - Loss: 0.06618303805589676, Accuracy: 1.0\n",
            "Step 22236/22500 - Loss: 0.018831292167305946, Accuracy: 1.0\n",
            "Step 22237/22500 - Loss: 0.008462069556117058, Accuracy: 1.0\n",
            "Step 22238/22500 - Loss: 0.11244361102581024, Accuracy: 0.875\n",
            "Step 22239/22500 - Loss: 0.003204159904271364, Accuracy: 1.0\n",
            "Step 22240/22500 - Loss: 0.2577754259109497, Accuracy: 0.875\n",
            "Step 22241/22500 - Loss: 0.024174245074391365, Accuracy: 1.0\n",
            "Step 22242/22500 - Loss: 0.016511961817741394, Accuracy: 1.0\n",
            "Step 22243/22500 - Loss: 0.10932399332523346, Accuracy: 1.0\n",
            "Step 22244/22500 - Loss: 0.011676423251628876, Accuracy: 1.0\n",
            "Step 22245/22500 - Loss: 0.1546728014945984, Accuracy: 0.875\n",
            "Step 22246/22500 - Loss: 0.048083022236824036, Accuracy: 1.0\n",
            "Step 22247/22500 - Loss: 0.631230354309082, Accuracy: 0.75\n",
            "Step 22248/22500 - Loss: 0.3032171428203583, Accuracy: 0.875\n",
            "Step 22249/22500 - Loss: 0.018170207738876343, Accuracy: 1.0\n",
            "Step 22250/22500 - Loss: 0.00630126241594553, Accuracy: 1.0\n",
            "Step 22251/22500 - Loss: 0.19047097861766815, Accuracy: 1.0\n",
            "Step 22252/22500 - Loss: 0.3487585484981537, Accuracy: 0.875\n",
            "Step 22253/22500 - Loss: 0.027241958305239677, Accuracy: 1.0\n",
            "Step 22254/22500 - Loss: 0.011610196903347969, Accuracy: 1.0\n",
            "Step 22255/22500 - Loss: 0.04848558455705643, Accuracy: 1.0\n",
            "Step 22256/22500 - Loss: 0.01884905993938446, Accuracy: 1.0\n",
            "Step 22257/22500 - Loss: 0.02828787826001644, Accuracy: 1.0\n",
            "Step 22258/22500 - Loss: 0.009586158208549023, Accuracy: 1.0\n",
            "Step 22259/22500 - Loss: 0.018542315810918808, Accuracy: 1.0\n",
            "Step 22260/22500 - Loss: 0.018737249076366425, Accuracy: 1.0\n",
            "Step 22261/22500 - Loss: 0.1713690310716629, Accuracy: 0.875\n",
            "Step 22262/22500 - Loss: 0.016873423010110855, Accuracy: 1.0\n",
            "Step 22263/22500 - Loss: 0.6218442916870117, Accuracy: 0.875\n",
            "Step 22264/22500 - Loss: 0.004078307654708624, Accuracy: 1.0\n",
            "Step 22265/22500 - Loss: 0.07251818478107452, Accuracy: 1.0\n",
            "Step 22266/22500 - Loss: 0.006103887222707272, Accuracy: 1.0\n",
            "Step 22267/22500 - Loss: 0.012533548288047314, Accuracy: 1.0\n",
            "Step 22268/22500 - Loss: 0.021310701966285706, Accuracy: 1.0\n",
            "Step 22269/22500 - Loss: 0.008712132461369038, Accuracy: 1.0\n",
            "Step 22270/22500 - Loss: 0.02527114562690258, Accuracy: 1.0\n",
            "Step 22271/22500 - Loss: 0.0679745003581047, Accuracy: 1.0\n",
            "Step 22272/22500 - Loss: 0.005310466047376394, Accuracy: 1.0\n",
            "Step 22273/22500 - Loss: 0.03989384323358536, Accuracy: 1.0\n",
            "Step 22274/22500 - Loss: 0.45065808296203613, Accuracy: 0.875\n",
            "Step 22275/22500 - Loss: 0.030252764001488686, Accuracy: 1.0\n",
            "Step 22276/22500 - Loss: 0.040057916194200516, Accuracy: 1.0\n",
            "Step 22277/22500 - Loss: 0.05075553432106972, Accuracy: 1.0\n",
            "Step 22278/22500 - Loss: 0.021345749497413635, Accuracy: 1.0\n",
            "Step 22279/22500 - Loss: 0.01418014895170927, Accuracy: 1.0\n",
            "Step 22280/22500 - Loss: 0.009881749749183655, Accuracy: 1.0\n",
            "Step 22281/22500 - Loss: 0.44393670558929443, Accuracy: 0.75\n",
            "Step 22282/22500 - Loss: 0.13138945400714874, Accuracy: 0.875\n",
            "Step 22283/22500 - Loss: 0.40284037590026855, Accuracy: 0.75\n",
            "Step 22284/22500 - Loss: 0.018957164138555527, Accuracy: 1.0\n",
            "Step 22285/22500 - Loss: 0.40406280755996704, Accuracy: 0.875\n",
            "Step 22286/22500 - Loss: 0.074322909116745, Accuracy: 1.0\n",
            "Step 22287/22500 - Loss: 0.21109184622764587, Accuracy: 0.875\n",
            "Step 22288/22500 - Loss: 0.17040476202964783, Accuracy: 0.875\n",
            "Step 22289/22500 - Loss: 0.05311087146401405, Accuracy: 1.0\n",
            "Step 22290/22500 - Loss: 0.07394436001777649, Accuracy: 1.0\n",
            "Step 22291/22500 - Loss: 0.029796242713928223, Accuracy: 1.0\n",
            "Step 22292/22500 - Loss: 0.015041167847812176, Accuracy: 1.0\n",
            "Step 22293/22500 - Loss: 0.03585320711135864, Accuracy: 1.0\n",
            "Step 22294/22500 - Loss: 0.016773683950304985, Accuracy: 1.0\n",
            "Step 22295/22500 - Loss: 0.03880063816905022, Accuracy: 1.0\n",
            "Step 22296/22500 - Loss: 0.018280165269970894, Accuracy: 1.0\n",
            "Step 22297/22500 - Loss: 0.020179739221930504, Accuracy: 1.0\n",
            "Step 22298/22500 - Loss: 0.02641339600086212, Accuracy: 1.0\n",
            "Step 22299/22500 - Loss: 0.27655866742134094, Accuracy: 0.875\n",
            "Step 22300/22500 - Loss: 0.050672657787799835, Accuracy: 1.0\n",
            "Step 22301/22500 - Loss: 0.04766815900802612, Accuracy: 1.0\n",
            "Step 22302/22500 - Loss: 0.33366042375564575, Accuracy: 0.875\n",
            "Step 22303/22500 - Loss: 0.012187497690320015, Accuracy: 1.0\n",
            "Step 22304/22500 - Loss: 0.062146082520484924, Accuracy: 1.0\n",
            "Step 22305/22500 - Loss: 0.017011655494570732, Accuracy: 1.0\n",
            "Step 22306/22500 - Loss: 0.022707873955368996, Accuracy: 1.0\n",
            "Step 22307/22500 - Loss: 0.005006043706089258, Accuracy: 1.0\n",
            "Step 22308/22500 - Loss: 0.005956883076578379, Accuracy: 1.0\n",
            "Step 22309/22500 - Loss: 0.03533640503883362, Accuracy: 1.0\n",
            "Step 22310/22500 - Loss: 0.09077981114387512, Accuracy: 1.0\n",
            "Step 22311/22500 - Loss: 0.09352656453847885, Accuracy: 1.0\n",
            "Step 22312/22500 - Loss: 0.10738629847764969, Accuracy: 1.0\n",
            "Step 22313/22500 - Loss: 0.08948677778244019, Accuracy: 1.0\n",
            "Step 22314/22500 - Loss: 0.008172544650733471, Accuracy: 1.0\n",
            "Step 22315/22500 - Loss: 0.006826956756412983, Accuracy: 1.0\n",
            "Step 22316/22500 - Loss: 0.5438050031661987, Accuracy: 0.875\n",
            "Step 22317/22500 - Loss: 0.742612898349762, Accuracy: 0.625\n",
            "Step 22318/22500 - Loss: 0.46174356341362, Accuracy: 0.875\n",
            "Step 22319/22500 - Loss: 0.11146023869514465, Accuracy: 1.0\n",
            "Step 22320/22500 - Loss: 0.13177341222763062, Accuracy: 0.875\n",
            "Step 22321/22500 - Loss: 0.028691891580820084, Accuracy: 1.0\n",
            "Step 22322/22500 - Loss: 0.14260584115982056, Accuracy: 0.875\n",
            "Step 22323/22500 - Loss: 0.1221308708190918, Accuracy: 0.875\n",
            "Step 22324/22500 - Loss: 0.14658188819885254, Accuracy: 0.875\n",
            "Step 22325/22500 - Loss: 0.1547534167766571, Accuracy: 1.0\n",
            "Step 22326/22500 - Loss: 0.09412656724452972, Accuracy: 1.0\n",
            "Step 22327/22500 - Loss: 0.49805817008018494, Accuracy: 0.875\n",
            "Step 22328/22500 - Loss: 0.11856835335493088, Accuracy: 1.0\n",
            "Step 22329/22500 - Loss: 0.023426029831171036, Accuracy: 1.0\n",
            "Step 22330/22500 - Loss: 0.8377923965454102, Accuracy: 0.75\n",
            "Step 22331/22500 - Loss: 0.2089686393737793, Accuracy: 0.875\n",
            "Step 22332/22500 - Loss: 0.02512797713279724, Accuracy: 1.0\n",
            "Step 22333/22500 - Loss: 0.4115484654903412, Accuracy: 0.875\n",
            "Step 22334/22500 - Loss: 0.06708942353725433, Accuracy: 1.0\n",
            "Step 22335/22500 - Loss: 0.3858916163444519, Accuracy: 0.875\n",
            "Step 22336/22500 - Loss: 0.29585909843444824, Accuracy: 0.875\n",
            "Step 22337/22500 - Loss: 0.7325751185417175, Accuracy: 0.625\n",
            "Step 22338/22500 - Loss: 0.5862552523612976, Accuracy: 0.875\n",
            "Step 22339/22500 - Loss: 0.08323153853416443, Accuracy: 1.0\n",
            "Step 22340/22500 - Loss: 0.011481176130473614, Accuracy: 1.0\n",
            "Step 22341/22500 - Loss: 0.052163802087306976, Accuracy: 1.0\n",
            "Step 22342/22500 - Loss: 0.03631751984357834, Accuracy: 1.0\n",
            "Step 22343/22500 - Loss: 0.009293446317315102, Accuracy: 1.0\n",
            "Step 22344/22500 - Loss: 0.0611426904797554, Accuracy: 1.0\n",
            "Step 22345/22500 - Loss: 0.25945723056793213, Accuracy: 0.875\n",
            "Step 22346/22500 - Loss: 0.05375925824046135, Accuracy: 1.0\n",
            "Step 22347/22500 - Loss: 0.00387301342561841, Accuracy: 1.0\n",
            "Step 22348/22500 - Loss: 0.017020415514707565, Accuracy: 1.0\n",
            "Step 22349/22500 - Loss: 0.07988797873258591, Accuracy: 1.0\n",
            "Step 22350/22500 - Loss: 0.3953295648097992, Accuracy: 0.875\n",
            "Step 22351/22500 - Loss: 0.15324227511882782, Accuracy: 0.875\n",
            "Step 22352/22500 - Loss: 0.04377874359488487, Accuracy: 1.0\n",
            "Step 22353/22500 - Loss: 0.024844635277986526, Accuracy: 1.0\n",
            "Step 22354/22500 - Loss: 0.4497464895248413, Accuracy: 0.875\n",
            "Step 22355/22500 - Loss: 0.26016613841056824, Accuracy: 0.875\n",
            "Step 22356/22500 - Loss: 0.008529205806553364, Accuracy: 1.0\n",
            "Step 22357/22500 - Loss: 0.20453126728534698, Accuracy: 0.875\n",
            "Step 22358/22500 - Loss: 0.017954442650079727, Accuracy: 1.0\n",
            "Step 22359/22500 - Loss: 0.048930078744888306, Accuracy: 1.0\n",
            "Step 22360/22500 - Loss: 0.08115436881780624, Accuracy: 1.0\n",
            "Step 22361/22500 - Loss: 0.004921055398881435, Accuracy: 1.0\n",
            "Step 22362/22500 - Loss: 0.46287673711776733, Accuracy: 0.875\n",
            "Step 22363/22500 - Loss: 0.014848551712930202, Accuracy: 1.0\n",
            "Step 22364/22500 - Loss: 0.11124599725008011, Accuracy: 1.0\n",
            "Step 22365/22500 - Loss: 0.8931062817573547, Accuracy: 0.625\n",
            "Step 22366/22500 - Loss: 0.06633326411247253, Accuracy: 1.0\n",
            "Step 22367/22500 - Loss: 0.1081785038113594, Accuracy: 0.875\n",
            "Step 22368/22500 - Loss: 0.03920163959264755, Accuracy: 1.0\n",
            "Step 22369/22500 - Loss: 0.057712655514478683, Accuracy: 1.0\n",
            "Step 22370/22500 - Loss: 0.004345092456787825, Accuracy: 1.0\n",
            "Step 22371/22500 - Loss: 0.010055923834443092, Accuracy: 1.0\n",
            "Step 22372/22500 - Loss: 0.4044250249862671, Accuracy: 0.75\n",
            "Step 22373/22500 - Loss: 0.21604841947555542, Accuracy: 0.875\n",
            "Step 22374/22500 - Loss: 0.03038066439330578, Accuracy: 1.0\n",
            "Step 22375/22500 - Loss: 0.07807314395904541, Accuracy: 1.0\n",
            "Step 22376/22500 - Loss: 0.07574189454317093, Accuracy: 1.0\n",
            "Step 22377/22500 - Loss: 0.05250110104680061, Accuracy: 1.0\n",
            "Step 22378/22500 - Loss: 0.02921508438885212, Accuracy: 1.0\n",
            "Step 22379/22500 - Loss: 0.05756831169128418, Accuracy: 1.0\n",
            "Step 22380/22500 - Loss: 0.04156370460987091, Accuracy: 1.0\n",
            "Step 22381/22500 - Loss: 0.029258063063025475, Accuracy: 1.0\n",
            "Step 22382/22500 - Loss: 0.13924501836299896, Accuracy: 0.875\n",
            "Step 22383/22500 - Loss: 0.009006845764815807, Accuracy: 1.0\n",
            "Step 22384/22500 - Loss: 0.08121472597122192, Accuracy: 1.0\n",
            "Step 22385/22500 - Loss: 0.280263215303421, Accuracy: 0.875\n",
            "Step 22386/22500 - Loss: 0.028119364753365517, Accuracy: 1.0\n",
            "Step 22387/22500 - Loss: 0.6357392072677612, Accuracy: 0.75\n",
            "Step 22388/22500 - Loss: 0.11206788569688797, Accuracy: 1.0\n",
            "Step 22389/22500 - Loss: 0.03138723969459534, Accuracy: 1.0\n",
            "Step 22390/22500 - Loss: 0.005783130414783955, Accuracy: 1.0\n",
            "Step 22391/22500 - Loss: 0.14702005684375763, Accuracy: 0.875\n",
            "Step 22392/22500 - Loss: 0.005510173738002777, Accuracy: 1.0\n",
            "Step 22393/22500 - Loss: 0.0065366649068892, Accuracy: 1.0\n",
            "Step 22394/22500 - Loss: 0.30346041917800903, Accuracy: 0.875\n",
            "Step 22395/22500 - Loss: 0.013025771826505661, Accuracy: 1.0\n",
            "Step 22396/22500 - Loss: 0.007050519809126854, Accuracy: 1.0\n",
            "Step 22397/22500 - Loss: 0.13239052891731262, Accuracy: 1.0\n",
            "Step 22398/22500 - Loss: 0.08210920542478561, Accuracy: 1.0\n",
            "Step 22399/22500 - Loss: 0.22800885140895844, Accuracy: 0.875\n",
            "Step 22400/22500 - Loss: 0.10719465464353561, Accuracy: 1.0\n",
            "Step 22401/22500 - Loss: 0.006145027000457048, Accuracy: 1.0\n",
            "Step 22402/22500 - Loss: 0.08330921083688736, Accuracy: 1.0\n",
            "Step 22403/22500 - Loss: 0.042946238070726395, Accuracy: 1.0\n",
            "Step 22404/22500 - Loss: 0.4003034234046936, Accuracy: 0.875\n",
            "Step 22405/22500 - Loss: 0.15617257356643677, Accuracy: 1.0\n",
            "Step 22406/22500 - Loss: 0.016943002119660378, Accuracy: 1.0\n",
            "Step 22407/22500 - Loss: 0.27037373185157776, Accuracy: 0.875\n",
            "Step 22408/22500 - Loss: 0.238783597946167, Accuracy: 0.75\n",
            "Step 22409/22500 - Loss: 0.15726026892662048, Accuracy: 1.0\n",
            "Step 22410/22500 - Loss: 0.13336780667304993, Accuracy: 1.0\n",
            "Step 22411/22500 - Loss: 0.021200569346547127, Accuracy: 1.0\n",
            "Step 22412/22500 - Loss: 0.026554252952337265, Accuracy: 1.0\n",
            "Step 22413/22500 - Loss: 0.021361250430345535, Accuracy: 1.0\n",
            "Step 22414/22500 - Loss: 0.01599395088851452, Accuracy: 1.0\n",
            "Step 22415/22500 - Loss: 0.06954962760210037, Accuracy: 1.0\n",
            "Step 22416/22500 - Loss: 0.009119737893342972, Accuracy: 1.0\n",
            "Step 22417/22500 - Loss: 0.11093875765800476, Accuracy: 1.0\n",
            "Step 22418/22500 - Loss: 0.02647039107978344, Accuracy: 1.0\n",
            "Step 22419/22500 - Loss: 0.02205491065979004, Accuracy: 1.0\n",
            "Step 22420/22500 - Loss: 0.048644863069057465, Accuracy: 1.0\n",
            "Step 22421/22500 - Loss: 0.23026324808597565, Accuracy: 0.75\n",
            "Step 22422/22500 - Loss: 0.03563559800386429, Accuracy: 1.0\n",
            "Step 22423/22500 - Loss: 0.023645717650651932, Accuracy: 1.0\n",
            "Step 22424/22500 - Loss: 0.318511039018631, Accuracy: 0.875\n",
            "Step 22425/22500 - Loss: 0.002092671813443303, Accuracy: 1.0\n",
            "Step 22426/22500 - Loss: 0.0024176223669201136, Accuracy: 1.0\n",
            "Step 22427/22500 - Loss: 0.6550837159156799, Accuracy: 0.75\n",
            "Step 22428/22500 - Loss: 0.06780203431844711, Accuracy: 1.0\n",
            "Step 22429/22500 - Loss: 0.10936517268419266, Accuracy: 1.0\n",
            "Step 22430/22500 - Loss: 0.040125902742147446, Accuracy: 1.0\n",
            "Step 22431/22500 - Loss: 0.4387861490249634, Accuracy: 0.875\n",
            "Step 22432/22500 - Loss: 0.4192196726799011, Accuracy: 0.75\n",
            "Step 22433/22500 - Loss: 0.7697612047195435, Accuracy: 0.875\n",
            "Step 22434/22500 - Loss: 0.025626515969634056, Accuracy: 1.0\n",
            "Step 22435/22500 - Loss: 0.020884202793240547, Accuracy: 1.0\n",
            "Step 22436/22500 - Loss: 0.07778346538543701, Accuracy: 1.0\n",
            "Step 22437/22500 - Loss: 0.014124566689133644, Accuracy: 1.0\n",
            "Step 22438/22500 - Loss: 0.540265679359436, Accuracy: 0.875\n",
            "Step 22439/22500 - Loss: 0.020139727741479874, Accuracy: 1.0\n",
            "Step 22440/22500 - Loss: 0.007861960679292679, Accuracy: 1.0\n",
            "Step 22441/22500 - Loss: 0.013898748904466629, Accuracy: 1.0\n",
            "Step 22442/22500 - Loss: 0.012201943434774876, Accuracy: 1.0\n",
            "Step 22443/22500 - Loss: 0.7662405967712402, Accuracy: 0.625\n",
            "Step 22444/22500 - Loss: 0.023506993427872658, Accuracy: 1.0\n",
            "Step 22445/22500 - Loss: 0.008664009161293507, Accuracy: 1.0\n",
            "Step 22446/22500 - Loss: 0.0510370172560215, Accuracy: 1.0\n",
            "Step 22447/22500 - Loss: 0.011928054504096508, Accuracy: 1.0\n",
            "Step 22448/22500 - Loss: 0.1123441830277443, Accuracy: 0.875\n",
            "Step 22449/22500 - Loss: 0.2864219546318054, Accuracy: 0.875\n",
            "Step 22450/22500 - Loss: 0.01855309121310711, Accuracy: 1.0\n",
            "Step 22451/22500 - Loss: 0.17240336537361145, Accuracy: 0.875\n",
            "Step 22452/22500 - Loss: 0.39078062772750854, Accuracy: 0.875\n",
            "Step 22453/22500 - Loss: 0.03724098950624466, Accuracy: 1.0\n",
            "Step 22454/22500 - Loss: 0.022048214450478554, Accuracy: 1.0\n",
            "Step 22455/22500 - Loss: 0.1381509006023407, Accuracy: 0.875\n",
            "Step 22456/22500 - Loss: 0.10576865077018738, Accuracy: 0.875\n",
            "Step 22457/22500 - Loss: 0.012136328965425491, Accuracy: 1.0\n",
            "Step 22458/22500 - Loss: 0.09019359946250916, Accuracy: 1.0\n",
            "Step 22459/22500 - Loss: 0.09258171916007996, Accuracy: 1.0\n",
            "Step 22460/22500 - Loss: 0.09263084828853607, Accuracy: 1.0\n",
            "Step 22461/22500 - Loss: 0.008996742777526379, Accuracy: 1.0\n",
            "Step 22462/22500 - Loss: 0.11449738591909409, Accuracy: 0.875\n",
            "Step 22463/22500 - Loss: 0.23481708765029907, Accuracy: 0.875\n",
            "Step 22464/22500 - Loss: 0.5464164614677429, Accuracy: 0.875\n",
            "Step 22465/22500 - Loss: 0.026143129914999008, Accuracy: 1.0\n",
            "Step 22466/22500 - Loss: 0.027575476095080376, Accuracy: 1.0\n",
            "Step 22467/22500 - Loss: 0.11020947247743607, Accuracy: 0.875\n",
            "Step 22468/22500 - Loss: 0.5665381550788879, Accuracy: 0.75\n",
            "Step 22469/22500 - Loss: 0.28062209486961365, Accuracy: 0.875\n",
            "Step 22470/22500 - Loss: 0.03171918913722038, Accuracy: 1.0\n",
            "Step 22471/22500 - Loss: 0.10572273284196854, Accuracy: 1.0\n",
            "Step 22472/22500 - Loss: 0.01529978308826685, Accuracy: 1.0\n",
            "Step 22473/22500 - Loss: 0.015424671582877636, Accuracy: 1.0\n",
            "Step 22474/22500 - Loss: 0.027467401698231697, Accuracy: 1.0\n",
            "Step 22475/22500 - Loss: 0.034625936299562454, Accuracy: 1.0\n",
            "Step 22476/22500 - Loss: 0.1405371129512787, Accuracy: 1.0\n",
            "Step 22477/22500 - Loss: 0.06451909989118576, Accuracy: 1.0\n",
            "Step 22478/22500 - Loss: 0.011899777688086033, Accuracy: 1.0\n",
            "Step 22479/22500 - Loss: 0.2985822558403015, Accuracy: 0.75\n",
            "Step 22480/22500 - Loss: 0.03666803985834122, Accuracy: 1.0\n",
            "Step 22481/22500 - Loss: 0.2758638560771942, Accuracy: 0.875\n",
            "Step 22482/22500 - Loss: 0.30133408308029175, Accuracy: 0.875\n",
            "Step 22483/22500 - Loss: 0.006178901996463537, Accuracy: 1.0\n",
            "Step 22484/22500 - Loss: 0.011650877073407173, Accuracy: 1.0\n",
            "Step 22485/22500 - Loss: 0.13134780526161194, Accuracy: 1.0\n",
            "Step 22486/22500 - Loss: 0.30361321568489075, Accuracy: 0.75\n",
            "Step 22487/22500 - Loss: 0.012706327252089977, Accuracy: 1.0\n",
            "Step 22488/22500 - Loss: 0.05610096454620361, Accuracy: 1.0\n",
            "Step 22489/22500 - Loss: 0.34230518341064453, Accuracy: 0.875\n",
            "Step 22490/22500 - Loss: 0.43099403381347656, Accuracy: 0.875\n",
            "Step 22491/22500 - Loss: 0.031160272657871246, Accuracy: 1.0\n",
            "Step 22492/22500 - Loss: 0.011883263476192951, Accuracy: 1.0\n",
            "Step 22493/22500 - Loss: 0.01608394645154476, Accuracy: 1.0\n",
            "Step 22494/22500 - Loss: 0.14369060099124908, Accuracy: 0.875\n",
            "Step 22495/22500 - Loss: 0.025158673524856567, Accuracy: 1.0\n",
            "Step 22496/22500 - Loss: 0.0573008731007576, Accuracy: 1.0\n",
            "Step 22497/22500 - Loss: 0.12541380524635315, Accuracy: 0.875\n",
            "Step 22498/22500 - Loss: 0.08812029659748077, Accuracy: 1.0\n",
            "Step 22499/22500 - Loss: 0.15041960775852203, Accuracy: 0.875\n",
            "Step 22500/22500 - Loss: 0.09547916799783707, Accuracy: 1.0\n",
            "Epoch 3 - Train loss: 0.13367875648930203, Accuracy: 0.9491222222222222\n",
            "Epoch 3 - Validation loss: 0.3617672021549428, Accuracy: 0.87655\n",
            "Training complete!\n",
            "Overall Precision: 0.8733104150553685, Recall: 0.8729968248206175, F1 Score: 0.873027781424728\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 5  # Number of training epochs\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(train_loader) * num_epochs)\n",
        "\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def calc_accuracy(preds, labels):\n",
        "    _, predictions = torch.max(preds, dim=1)\n",
        "    correct = (predictions == labels).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    total_train_acc = 0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = criterion(outputs.logits, batch['labels'])\n",
        "        acc = calc_accuracy(outputs.logits, batch['labels'])\n",
        "        print(f\"Step {step+1}/{len(train_loader)} - Loss: {loss.item()}, Accuracy: {acc.item()}\")\n",
        "        total_train_loss += loss.item()\n",
        "        total_train_acc += acc.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    avg_train_acc = total_train_acc / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} - Train loss: {avg_train_loss}, Accuracy: {avg_train_acc}\")\n",
        "\n",
        "    # Validation Loop\n",
        "    model.eval()\n",
        "    total_val_accuracy = 0\n",
        "    total_val_loss = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "        with torch.no_grad():\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = criterion(outputs.logits, batch['labels'])\n",
        "            acc = calc_accuracy(outputs.logits, batch['labels'])\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            total_val_accuracy += acc.item()\n",
        "\n",
        "            # for overall metrics calculation\n",
        "            preds = outputs.logits.argmax(dim=1).cpu().numpy()\n",
        "            labels = batch['labels'].cpu().numpy()\n",
        "            all_predictions.extend(preds)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    avg_val_accuracy = total_val_accuracy / len(val_loader)\n",
        "    print(f\"Epoch {epoch+1} - Validation loss: {avg_val_loss}, Accuracy: {avg_val_accuracy}\")\n",
        "\n",
        "# After all epochs, calculate overall metrics\n",
        "precision = precision_score(all_labels, all_predictions, average='macro')\n",
        "recall = recall_score(all_labels, all_predictions, average='macro')\n",
        "f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "\n",
        "print(\"Training complete!\")\n",
        "print(f\"Overall Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1phcjpJ7vkd-"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'bert.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvt6507Ha_sp"
      },
      "outputs": [],
      "source": [
        "## predict\n",
        "model = torch.load('bert.pth')\n",
        "\n",
        "## use the test set\n",
        "test_path = folder_path + 'data/twitter-datasets/test_data.txt'\n",
        "with open(test_path, 'r') as f:\n",
        "    test_tweets = f.readlines()\n",
        "\n",
        "test_encodings = tokenizer(test_tweets, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "test_dataset = TweetDataset(test_encodings, [0 for _ in range(len(test_tweets))])\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "for batch in test_loader:\n",
        "    with torch.no_grad():\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        preds = outputs.logits.argmax(dim=1).cpu().numpy()\n",
        "        predictions.extend(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6r6SXzwbgee"
      },
      "outputs": [],
      "source": [
        "predictions = np.array(predictions)\n",
        "predictions[predictions == 0] = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_iHW_xrbVlm",
        "outputId": "1b26e777-3a61-46fa-af39-f45a26130da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1 -1 -1 ... -1  1 -1]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmFrYWA7bYxU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG1C1sVVbKZp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "submission = pd.DataFrame({'Id':range(1, len(predictions) + 1),'Prediction': predictions})\n",
        "submission.to_csv('submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02abcd45b1864d078cc550c667fdaf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2989b8f0d1e4896b6f348dd4dddfe2b",
            "placeholder": "​",
            "style": "IPY_MODEL_102153cc6f3248949ab7ac5875b73907",
            "value": "model.safetensors: 100%"
          }
        },
        "03b02aed55704de489049ff99a8794c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff749937033648f9a17b5f36a31d9765",
            "placeholder": "​",
            "style": "IPY_MODEL_1d758595b9c04c4c8b5d097b05683d7a",
            "value": " 440M/440M [00:01&lt;00:00, 341MB/s]"
          }
        },
        "0b5d6a1e607144878554a64ebab0533f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f38fc12874446abbf2767a04e1e05ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa78a342be94571a268ee61f4e3c01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9094bfe693954583927f67e355770eaf",
            "placeholder": "​",
            "style": "IPY_MODEL_4d26a53fe26549349e45e227c1bfd585",
            "value": " 570/570 [00:00&lt;00:00, 43.6kB/s]"
          }
        },
        "102153cc6f3248949ab7ac5875b73907": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "125fc3defb934484b47c9d86cd632bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "175368bb903c41b6b9dc09574b2f27d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d758595b9c04c4c8b5d097b05683d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26d819d3a7234c05978fa8b38a3d3c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28c1be7267954ebd9b0811bb128016f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cb7f33f73a44212903dacb9fc13a5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_408fe317813f421bb77c97ec30e41125",
              "IPY_MODEL_5f56a9f04032416995d83ebc7e8067b7",
              "IPY_MODEL_399404ae78514d87af805eeae52ac6da"
            ],
            "layout": "IPY_MODEL_dc8be3d30f5b47ffae3e394102a7392c"
          }
        },
        "2fa8386c7a7b47f4a5417002e5fec63a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36bf77fe27ab483997e073c49096464a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "399404ae78514d87af805eeae52ac6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73f44759a18d43229dcadc240334944f",
            "placeholder": "​",
            "style": "IPY_MODEL_36bf77fe27ab483997e073c49096464a",
            "value": " 232k/232k [00:00&lt;00:00, 473kB/s]"
          }
        },
        "39defc5139e24431ac20c3f1bc7faa7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aedb6b756d5949b897c8efcd38622855",
              "IPY_MODEL_55adf2e4079240c28006e6b2f5247c2d",
              "IPY_MODEL_909aa314910d429b9a24e6b33ba41dc8"
            ],
            "layout": "IPY_MODEL_bacc9e20d09d4064b8d9824d37a43d44"
          }
        },
        "3bd9188ae6414fe3b28f52d88aa6012c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408fe317813f421bb77c97ec30e41125": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9278eac27dc740cfafd944b71bc44eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_c4c6b654729b4221962a4fdc30bbcb9e",
            "value": "vocab.txt: 100%"
          }
        },
        "443e61c993dd42eb9c9ad782b11eca93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d26a53fe26549349e45e227c1bfd585": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55adf2e4079240c28006e6b2f5247c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f38fc12874446abbf2767a04e1e05ef",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dd318a1fa2843cbab7047bc3741296e",
            "value": 28
          }
        },
        "5f56a9f04032416995d83ebc7e8067b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aeee5e49361449b8a269519a4f176d0",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_175368bb903c41b6b9dc09574b2f27d6",
            "value": 231508
          }
        },
        "636e173a4d8a4d5db8b34b8935db62e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72353c6129d44c2ab0654b922fd9a0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "726d5e2f329b4d12a8088b6667ea42c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab80dce52b374653b0d363e821b28468",
              "IPY_MODEL_79e3872c7ffd4fc19602cd0917243da3",
              "IPY_MODEL_b347db1d29654fd9b096b789d8b6080a"
            ],
            "layout": "IPY_MODEL_8a296714b44044689d1881fd9ec84160"
          }
        },
        "73f44759a18d43229dcadc240334944f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "784f5867029247ecacfb9cf7912b490a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7871b157ae36445cac915f7fe44f5856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28c1be7267954ebd9b0811bb128016f8",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_784f5867029247ecacfb9cf7912b490a",
            "value": 440449768
          }
        },
        "79e3872c7ffd4fc19602cd0917243da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72353c6129d44c2ab0654b922fd9a0bb",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f86cfe1ddaa240ce8eaac38a82c20abd",
            "value": 466062
          }
        },
        "88a9c0743a344f3bb06c7c411730822d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89e4a680539f47a3ab8a6ff018898df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5d6a1e607144878554a64ebab0533f",
            "placeholder": "​",
            "style": "IPY_MODEL_ae76992fb23943f7ac30b058a4c8e16a",
            "value": "config.json: 100%"
          }
        },
        "8a296714b44044689d1881fd9ec84160": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dd318a1fa2843cbab7047bc3741296e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9094bfe693954583927f67e355770eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "909aa314910d429b9a24e6b33ba41dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b679171ab707492ab9d0aebc07232d92",
            "placeholder": "​",
            "style": "IPY_MODEL_125fc3defb934484b47c9d86cd632bbc",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.76kB/s]"
          }
        },
        "9156a6bc795f42beb5a5991b23591033": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9278eac27dc740cfafd944b71bc44eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aeee5e49361449b8a269519a4f176d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d6c22f05b2f4501bea23c38edcbbb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_636e173a4d8a4d5db8b34b8935db62e0",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26d819d3a7234c05978fa8b38a3d3c61",
            "value": 570
          }
        },
        "ab80dce52b374653b0d363e821b28468": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eed58ea3c0e942d4a93f98080f1ea808",
            "placeholder": "​",
            "style": "IPY_MODEL_bd099c2b893244eb8c07824b3350a48f",
            "value": "tokenizer.json: 100%"
          }
        },
        "ae76992fb23943f7ac30b058a4c8e16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aedb6b756d5949b897c8efcd38622855": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bd9188ae6414fe3b28f52d88aa6012c",
            "placeholder": "​",
            "style": "IPY_MODEL_bd417b8d4a8745b293956f05ba48f7b2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b347db1d29654fd9b096b789d8b6080a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9156a6bc795f42beb5a5991b23591033",
            "placeholder": "​",
            "style": "IPY_MODEL_443e61c993dd42eb9c9ad782b11eca93",
            "value": " 466k/466k [00:00&lt;00:00, 1.90MB/s]"
          }
        },
        "b679171ab707492ab9d0aebc07232d92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bacc9e20d09d4064b8d9824d37a43d44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd099c2b893244eb8c07824b3350a48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd417b8d4a8745b293956f05ba48f7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4c6b654729b4221962a4fdc30bbcb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2989b8f0d1e4896b6f348dd4dddfe2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdf4e8013ca45f78e131323c7437659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02abcd45b1864d078cc550c667fdaf48",
              "IPY_MODEL_7871b157ae36445cac915f7fe44f5856",
              "IPY_MODEL_03b02aed55704de489049ff99a8794c3"
            ],
            "layout": "IPY_MODEL_88a9c0743a344f3bb06c7c411730822d"
          }
        },
        "dc8be3d30f5b47ffae3e394102a7392c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eed58ea3c0e942d4a93f98080f1ea808": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b5b740966544598f468398a42121c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89e4a680539f47a3ab8a6ff018898df4",
              "IPY_MODEL_9d6c22f05b2f4501bea23c38edcbbb6b",
              "IPY_MODEL_0fa78a342be94571a268ee61f4e3c01d"
            ],
            "layout": "IPY_MODEL_2fa8386c7a7b47f4a5417002e5fec63a"
          }
        },
        "f86cfe1ddaa240ce8eaac38a82c20abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff749937033648f9a17b5f36a31d9765": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
